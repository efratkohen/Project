{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clean_data_svi as cds\n",
    "import supervised as sup\n",
    "import pathlib\n",
    "import keras_model as km\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from datetime import timedelta, datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from keras import backend as K, Sequential, Input, Model\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, LSTM, Bidirectional, Conv1D, MaxPooling1D, MaxPooling2D, Flatten, \\\n",
    "    TimeDistributed, RepeatVector, Dropout, GRU, AveragePooling1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error, median_absolute_error, roc_curve, auc, f1_score, \\\n",
    "    precision_recall_curve, r2_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import imblearn\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN, BorderlineSMOTE, SVMSMOTE, KMeansSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_for_max_f1(y_real, Yhat):\n",
    "    '''\n",
    "    Given inputs y_real and y_predict, the function returns\n",
    "    the threshold (rounded to the nearest hundredth) that\n",
    "    maximizes f1.\n",
    "    \n",
    "    Note: this func not necessarily optimized, could return to \n",
    "    doing this but not needed).\n",
    "    \n",
    "    Also note that we calculate f1 without using the results method\n",
    "    in keras_model. This is because we need to check beforehand that\n",
    "    computing f1 won't produce a NaN so we won't get an invalid value warning.\n",
    "    '''\n",
    "    \n",
    "    #error is occuring in km.results when computing f1, because TNR, NPV are 0, implying that there\n",
    "    #are no true negatives. While we added if statements to account for at least one predicted\n",
    "    #negative, this does not correlate to at least one true negative. Hence, instead of using keras.results\n",
    "    #we use that code by check that tn is not 0\n",
    "    f1_vals = []\n",
    "    for i in range(0, 100):\n",
    "        threshold = i/100\n",
    "        y_predict = np.where(Yhat > threshold, 1, 0).astype(int)\n",
    "\n",
    "        cm = confusion_matrix(y_real, y_predict)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_real, y_predict).ravel()\n",
    "        \n",
    "        if tn != 0:      \n",
    "            TNR = (tn) / (tn + fp)\n",
    "            NPV = (tn) / (tn + fn)\n",
    "            f1 = 2 * (TNR * NPV) / (TNR + NPV)\n",
    "        else:\n",
    "            f1 = -2   \n",
    "        f1_vals.append(f1)\n",
    "        \n",
    "    f1_vals = np.array(f1_vals)\n",
    "    f1_vals = np.nan_to_num(f1_vals, nan=-1)\n",
    "    return (np.argmax(f1_vals))/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cf_matrix(y_real, y_predict):\n",
    "    '''\n",
    "    Given y_real and y_predict, this method displays the results\n",
    "    (accuracy, recall, precision, f1) followed by the plot of the confusion matrix.\n",
    "    '''\n",
    "    print(km.results(y_real, y_predict), '\\n')\n",
    "    \n",
    "    classes = ['High_svi', 'Low_svi']\n",
    "    cm = confusion_matrix(y_real, y_predict)\n",
    "    sup.plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVI_list = []\n",
    "for i in range(4):\n",
    "    df = pd.read_csv(f\"clean_tables/svi_{i+1}.csv\", index_col=\"date\")\n",
    "    df = df.drop(columns=['Settling_velocity', 'SV_label', 'SVI_label'])\n",
    "    df.index = pd.to_datetime(df.index, dayfirst=True)\n",
    "    SVI_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.read_csv(\"clean_tables/temperatur.csv\", index_col=\"date\")\n",
    "temp_df.index = pd.to_datetime(temp_df.index, dayfirst=True)\n",
    "sludge_age_df = pd.read_csv(\"clean_tables/sludge_age_f_m.csv\", index_col=\"date\")\n",
    "sludge_age_df.index = pd.to_datetime(sludge_age_df.index, dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactor_list = []\n",
    "for i in range(4):\n",
    "    join = pd.concat([SVI_list[i], temp_df], axis=1)\n",
    "    if i <=1:\n",
    "        join = pd.concat([join, sludge_age_df.iloc[:, np.r_[0, 2]]], axis=1)\n",
    "    else:\n",
    "        join = pd.concat([join, sludge_age_df.iloc[:, np.r_[1, 3]]], axis=1)\n",
    "    join.columns = ['SVI', 'Temperature', 'F_M', 'Sludge Age']\n",
    "    reactor_list.append(join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVI</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>F_M</th>\n",
       "      <th>Sludge Age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>94.066570</td>\n",
       "      <td>22.030</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02</th>\n",
       "      <td>95.318860</td>\n",
       "      <td>21.985</td>\n",
       "      <td>0.22</td>\n",
       "      <td>3.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-03</th>\n",
       "      <td>82.826748</td>\n",
       "      <td>21.740</td>\n",
       "      <td>0.22</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>95.307918</td>\n",
       "      <td>21.815</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>93.930636</td>\n",
       "      <td>21.890</td>\n",
       "      <td>0.23</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-27</th>\n",
       "      <td>144.736842</td>\n",
       "      <td>22.540</td>\n",
       "      <td>0.23</td>\n",
       "      <td>3.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-28</th>\n",
       "      <td>130.890052</td>\n",
       "      <td>22.535</td>\n",
       "      <td>0.24</td>\n",
       "      <td>3.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-29</th>\n",
       "      <td>140.306122</td>\n",
       "      <td>22.660</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-30</th>\n",
       "      <td>131.250000</td>\n",
       "      <td>22.660</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>147.453083</td>\n",
       "      <td>22.735</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4018 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   SVI  Temperature   F_M  Sludge Age\n",
       "date                                                 \n",
       "2010-01-01   94.066570       22.030  0.22        2.92\n",
       "2010-01-02   95.318860       21.985  0.22        3.04\n",
       "2010-01-03   82.826748       21.740  0.22        3.00\n",
       "2010-01-04   95.307918       21.815  0.22        2.97\n",
       "2010-01-05   93.930636       21.890  0.23        2.94\n",
       "...                ...          ...   ...         ...\n",
       "2020-12-27  144.736842       22.540  0.23        3.41\n",
       "2020-12-28  130.890052       22.535  0.24        3.10\n",
       "2020-12-29  140.306122       22.660  0.25        3.15\n",
       "2020-12-30  131.250000       22.660  0.25        3.32\n",
       "2020-12-31  147.453083       22.735  0.25        3.32\n",
       "\n",
       "[4018 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reactor_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_list = []\n",
    "for i in range(4):\n",
    "    df = pd.read_csv(f\"clean_tables/micro_{i+1}.csv\", index_col=\"date\")\n",
    "    df.index = pd.to_datetime(df.index, dayfirst=True)\n",
    "    micro_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arcella</th>\n",
       "      <th>nude ameba</th>\n",
       "      <th>aspidisca</th>\n",
       "      <th>trachelopylum</th>\n",
       "      <th>lionutus</th>\n",
       "      <th>paramecium</th>\n",
       "      <th>carchecium</th>\n",
       "      <th>epistylis</th>\n",
       "      <th>opercularia</th>\n",
       "      <th>podophyra</th>\n",
       "      <th>...</th>\n",
       "      <th>Floc Strength</th>\n",
       "      <th>Indian Ink</th>\n",
       "      <th>Filament index</th>\n",
       "      <th>Floc_size_small</th>\n",
       "      <th>Floc_size_medium</th>\n",
       "      <th>Floc_size_large</th>\n",
       "      <th>Shape_close</th>\n",
       "      <th>Shape_open</th>\n",
       "      <th>Filaments_in_floc</th>\n",
       "      <th>Free_filaments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-02-18</th>\n",
       "      <td>40.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-02</th>\n",
       "      <td>27.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-08</th>\n",
       "      <td>27.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-18</th>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-08</th>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-23</th>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-21</th>\n",
       "      <td>7.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-28</th>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-11</th>\n",
       "      <td>23.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-25</th>\n",
       "      <td>12.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>362 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            arcella  nude ameba  aspidisca  trachelopylum  lionutus  \\\n",
       "date                                                                  \n",
       "2010-02-18     40.0         4.0        2.0            0.0       6.0   \n",
       "2010-03-02     27.0         5.0        3.0            1.0      16.0   \n",
       "2010-03-08     27.0         8.0       14.0            1.0       9.0   \n",
       "2010-03-18     11.0        12.0        2.0            0.0      16.0   \n",
       "2010-04-08     12.0         6.0       10.0            0.0      13.0   \n",
       "...             ...         ...        ...            ...       ...   \n",
       "2020-09-23      5.0        11.0        9.0            2.0       5.0   \n",
       "2020-10-21      7.0        57.0       55.0            0.0      12.0   \n",
       "2020-10-28     14.0        20.0        1.0            0.0      24.0   \n",
       "2020-11-11     23.0        86.0       17.0            1.0      29.0   \n",
       "2020-11-25     12.0        56.0       64.0            0.0      18.0   \n",
       "\n",
       "            paramecium  carchecium  epistylis  opercularia  podophyra  ...  \\\n",
       "date                                                                   ...   \n",
       "2010-02-18         0.0         1.0        4.0          4.0        0.0  ...   \n",
       "2010-03-02         0.0         0.0       13.0          4.0        0.0  ...   \n",
       "2010-03-08         1.0         0.0       11.0          9.0        0.0  ...   \n",
       "2010-03-18         0.0         0.0        7.0          0.0        0.0  ...   \n",
       "2010-04-08         1.0         0.0        1.0          1.0        0.0  ...   \n",
       "...                ...         ...        ...          ...        ...  ...   \n",
       "2020-09-23         0.0         0.0        6.0          0.0        3.0  ...   \n",
       "2020-10-21         0.0        14.0       26.0          0.0        0.0  ...   \n",
       "2020-10-28         0.0         0.0       35.0          2.0        0.0  ...   \n",
       "2020-11-11         0.0         0.0       18.0          0.0        0.0  ...   \n",
       "2020-11-25         0.0         0.0       41.0          4.0        2.0  ...   \n",
       "\n",
       "            Floc Strength  Indian Ink  Filament index  Floc_size_small  \\\n",
       "date                                                                     \n",
       "2010-02-18            NaN         NaN             3.0              0.0   \n",
       "2010-03-02            NaN         NaN             3.0              NaN   \n",
       "2010-03-08            NaN         NaN             3.0              NaN   \n",
       "2010-03-18            NaN         NaN             3.0              0.0   \n",
       "2010-04-08            NaN         NaN             3.0              0.0   \n",
       "...                   ...         ...             ...              ...   \n",
       "2020-09-23            3.0         1.0             2.0              0.0   \n",
       "2020-10-21            1.0         3.0             3.0              1.0   \n",
       "2020-10-28            2.0         3.0             2.5              1.0   \n",
       "2020-11-11            3.0         2.0             2.5              1.0   \n",
       "2020-11-25            1.0         2.0             2.5              1.0   \n",
       "\n",
       "            Floc_size_medium  Floc_size_large  Shape_close  Shape_open  \\\n",
       "date                                                                     \n",
       "2010-02-18               1.0              1.0          0.0         1.0   \n",
       "2010-03-02               NaN              NaN          0.0         1.0   \n",
       "2010-03-08               NaN              NaN          1.0         1.0   \n",
       "2010-03-18               1.0              1.0          0.0         1.0   \n",
       "2010-04-08               1.0              1.0          0.0         1.0   \n",
       "...                      ...              ...          ...         ...   \n",
       "2020-09-23               1.0              1.0          1.0         1.0   \n",
       "2020-10-21               1.0              1.0          0.0         1.0   \n",
       "2020-10-28               1.0              1.0          1.0         1.0   \n",
       "2020-11-11               1.0              1.0          1.0         1.0   \n",
       "2020-11-25               1.0              1.0          0.0         1.0   \n",
       "\n",
       "            Filaments_in_floc  Free_filaments  \n",
       "date                                           \n",
       "2010-02-18                1.0             1.0  \n",
       "2010-03-02                1.0             0.0  \n",
       "2010-03-08                1.0             1.0  \n",
       "2010-03-18                1.0             1.0  \n",
       "2010-04-08                1.0             1.0  \n",
       "...                       ...             ...  \n",
       "2020-09-23                1.0             1.0  \n",
       "2020-10-21                1.0             1.0  \n",
       "2020-10-28                1.0             1.0  \n",
       "2020-11-11                1.0             1.0  \n",
       "2020-11-25                1.0             1.0  \n",
       "\n",
       "[362 rows x 37 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_list = []\n",
    "for i in range(4):\n",
    "    join = pd.concat([reactor_list[i], micro_list[i]], axis=1)\n",
    "    join_list.append(join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVI</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>F_M</th>\n",
       "      <th>Sludge Age</th>\n",
       "      <th>arcella</th>\n",
       "      <th>nude ameba</th>\n",
       "      <th>aspidisca</th>\n",
       "      <th>trachelopylum</th>\n",
       "      <th>lionutus</th>\n",
       "      <th>paramecium</th>\n",
       "      <th>...</th>\n",
       "      <th>Floc Strength</th>\n",
       "      <th>Indian Ink</th>\n",
       "      <th>Filament index</th>\n",
       "      <th>Floc_size_small</th>\n",
       "      <th>Floc_size_medium</th>\n",
       "      <th>Floc_size_large</th>\n",
       "      <th>Shape_close</th>\n",
       "      <th>Shape_open</th>\n",
       "      <th>Filaments_in_floc</th>\n",
       "      <th>Free_filaments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-10-28</th>\n",
       "      <td>117.302053</td>\n",
       "      <td>27.165</td>\n",
       "      <td>0.24</td>\n",
       "      <td>3.32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-29</th>\n",
       "      <td>194.174757</td>\n",
       "      <td>27.495</td>\n",
       "      <td>0.24</td>\n",
       "      <td>3.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-30</th>\n",
       "      <td>153.714774</td>\n",
       "      <td>27.055</td>\n",
       "      <td>0.24</td>\n",
       "      <td>3.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-31</th>\n",
       "      <td>177.165354</td>\n",
       "      <td>26.720</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-01</th>\n",
       "      <td>171.113626</td>\n",
       "      <td>26.380</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-02</th>\n",
       "      <td>165.061898</td>\n",
       "      <td>26.210</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3.47</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-03</th>\n",
       "      <td>154.241645</td>\n",
       "      <td>25.915</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-04</th>\n",
       "      <td>123.667377</td>\n",
       "      <td>25.620</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-05</th>\n",
       "      <td>122.850123</td>\n",
       "      <td>25.965</td>\n",
       "      <td>0.23</td>\n",
       "      <td>2.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-06</th>\n",
       "      <td>127.416520</td>\n",
       "      <td>26.255</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-07</th>\n",
       "      <td>156.046814</td>\n",
       "      <td>26.105</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-08</th>\n",
       "      <td>159.482759</td>\n",
       "      <td>25.820</td>\n",
       "      <td>0.27</td>\n",
       "      <td>2.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-09</th>\n",
       "      <td>172.413793</td>\n",
       "      <td>25.450</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-10</th>\n",
       "      <td>133.874239</td>\n",
       "      <td>25.860</td>\n",
       "      <td>0.23</td>\n",
       "      <td>3.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-11</th>\n",
       "      <td>124.463519</td>\n",
       "      <td>26.245</td>\n",
       "      <td>0.23</td>\n",
       "      <td>2.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-12</th>\n",
       "      <td>118.990957</td>\n",
       "      <td>26.550</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-13</th>\n",
       "      <td>163.551402</td>\n",
       "      <td>26.600</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-14</th>\n",
       "      <td>141.057935</td>\n",
       "      <td>26.070</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-15</th>\n",
       "      <td>164.383562</td>\n",
       "      <td>26.085</td>\n",
       "      <td>0.27</td>\n",
       "      <td>2.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-16</th>\n",
       "      <td>138.269402</td>\n",
       "      <td>26.430</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-17</th>\n",
       "      <td>133.813690</td>\n",
       "      <td>26.375</td>\n",
       "      <td>0.27</td>\n",
       "      <td>2.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-18</th>\n",
       "      <td>140.449438</td>\n",
       "      <td>26.240</td>\n",
       "      <td>0.27</td>\n",
       "      <td>2.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-19</th>\n",
       "      <td>158.562368</td>\n",
       "      <td>26.185</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-20</th>\n",
       "      <td>170.278638</td>\n",
       "      <td>26.335</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-21</th>\n",
       "      <td>132.770066</td>\n",
       "      <td>26.000</td>\n",
       "      <td>0.27</td>\n",
       "      <td>2.07</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-22</th>\n",
       "      <td>142.624287</td>\n",
       "      <td>25.870</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-23</th>\n",
       "      <td>183.767228</td>\n",
       "      <td>25.385</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-24</th>\n",
       "      <td>179.573513</td>\n",
       "      <td>25.130</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25</th>\n",
       "      <td>191.612437</td>\n",
       "      <td>24.885</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26</th>\n",
       "      <td>197.394394</td>\n",
       "      <td>24.700</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   SVI  Temperature   F_M  Sludge Age  arcella  nude ameba  \\\n",
       "date                                                                         \n",
       "2010-10-28  117.302053       27.165  0.24        3.32      NaN         NaN   \n",
       "2010-10-29  194.174757       27.495  0.24        3.09      NaN         NaN   \n",
       "2010-10-30  153.714774       27.055  0.24        3.39      NaN         NaN   \n",
       "2010-10-31  177.165354       26.720  0.25        2.74      NaN         NaN   \n",
       "2010-11-01  171.113626       26.380  0.25        3.43      NaN         NaN   \n",
       "2010-11-02  165.061898       26.210  0.25        3.47     15.0        14.0   \n",
       "2010-11-03  154.241645       25.915  0.25        2.54      NaN         NaN   \n",
       "2010-11-04  123.667377       25.620  0.24        2.23      NaN         NaN   \n",
       "2010-11-05  122.850123       25.965  0.23        2.44      NaN         NaN   \n",
       "2010-11-06  127.416520       26.255  0.24        2.68      NaN         NaN   \n",
       "2010-11-07  156.046814       26.105  0.24        2.83      NaN         NaN   \n",
       "2010-11-08  159.482759       25.820  0.27        2.88      NaN         NaN   \n",
       "2010-11-09  172.413793       25.450  0.22        2.93      NaN         NaN   \n",
       "2010-11-10  133.874239       25.860  0.23        3.10      NaN         NaN   \n",
       "2010-11-11  124.463519       26.245  0.23        2.83      NaN         NaN   \n",
       "2010-11-12  118.990957       26.550  0.24        2.97      NaN         NaN   \n",
       "2010-11-13  163.551402       26.600  0.25        3.13      NaN         NaN   \n",
       "2010-11-14  141.057935       26.070  0.26        2.96      NaN         NaN   \n",
       "2010-11-15  164.383562       26.085  0.27        2.84      NaN         NaN   \n",
       "2010-11-16  138.269402       26.430  0.26        2.89      NaN         NaN   \n",
       "2010-11-17  133.813690       26.375  0.27        2.94      NaN         NaN   \n",
       "2010-11-18  140.449438       26.240  0.27        2.88      NaN         NaN   \n",
       "2010-11-19  158.562368       26.185  0.28        1.99      NaN         NaN   \n",
       "2010-11-20  170.278638       26.335  0.28        2.24      NaN         NaN   \n",
       "2010-11-21  132.770066       26.000  0.27        2.07     17.0         2.0   \n",
       "2010-11-22  142.624287       25.870  0.26        2.98      NaN         NaN   \n",
       "2010-11-23  183.767228       25.385  0.26        2.88      NaN         NaN   \n",
       "2010-11-24  179.573513       25.130  0.25        2.77      NaN         NaN   \n",
       "2010-11-25  191.612437       24.885  0.24        2.67      NaN         NaN   \n",
       "2010-11-26  197.394394       24.700  0.24        2.68      NaN         NaN   \n",
       "\n",
       "            aspidisca  trachelopylum  lionutus  paramecium  ...  \\\n",
       "date                                                        ...   \n",
       "2010-10-28        NaN            NaN       NaN         NaN  ...   \n",
       "2010-10-29        NaN            NaN       NaN         NaN  ...   \n",
       "2010-10-30        NaN            NaN       NaN         NaN  ...   \n",
       "2010-10-31        NaN            NaN       NaN         NaN  ...   \n",
       "2010-11-01        NaN            NaN       NaN         NaN  ...   \n",
       "2010-11-02        2.0            0.0      13.0         1.0  ...   \n",
       "2010-11-03        NaN            NaN       NaN         NaN  ...   \n",
       "2010-11-04        NaN            NaN       NaN         NaN  ...   \n",
       "2010-11-05        NaN            NaN       NaN         NaN  ...   \n",
       "2010-11-06        NaN            NaN       NaN         NaN  ...   \n",
       "2010-11-07        NaN            NaN       NaN         NaN  ...   \n",
       "2010-11-08        NaN            NaN       NaN         NaN  ...   \n",
       "2010-11-09        NaN            NaN       NaN         NaN  ...   \n",
       "2010-11-10        NaN            NaN       NaN         NaN  ...   \n",
       "2010-11-11        NaN            NaN       NaN         NaN  ...   \n",
       "2010-11-12        NaN            NaN       NaN         NaN  ...   \n",
       "2010-11-13        NaN            NaN       NaN         NaN  ...   \n",
       "2010-11-14        NaN            NaN       NaN         NaN  ...   \n",
       "2010-11-15        NaN            NaN       NaN         NaN  ...   \n",
       "2010-11-16        NaN            NaN       NaN         NaN  ...   \n",
       "2010-11-17        NaN            NaN       NaN         NaN  ...   \n",
       "2010-11-18        NaN            NaN       NaN         NaN  ...   \n",
       "2010-11-19        NaN            NaN       NaN         NaN  ...   \n",
       "2010-11-20        NaN            NaN       NaN         NaN  ...   \n",
       "2010-11-21        1.0            0.0      14.0         0.0  ...   \n",
       "2010-11-22        NaN            NaN       NaN         NaN  ...   \n",
       "2010-11-23        NaN            NaN       NaN         NaN  ...   \n",
       "2010-11-24        NaN            NaN       NaN         NaN  ...   \n",
       "2010-11-25        NaN            NaN       NaN         NaN  ...   \n",
       "2010-11-26        NaN            NaN       NaN         NaN  ...   \n",
       "\n",
       "            Floc Strength  Indian Ink  Filament index  Floc_size_small  \\\n",
       "date                                                                     \n",
       "2010-10-28            NaN         NaN             NaN              NaN   \n",
       "2010-10-29            NaN         NaN             NaN              NaN   \n",
       "2010-10-30            NaN         NaN             NaN              NaN   \n",
       "2010-10-31            NaN         NaN             NaN              NaN   \n",
       "2010-11-01            NaN         NaN             NaN              NaN   \n",
       "2010-11-02            NaN         NaN             3.0              0.0   \n",
       "2010-11-03            NaN         NaN             NaN              NaN   \n",
       "2010-11-04            NaN         NaN             NaN              NaN   \n",
       "2010-11-05            NaN         NaN             NaN              NaN   \n",
       "2010-11-06            NaN         NaN             NaN              NaN   \n",
       "2010-11-07            NaN         NaN             NaN              NaN   \n",
       "2010-11-08            NaN         NaN             NaN              NaN   \n",
       "2010-11-09            NaN         NaN             NaN              NaN   \n",
       "2010-11-10            NaN         NaN             NaN              NaN   \n",
       "2010-11-11            NaN         NaN             NaN              NaN   \n",
       "2010-11-12            NaN         NaN             NaN              NaN   \n",
       "2010-11-13            NaN         NaN             NaN              NaN   \n",
       "2010-11-14            NaN         NaN             NaN              NaN   \n",
       "2010-11-15            NaN         NaN             NaN              NaN   \n",
       "2010-11-16            NaN         NaN             NaN              NaN   \n",
       "2010-11-17            NaN         NaN             NaN              NaN   \n",
       "2010-11-18            NaN         NaN             NaN              NaN   \n",
       "2010-11-19            NaN         NaN             NaN              NaN   \n",
       "2010-11-20            NaN         NaN             NaN              NaN   \n",
       "2010-11-21            NaN         NaN             3.0              1.0   \n",
       "2010-11-22            NaN         NaN             NaN              NaN   \n",
       "2010-11-23            NaN         NaN             NaN              NaN   \n",
       "2010-11-24            NaN         NaN             NaN              NaN   \n",
       "2010-11-25            NaN         NaN             NaN              NaN   \n",
       "2010-11-26            NaN         NaN             NaN              NaN   \n",
       "\n",
       "            Floc_size_medium  Floc_size_large  Shape_close  Shape_open  \\\n",
       "date                                                                     \n",
       "2010-10-28               NaN              NaN          NaN         NaN   \n",
       "2010-10-29               NaN              NaN          NaN         NaN   \n",
       "2010-10-30               NaN              NaN          NaN         NaN   \n",
       "2010-10-31               NaN              NaN          NaN         NaN   \n",
       "2010-11-01               NaN              NaN          NaN         NaN   \n",
       "2010-11-02               1.0              1.0          1.0         1.0   \n",
       "2010-11-03               NaN              NaN          NaN         NaN   \n",
       "2010-11-04               NaN              NaN          NaN         NaN   \n",
       "2010-11-05               NaN              NaN          NaN         NaN   \n",
       "2010-11-06               NaN              NaN          NaN         NaN   \n",
       "2010-11-07               NaN              NaN          NaN         NaN   \n",
       "2010-11-08               NaN              NaN          NaN         NaN   \n",
       "2010-11-09               NaN              NaN          NaN         NaN   \n",
       "2010-11-10               NaN              NaN          NaN         NaN   \n",
       "2010-11-11               NaN              NaN          NaN         NaN   \n",
       "2010-11-12               NaN              NaN          NaN         NaN   \n",
       "2010-11-13               NaN              NaN          NaN         NaN   \n",
       "2010-11-14               NaN              NaN          NaN         NaN   \n",
       "2010-11-15               NaN              NaN          NaN         NaN   \n",
       "2010-11-16               NaN              NaN          NaN         NaN   \n",
       "2010-11-17               NaN              NaN          NaN         NaN   \n",
       "2010-11-18               NaN              NaN          NaN         NaN   \n",
       "2010-11-19               NaN              NaN          NaN         NaN   \n",
       "2010-11-20               NaN              NaN          NaN         NaN   \n",
       "2010-11-21               0.0              1.0          1.0         1.0   \n",
       "2010-11-22               NaN              NaN          NaN         NaN   \n",
       "2010-11-23               NaN              NaN          NaN         NaN   \n",
       "2010-11-24               NaN              NaN          NaN         NaN   \n",
       "2010-11-25               NaN              NaN          NaN         NaN   \n",
       "2010-11-26               NaN              NaN          NaN         NaN   \n",
       "\n",
       "            Filaments_in_floc  Free_filaments  \n",
       "date                                           \n",
       "2010-10-28                NaN             NaN  \n",
       "2010-10-29                NaN             NaN  \n",
       "2010-10-30                NaN             NaN  \n",
       "2010-10-31                NaN             NaN  \n",
       "2010-11-01                NaN             NaN  \n",
       "2010-11-02                1.0             1.0  \n",
       "2010-11-03                NaN             NaN  \n",
       "2010-11-04                NaN             NaN  \n",
       "2010-11-05                NaN             NaN  \n",
       "2010-11-06                NaN             NaN  \n",
       "2010-11-07                NaN             NaN  \n",
       "2010-11-08                NaN             NaN  \n",
       "2010-11-09                NaN             NaN  \n",
       "2010-11-10                NaN             NaN  \n",
       "2010-11-11                NaN             NaN  \n",
       "2010-11-12                NaN             NaN  \n",
       "2010-11-13                NaN             NaN  \n",
       "2010-11-14                NaN             NaN  \n",
       "2010-11-15                NaN             NaN  \n",
       "2010-11-16                NaN             NaN  \n",
       "2010-11-17                NaN             NaN  \n",
       "2010-11-18                NaN             NaN  \n",
       "2010-11-19                NaN             NaN  \n",
       "2010-11-20                NaN             NaN  \n",
       "2010-11-21                1.0             1.0  \n",
       "2010-11-22                NaN             NaN  \n",
       "2010-11-23                NaN             NaN  \n",
       "2010-11-24                NaN             NaN  \n",
       "2010-11-25                NaN             NaN  \n",
       "2010-11-26                NaN             NaN  \n",
       "\n",
       "[30 rows x 41 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model without resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 52.57it/s]\n"
     ]
    }
   ],
   "source": [
    "X, Y = km.create_join_x_y_arr(join_list, n_steps_in=7, binary=True)\n",
    "X_normalize, Y_normalize, scalers = km.normalize(X, Y)\n",
    "X_normalize = np.nan_to_num(X_normalize, nan=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10570/14439 [====================>.........] - ETA: 4s - loss: nan - binary_accuracy: 0.3222"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-5669e206f0e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m model.compile(optimizer='adam', loss='binary_crossentropy', \n\u001b[1;32m      7\u001b[0m               metrics=[keras.metrics.BinaryAccuracy(name='binary_accuracy', dtype=None, threshold=0.5)])\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mYhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/TF/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/opt/miniconda3/envs/TF/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/TF/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/TF/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/TF/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/TF/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/TF/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/miniconda3/envs/TF/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X_normalize, Y_normalize, test_size=0.10, random_state=42)\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, activation='relu', name='first_lstm', recurrent_dropout=0.1, input_shape=(Xtrain.shape[1], Xtrain.shape[2])))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', \n",
    "              metrics=[keras.metrics.BinaryAccuracy(name='binary_accuracy', dtype=None, threshold=0.5)])\n",
    "model.fit(Xtrain, ytrain, epochs=3, batch_size=10, shuffle=True)\n",
    "\n",
    "Yhat, Ytest = km.evaluate(model, Xtest, ytest, scalers, binary=True)\n",
    "y_real = Ytest.astype(int)\n",
    "threshold = threshold_for_max_f1(y_real, Yhat)\n",
    "y_predict = np.where(Yhat > threshold, 1, 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cf_matrix(y_real, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model with resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_sample(X, Y, sampler):\n",
    "    '''\n",
    "    This function over samples data X and labels Y. Because each piece of data is 2D (hence X is 3D),\n",
    "    we need to do some clever resizing since the imblearn Oversampling functions only work with a 2D X.\n",
    "    '''\n",
    "    \n",
    "    sampler = sampler(random_state=0)\n",
    "\n",
    "    orig_X_shape = X.shape\n",
    "    X_reshaped = np.reshape(X, (X.shape[0], X.shape[1]*X.shape[2]))\n",
    "    X_resampled, Y_resampled = sampler.fit_resample(X_reshaped, Y)\n",
    "    X_resampled = np.reshape(X_resampled, (X_resampled.shape[0], orig_X_shape[1], orig_X_shape[2]))\n",
    "    \n",
    "    return X_resampled, Y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 51.37it/s]\n"
     ]
    }
   ],
   "source": [
    "X, Y = km.create_join_x_y_arr(join_list, n_steps_in=7, binary=True)\n",
    "X_normalize, Y_normalize, scalers = km.normalize(X, Y)\n",
    "X_normalize = np.nan_to_num(X_normalize, nan=-1)\n",
    "# X_normalize, Y_normalize = over_sample(X_normalize, Y_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19564/19564 [==============================] - 18s 928us/step - loss: 0.5774 - binary_accuracy: 0.6036\n",
      "Epoch 2/10\n",
      "19564/19564 [==============================] - 19s 956us/step - loss: 0.4634 - binary_accuracy: 0.7051\n",
      "Epoch 3/10\n",
      "19564/19564 [==============================] - 17s 869us/step - loss: 0.4416 - binary_accuracy: 0.7367\n",
      "Epoch 4/10\n",
      "19564/19564 [==============================] - 18s 902us/step - loss: 0.4359 - binary_accuracy: 0.7518\n",
      "Epoch 5/10\n",
      "19564/19564 [==============================] - 18s 898us/step - loss: 0.4289 - binary_accuracy: 0.7607\n",
      "Epoch 6/10\n",
      "19564/19564 [==============================] - 19s 978us/step - loss: 0.4266 - binary_accuracy: 0.7668\n",
      "Epoch 7/10\n",
      "19564/19564 [==============================] - 18s 920us/step - loss: 0.4210 - binary_accuracy: 0.7713\n",
      "Epoch 8/10\n",
      "19564/19564 [==============================] - 18s 913us/step - loss: 0.4183 - binary_accuracy: 0.7747\n",
      "Epoch 9/10\n",
      "19564/19564 [==============================] - 17s 875us/step - loss: 0.4181 - binary_accuracy: 0.7779\n",
      "Epoch 10/10\n",
      "19564/19564 [==============================] - 17s 870us/step - loss: 0.4139 - binary_accuracy: 0.7801\n",
      "(0.7993769470404984, 0.814453125, 0.6475155279503105, 0.7214532871972318)\n",
      "Epoch 1/10\n",
      "19564/19564 [==============================] - 19s 977us/step - loss: 0.5758 - binary_accuracy: 0.6058\n",
      "Epoch 2/10\n",
      "19564/19564 [==============================] - 17s 869us/step - loss: 0.4552 - binary_accuracy: 0.7084\n",
      "Epoch 3/10\n",
      "19564/19564 [==============================] - 17s 862us/step - loss: 0.4305 - binary_accuracy: 0.7414\n",
      "Epoch 4/10\n",
      "19564/19564 [==============================] - 17s 888us/step - loss: 0.4182 - binary_accuracy: 0.7574\n",
      "Epoch 5/10\n",
      "19564/19564 [==============================] - 17s 880us/step - loss: 0.4166 - binary_accuracy: 0.7674\n",
      "Epoch 6/10\n",
      "19564/19564 [==============================] - 17s 866us/step - loss: 0.4146 - binary_accuracy: 0.7738\n",
      "Epoch 7/10\n",
      "19564/19564 [==============================] - 17s 860us/step - loss: 0.4092 - binary_accuracy: 0.7784\n",
      "Epoch 8/10\n",
      "19564/19564 [==============================] - 18s 931us/step - loss: 0.4045 - binary_accuracy: 0.7826\n",
      "Epoch 9/10\n",
      "19564/19564 [==============================] - 17s 876us/step - loss: 0.4071 - binary_accuracy: 0.7856\n",
      "Epoch 10/10\n",
      "19564/19564 [==============================] - 17s 863us/step - loss: 0.4031 - binary_accuracy: 0.7880\n",
      "(0.8274143302180685, 0.712890625, 0.7373737373737373, 0.7249255213505461)\n",
      "Epoch 1/10\n",
      "18612/18612 [==============================] - 19s 1ms/step - loss: 0.6348 - binary_accuracy: 0.5614\n",
      "Epoch 2/10\n",
      "18612/18612 [==============================] - 17s 907us/step - loss: 0.5026 - binary_accuracy: 0.6575\n",
      "Epoch 3/10\n",
      "18612/18612 [==============================] - 17s 916us/step - loss: 0.4702 - binary_accuracy: 0.6983\n",
      "Epoch 4/10\n",
      "18612/18612 [==============================] - 18s 970us/step - loss: 0.4647 - binary_accuracy: 0.7179\n",
      "Epoch 5/10\n",
      "18612/18612 [==============================] - 15s 827us/step - loss: 0.4585 - binary_accuracy: 0.7302\n",
      "Epoch 6/10\n",
      "18612/18612 [==============================] - 16s 833us/step - loss: 0.4513 - binary_accuracy: 0.7385\n",
      "Epoch 7/10\n",
      "18612/18612 [==============================] - 16s 841us/step - loss: 0.4498 - binary_accuracy: 0.7447\n",
      "Epoch 8/10\n",
      "18612/18612 [==============================] - 16s 844us/step - loss: 0.4471 - binary_accuracy: 0.7499\n",
      "Epoch 9/10\n",
      "18612/18612 [==============================] - 16s 848us/step - loss: 0.4440 - binary_accuracy: 0.7536\n",
      "Epoch 10/10\n",
      "18612/18612 [==============================] - 16s 847us/step - loss: 0.4389 - binary_accuracy: 0.7570\n",
      "(0.821183800623053, 0.7421875, 0.7102803738317757, 0.7258834765998088)\n",
      "Epoch 1/10\n",
      "19564/19564 [==============================] - 19s 996us/step - loss: 0.6235 - binary_accuracy: 0.5629\n",
      "Epoch 2/10\n",
      "19564/19564 [==============================] - 17s 870us/step - loss: 0.4963 - binary_accuracy: 0.6643\n",
      "Epoch 3/10\n",
      "19564/19564 [==============================] - 17s 876us/step - loss: 0.4739 - binary_accuracy: 0.7042\n",
      "Epoch 4/10\n",
      "19564/19564 [==============================] - 17s 871us/step - loss: 0.4615 - binary_accuracy: 0.7242\n",
      "Epoch 5/10\n",
      "19564/19564 [==============================] - 17s 879us/step - loss: 0.4555 - binary_accuracy: 0.7350\n",
      "Epoch 6/10\n",
      "19564/19564 [==============================] - 18s 917us/step - loss: 0.4508 - binary_accuracy: 0.7428\n",
      "Epoch 7/10\n",
      "19564/19564 [==============================] - 18s 930us/step - loss: 0.4470 - binary_accuracy: 0.7490\n",
      "Epoch 8/10\n",
      "19564/19564 [==============================] - 18s 920us/step - loss: 0.4429 - binary_accuracy: 0.7542\n",
      "Epoch 9/10\n",
      "19564/19564 [==============================] - 18s 930us/step - loss: 0.4411 - binary_accuracy: 0.7580\n",
      "Epoch 10/10\n",
      "19564/19564 [==============================] - 19s 985us/step - loss: 0.4359 - binary_accuracy: 0.7614\n",
      "(0.8249221183800624, 0.716796875, 0.7296222664015904, 0.7231527093596058)\n",
      "Epoch 1/10\n",
      "19564/19564 [==============================] - 19s 974us/step - loss: 0.5942 - binary_accuracy: 0.5965\n",
      "Epoch 2/10\n",
      "19564/19564 [==============================] - 19s 948us/step - loss: 0.4691 - binary_accuracy: 0.6973\n",
      "Epoch 3/10\n",
      "19564/19564 [==============================] - 17s 859us/step - loss: 0.4373 - binary_accuracy: 0.7335\n",
      "Epoch 4/10\n",
      "19564/19564 [==============================] - 18s 902us/step - loss: 0.4327 - binary_accuracy: 0.7506\n",
      "Epoch 5/10\n",
      "19564/19564 [==============================] - 16s 840us/step - loss: 0.4302 - binary_accuracy: 0.7609\n",
      "Epoch 6/10\n",
      "19564/19564 [==============================] - 18s 939us/step - loss: 0.4212 - binary_accuracy: 0.7679\n",
      "Epoch 7/10\n",
      "19564/19564 [==============================] - 22s 1ms/step - loss: 0.4180 - binary_accuracy: 0.7736\n",
      "Epoch 8/10\n",
      "19564/19564 [==============================] - 17s 887us/step - loss: 0.4157 - binary_accuracy: 0.7778\n",
      "Epoch 9/10\n",
      "19564/19564 [==============================] - 17s 858us/step - loss: 0.4138 - binary_accuracy: 0.7810\n",
      "Epoch 10/10\n",
      "19564/19564 [==============================] - 18s 930us/step - loss: 0.4141 - binary_accuracy: 0.7837\n",
      "(0.8105919003115265, 0.767578125, 0.6799307958477508, 0.7211009174311925)\n"
     ]
    }
   ],
   "source": [
    "samplers = [RandomOverSampler, SMOTE, ADASYN, BorderlineSMOTE, SVMSMOTE]\n",
    "results_list = []\n",
    "for sampler in samplers:\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X_normalize, Y_normalize, test_size=0.10, random_state=42)\n",
    "    Xtrain, ytrain = over_sample(Xtrain, ytrain, sampler)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, activation='relu', name='first_lstm', recurrent_dropout=0.1, input_shape=(Xtrain.shape[1], Xtrain.shape[2])))\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', \n",
    "                  metrics=[keras.metrics.BinaryAccuracy(name='binary_accuracy', dtype=None, threshold=0.5)])\n",
    "    model.fit(Xtrain, ytrain, epochs=10, batch_size=10, shuffle=True)\n",
    "\n",
    "    Yhat, Ytest = km.evaluate(model, Xtest, ytest, scalers, binary=True)\n",
    "    y_real = Ytest.astype(int)\n",
    "    threshold = threshold_for_max_f1(y_real, Yhat)\n",
    "    y_predict = np.where(Yhat > threshold, 1, 0).astype(int)\n",
    "    \n",
    "    print(km.results(y_real, y_predict))\n",
    "    results_list.append(km.results(y_real, y_predict))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8087227414330218, 0.76171875, 0.6782608695652174, 0.717571297148114) \n",
      "\n",
      "Confusion matrix, without normalization\n",
      "[[390 122]\n",
      " [185 908]]\n"
     ]
    }
   ],
   "source": [
    "plot_cf_matrix(y_real, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 70.93it/s]\n"
     ]
    }
   ],
   "source": [
    "X_normalize, Y_normalize, scalers = km.normalize(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normalize = np.nan_to_num(X_normalize, nan=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "14439/14439 [==============================] - 15s 1ms/step - loss: 0.5811 - binary_accuracy: 0.6827\n",
      "Epoch 2/3\n",
      "14439/14439 [==============================] - 13s 918us/step - loss: 0.4502 - binary_accuracy: 0.7281\n",
      "Epoch 3/3\n",
      "14439/14439 [==============================] - 12s 831us/step - loss: 0.4287 - binary_accuracy: 0.7552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fc3ebd9b490>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X_normalize, Y_normalize, test_size=0.10, random_state=42)\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, activation='relu', name='first_lstm', recurrent_dropout=0.1, input_shape=(Xtrain.shape[1], Xtrain.shape[2])))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', \n",
    "              metrics=[keras.metrics.BinaryAccuracy(name='binary_accuracy', dtype=None, threshold=0.5)])\n",
    "model.fit(Xtrain, ytrain, epochs=3, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yhat, Ytest = km.evaluate(model, Xtest, ytest, scalers, binary=True)\n",
    "y_real = Ytest.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = threshold_for_max_f1(y_real, Yhat)\n",
    "y_predict = np.where(Yhat > threshold, 1, 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8043613707165109, 0.771484375, 0.6672297297297297, 0.7155797101449275) \n",
      "\n",
      "Confusion matrix, without normalization\n",
      "[[395 117]\n",
      " [197 896]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_cf_matrix(y_real, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(Ytest, Yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 71.03it/s]\n"
     ]
    }
   ],
   "source": [
    "X_normalize, Y_normalize, scalers = km.normalize(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8794262494281794"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normalize = np.nan_to_num(X_normalize, nan=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'ROC curve')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAdHUlEQVR4nO3de7QdZX3/8feHQOSWBCGgMeGYgBEMi6tHAliUi2BAaOSncq1UW1ekApZl9QcFfupPKdVCraSiMWKMUEKUe6SRiK0QCySES8iNQlMCyYHw41ouAYXA9/fHzIZhZ5995pyzZ++z93xea5119sw8e+Y7J1nzned5Zp5HEYGZmZXXZq0OwMzMWsuJwMys5JwIzMxKzonAzKzknAjMzErOicDMrOScCMzMSs6JwDqOpEckvSLpJUlPSJotaduqMgdJ+ndJL0p6XtKvJE2qKjNS0vclrU33tTpdHt3cMzIrlhOBdapjI2JbYB9gX+BvKxskHQj8BrgReA8wAbgfuF3SLmmZ4cC/AXsAU4CRwEHAM8D+RQUtafOi9m3WGycC62gR8QSwgCQhVPwDcHlEXBIRL0bEsxFxPrAI+GZa5lSgCzguIlZFxBsR8WREfDsi5tc6lqQ9JN0i6VlJ/0/Suen62ZIuyJQ7RFJPZvkRSWdLWgZskHS+pGuq9n2JpOnp51GSfippvaTHJF0gadjg/lJWZk4E1tEkjQOOAlany1uT3NlfXaP4L4Ej0s8fA26OiJdyHmcE8FvgZpJaxvtIahR5nQR8AtgOuAI4WtLIdN/DgOOBOWnZnwMb02PsCxwJfKEfxzJ7GycC61Q3SHoRWAc8CXwjXb89yf/79TW+sx6otP/v0EuZ3hwDPBER/xgRf0hrGov78f3pEbEuIl6JiEeBe4FPptsOA16OiEWS3kWS2M6KiA0R8STwT8CJ/TiW2ds4EVin+mREjAAOAXbnrQv8c8AbwJga3xkDPJ1+fqaXMr3ZGfjvAUWaWFe1PIeklgBwMm/VBt4LbAGsl/Q/kv4H+DGw0yCObSXnRGAdLSJuA2YDF6fLG4A7gc/UKH48bzXn/Bb4uKRtch5qHbBrL9s2AFtnlt9dK9Sq5auBQ9KmreN4KxGsA/4IjI6I7dKfkRGxR844zTbhRGBl8H3gCEn7pMvnAH8u6cuSRkh6Z9qZeyDwf9MyV5BcdK+VtLukzSTtIOlcSUfXOMZNwLslnSXpHel+J6fblpK0+W8v6d3AWX0FHBFPAbcCPwPWRMQD6fr1JE88/WP6eOtmknaV9NF+/k3M3uREYB0vvaheDvyfdPk/gI8D/4ukH+BRkk7XP4mI/0rL/JGkw/g/gVuAF4C7SJqYNmn7j4gXSTqajwWeAP4LODTdfAXJ46mPkFzEf5Ez9DlpDHOq1p8KDAdWkTR1XUP/mrHM3kaemMbMrNxcIzAzKzknAjOzknMiMDMrOScCM7OSa7sBrkaPHh3jx49vdRhmZm3lnnvueToidqy1re0Swfjx47n77rtbHYaZWVuR9Ghv29w0ZGZWck4EZmYl50RgZlZyTgRmZiXnRGBmVnKFJQJJsyQ9KWlFL9slaXo6IfgySfsVFYuZmfWuyBrBbJJJv3tzFDAx/ZkG/KjAWMzMrBeFvUcQEQslja9TZCrJBOIBLJK0naQx6XjrZmZtbc7itdy49LGG7nPSe0byjWMbPwdRK18oG8vbp+frSddtkggkTSOpNdDV1dWU4MysMxRxQc5j8ZpnAZg8YfumH7u/WpkIVGNdzckRImImMBOgu7vbEyiYdagiLtqtuiBPnrA9U/cZy8mTh/7NaysTQQ/JhN8V44DHWxSLmfWimXfURVy02+mC3CqtTATzgDMkzQUmA8+7f8Cs8QZ7IW/mHbUv2q1RWCKQdBVwCDBaUg/wDWALgIiYAcwHjgZWAy8Dny8qFrMy6O2CP9gLuS/Ona/Ip4ZO6mN7AKcXdXyzTtXfC74v5NaXthuG2qwT9af5xhd8azQnArMm6OtC35/mG1/wrdGcCMwarNZFv68LvS/u1kpOBGYDUO8Ov9ZF3xd6G8qcCMxyqL7w17vD90Xf2o0TgVlG3idyfLG3TuJEYKWXvfj7iRwrIycCK408d/u+4FsZORFYR/PdvlnfnAisY/T12KYv+Ga1ORFYR5izeC3nXr8c8GObZv3lRGBtrVILqNz5X3jcnr7om/WTE4ENWXnG38k2/fjO32xgnAhsyKm+y683/o4TgNngORHYkFLd1u+LvFnxnAisZeo95eO2frPmcSKwpsg7IqdrAWbN50RgharX3u+LvtnQ4ERgDdfb27y+6JsNTU4ENmj1hmh2AjAb+pwIbFBqvdHri79Ze3EisH6r1fTjp3zM2pcTgfVLdQ3Ad/9m7c+JwPqlUhNwDcCsczgRWJ+yTUGr1r/A5AnbOwmYdZDNWh2ADW2VpqBKX8CkMSOZus/YFkdlZo3kGoH1Ktsf4KYgs87lRGCAx/0xKzMnAvPsXmYl50RQUn4XwMwqnAhK6salj7Fq/QtMGjPSd/5mJVdoIpA0BbgEGAZcFhHfqdo+CvgXoCuN5eKI+FmRMdlbJo0ZyS++eGCrwzCzFissEUgaBlwKHAH0AEskzYuIVZlipwOrIuJYSTsCD0q6MiJeLSquMqt+H2DSmJEtjsjMhoIiawT7A6sj4mEASXOBqUA2EQQwQpKAbYFngY0FxlQ6vQ0J7fcBzKyiyEQwFliXWe4BJleV+QEwD3gcGAGcEBFvVO9I0jRgGkBXl9ux8/K4QGaWR5GJQDXWRdXyx4GlwGHArsAtkn4fES+87UsRM4GZAN3d3dX7sBr8MpiZ5VXkEBM9wM6Z5XEkd/5Znweui8RqYA2we4ExlYKTgJn1R5GJYAkwUdIEScOBE0magbLWAocDSHoXsBvwcIExdTwnATPrr8KahiJio6QzgAUkj4/OioiVkk5Lt88Avg3MlrScpCnp7Ih4uqiYysDDRJtZfxX6HkFEzAfmV62bkfn8OHBkkTGUyZzFa1m85lkPE21m/eJhqDtIpTbgx0LNrD+cCDqEawNmNlBOBB0g20Hs2oCZ9ZcTQZvzU0JmNlhOBG3OTwmZ2WB5GOo2VRlDyJPJm9lgORG0kd4GkHO/gJkNhhNBG/FkMmZWBCeCNpBtBvJkMmbWaE4EQ1glAbgZyMyKlDsRSNomIjYUGYwleksAbgYysyL0mQgkHQRcRjKDWJekvYEvRsSXig6urLJPAzkBmFnR8tQI/olkApl5ABFxv6SPFBqVuS/AzJom1wtlEbGuatXrBcRiZmYtkCcRrEubh0LScElfBR4oOK7SqgweZ2bWLHmahk4DLiGZjL4H+A3g/oEGq+4g9tNBZtYseRLBbhFxSnaFpA8DtxcTUrn4CSEza7U8ieCfgf1yrLN+yo4c6gRgZq3SayKQdCBwELCjpK9kNo0kmYPYBqi6FuCRQ82slerVCIaTvDuwOTAis/4F4NNFBtXJXAsws6Gm10QQEbcBt0maHRGPNjGmjuRagJkNVXn6CF6WdBGwB7BlZWVEHFZYVB3Ibwub2VCVJxFcCfwCOIbkUdI/B54qMqhOk51Y3m8Lm9lQk+eFsh0i4qfAaxFxW0T8BXBAwXF1lMpkMn43wMyGojw1gtfS3+slfQJ4HBhXXEidydNJmtlQlScRXCBpFPA3JO8PjATOKjIoMzNrnj4TQUTclH58HjgU3nyz2MzMOkC9F8qGAceTjDF0c0SskHQMcC6wFbBvc0I0M7Mi1asR/BTYGbgLmC7pUeBA4JyIuKEJsXWE7BNDZmZDUb1E0A3sFRFvSNoSeBp4X0Q80ZzQOoOfGDKzoa7e46OvRsQbABHxB+Ch/iYBSVMkPShptaRzeilziKSlklZKuq0/+28XfmLIzIayejWC3SUtSz8L2DVdFhARsVe9Had9DJcCR5DMY7BE0ryIWJUpsx3wQ2BKRKyVtNPAT8XMzAaiXiL4wCD3vT+wOiIeBpA0F5gKrMqUORm4LiLWAkTEk4M8ZstVxhSqWLX+BSaNGdnCiMzM6qs36NxgB5obC2TnOu4BJleVeT+whaRbSUY4vSQiLq/ekaRpwDSArq6h3cRSGVOocvGfNGak+wfMbEjL80LZQKnGuqhx/A8Ch5M8knqnpEUR8dDbvhQxE5gJ0N3dXb2PIcNjCplZOyoyEfSQPH5aMY5keIrqMk9HxAZgg6SFwN7AQ7QhPyFkZu0oz6BzSNpK0m793PcSYKKkCZKGAycC86rK3AgcLGlzSVuTNB090M/jDCl+QsjM2k2fiUDSscBS4OZ0eR9J1Rf0TUTERuAMYAHJxf2XEbFS0mmSTkvLPJDudxnJi2uXRcSKAZ6LmZkNQJ6moW+SPAF0K0BELJU0Ps/OI2I+ML9q3Yyq5YuAi/LsbyjKPiXkJ4TMrB3laRraGBHPFx5Jm6o8JQR+QsjM2lOeGsEKSScDwyRNBL4M3FFsWO3BTwmZWSfIUyM4k2S+4j8Cc0iGoz6rwJjahp8SMrNOkKdGsFtEnAecV3Qw7SRbG/BTQmbWzvIkgu9JGgNcDcyNiJUFxzRkZTuGF695FnBtwMzaX59NQxFxKHAI8BQwU9JySecXHdhQlO0Ynjxhey48bk/XBsys7eV6szgdfnq6pN8B/xv4OnBBkYENNe4YNrNOleeFsg9I+qakFcAPSJ4YGld4ZEPInMVrOff65YCbgsys8+SpEfwMuAo4MiKqxwoqhUq/gJuCzKwT9ZkIIuKAZgQy1PnpIDPrVL02DUn6Zfp7uaRlmZ/lmZnLOl6lb8DMrFPVqxH8dfr7mGYEMhS5b8DMyqDXGkFErE8/fikiHs3+AF9qTnitk00C7hsws06WZ4iJI2qsO6rRgQw17iA2s7LotWlI0l+R3PnvUtUnMAK4vejAhgJ3EJtZGdTrI5gD/Br4e+CczPoXI6Kje0+zL4+ZmXW6eokgIuIRSadXb5C0facmA3cQm1nZ9FUjOAa4BwhAmW0B7FJgXC3jvgEzK5teE0FEHJP+ntC8cFrLQ0ubWRnlGWvow5K2ST//maTvSeq4q6SbhMysrPI8Pvoj4GVJe5OMPPoocEWhUbWAm4TMrKzyTl4fwFTgkoi4hOQR0o7hJiEzK7M8o4++KOlvgc8CB0saBmxRbFjN5bmHzazM8tQITiCZuP4v0glqxgIXFRpVC7g2YGZllWeqyieAK4FRko4B/hARlxcemZmZNUWep4aOB+4CPgMcDyyW9OmiAzMzs+bI00dwHvChiHgSQNKOwG+Ba4oMzMzMmiNPH8FmlSSQeibn98zMrA3kqRHcLGkBybzFkHQezy8uJDMza6Y8ncVfA34M7AXsDcyMiLOLDqxZPBWlmZVdvfkIJgIXA7sCy4GvRsRjzQqsWfwOgZmVXb0awSzgJuBTJCOQ/nN/dy5piqQHJa2WdE6dch+S9HqrnkbyOwRmVmb1+ghGRMRP0s8PSrq3PztO30C+lGSqyx5giaR5EbGqRrnvAgv6s38zM2uMeolgS0n78tY8BFtllyOir8SwP7A6Ih4GkDSXZLyiVVXlzgSuBT7Uz9jNzKwB6iWC9cD3MstPZJYDOKyPfY8F1mWWe4DJ2QKSxgLHpfvqNRFImgZMA+jqalwTjqekNDOrPzHNoYPct2qsi6rl7wNnR8TrUq3ib8YyE5gJ0N3dXb2PAXNHsZlZvvcIBqoH2DmzPA54vKpMNzA3TQKjgaMlbYyIGwqM623cUWxmZVdkIlgCTJQ0AXgMOBE4OVsgOw2mpNnATc1MAmZmVmAiiIiNks4geRpoGDArIlZKOi3dPqOoY5uZWX59JgIl7TanALtExLfS+YrfHRF39fXdiJhP1XAUvSWAiPhcrojNzKyh8gwe90PgQOCkdPlFkvcDzMysA+RpGpocEftJug8gIp6TNLzguMzMrEny1AheS9/+DXhzPoI3Co3KzMyaJk8imA5cD+wk6e+A/wAuLDQqMzNrmj6bhiLiSkn3AIeTvCT2yYh4oPDIzMysKfI8NdQFvAz8KrsuItYWGZiZmTVHns7ifyXpHxCwJTABeBDYo8C4zMysSfI0De2ZXZa0H/DFwiIyM7Om6vck9Onw0x4y2sysQ+TpI/hKZnEzYD/gqcIiahIPQW1mlsjTRzAi83kjSZ/BtcWE0xxzFq/l3OuXAx6C2sysbiJIXyTbNiK+1qR4mqIyD8GFx+3pIajNrPR67SOQtHlEvE7SFNRxPA+BmVmiXo3gLpIksFTSPOBqYENlY0RcV3BsZmbWBHn6CLYHniGZV7jyPkEATgRmZh2gXiLYKX1iaAVvJYCKhs0bbGZmrVUvEQwDtiXfJPRmZtam6iWC9RHxraZF0iR+f8DM7O3qvVlcqybQ9iqPjvr9ATOzRL1EcHjTomgyPzpqZvaWXhNBRDzbzEDMzKw1+j3onJmZdRYnAjOzknMiMDMrOScCM7OScyIwMys5JwIzs5JzIjAzKzknAjOzknMiMDMruUITgaQpkh6UtFrSOTW2nyJpWfpzh6S9i4zHzMw2VVgiSOc7vhQ4CpgEnCRpUlWxNcBHI2Iv4NvAzKLiMTOz2oqsEewPrI6IhyPiVWAuMDVbICLuiIjn0sVFwLgC4zEzsxqKTARjgXWZ5Z50XW/+Evh1rQ2Spkm6W9LdTz31VANDNDOzIhNB7pnNJB1KkgjOrrU9ImZGRHdEdO+4444NDNHMzPJMXj9QPcDOmeVxwOPVhSTtBVwGHBURzxQYj5mZ1VBkjWAJMFHSBEnDgROBedkCkrqA64DPRsRDBcZiZma9KKxGEBEbJZ0BLACGAbMiYqWk09LtM4CvAzsAP5QEsDEiuouKyczMNlVk0xARMR+YX7VuRubzF4AvFBlDlieuNzPbVKneLPbE9WZmmypVIgBPXG9mVq10icDMzN7OicDMrOScCMzMSs6JwMys5JwIzMxKzonAzKzknAjMzErOicDMrOScCMzMSs6JwMys5JwIzMxKzonAzKzknAjMzErOicDMrOScCMzMSs6JwMys5JwIzMxKzonAzKzknAjMzErOicDMrOScCMzMSs6JwMys5EqTCOYsXsviNc+2OgwzsyGnNIngxqWPATB1n7EtjsTMbGgpTSIAmDxhe06e3NXqMMzMhpRSJQIzM9uUE4GZWck5EZiZlZwTgZlZyRWaCCRNkfSgpNWSzqmxXZKmp9uXSdqvyHjMzGxThSUCScOAS4GjgEnASZImVRU7CpiY/kwDflRUPGZmVluRNYL9gdUR8XBEvArMBaZWlZkKXB6JRcB2ksYUGJOZmVXZvMB9jwXWZZZ7gMk5yowF1mcLSZpGUmOgq2tg7wFMes/IAX3PzKzTFZkIVGNdDKAMETETmAnQ3d29yfY8vnHsHgP5mplZxyuyaagH2DmzPA54fABlzMysQEUmgiXAREkTJA0HTgTmVZWZB5yaPj10APB8RKyv3pGZmRWnsKahiNgo6QxgATAMmBURKyWdlm6fAcwHjgZWAy8Dny8qHjMzq63IPgIiYj7JxT67bkbmcwCnFxmDmZnV5zeLzcxKzonAzKzknAjMzErOicDMrOSU9Ne2D0lPAY8O8OujgacbGE478DmXg8+5HAZzzu+NiB1rbWi7RDAYku6OiO5Wx9FMPudy8DmXQ1Hn7KYhM7OScyIwMyu5siWCma0OoAV8zuXgcy6HQs65VH0EZma2qbLVCMzMrIoTgZlZyXVkIpA0RdKDklZLOqfGdkmanm5fJmm/VsTZSDnO+ZT0XJdJukPS3q2Is5H6OudMuQ9Jel3Sp5sZXxHynLOkQyQtlbRS0m3NjrHRcvzfHiXpV5LuT8+5rUcxljRL0pOSVvSyvfHXr4joqB+SIa//G9gFGA7cD0yqKnM08GuSGdIOABa3Ou4mnPNBwDvTz0eV4Zwz5f6dZBTcT7c67ib8O28HrAK60uWdWh13E875XOC76ecdgWeB4a2OfRDn/BFgP2BFL9sbfv3qxBrB/sDqiHg4Il4F5gJTq8pMBS6PxCJgO0ljmh1oA/V5zhFxR0Q8ly4uIpkNrp3l+XcGOBO4FniymcEVJM85nwxcFxFrASKi3c87zzkHMEKSgG1JEsHG5obZOBGxkOQcetPw61cnJoKxwLrMck+6rr9l2kl/z+cvSe4o2lmf5yxpLHAcMIPOkOff+f3AOyXdKukeSac2Lbpi5DnnHwAfIJnmdjnw1xHxRnPCa4mGX78KnZimRVRjXfUzsnnKtJPc5yPpUJJE8CeFRlS8POf8feDsiHg9uVlse3nOeXPgg8DhwFbAnZIWRcRDRQdXkDzn/HFgKXAYsCtwi6TfR8QLBcfWKg2/fnViIugBds4sjyO5U+hvmXaS63wk7QVcBhwVEc80Kbai5DnnbmBumgRGA0dL2hgRNzQlwsbL+3/76YjYAGyQtBDYG2jXRJDnnD8PfCeSBvTVktYAuwN3NSfEpmv49asTm4aWABMlTZA0HDgRmFdVZh5watr7fgDwfESsb3agDdTnOUvqAq4DPtvGd4dZfZ5zREyIiPERMR64BvhSGycByPd/+0bgYEmbS9oamAw80OQ4GynPOa8lqQEh6V3AbsDDTY2yuRp+/eq4GkFEbJR0BrCA5ImDWRGxUtJp6fYZJE+QHA2sBl4muaNoWznP+evADsAP0zvkjdHGIzfmPOeOkuecI+IBSTcDy4A3gMsiouZjiO0g57/zt4HZkpaTNJucHRFtOzy1pKuAQ4DRknqAbwBbQHHXLw8xYWZWcp3YNGRmZv3gRGBmVnJOBGZmJedEYGZWck4EZmYl50RgQ1I6WujSzM/4OmVfasDxZktakx7rXkkHDmAfl0malH4+t2rbHYONMd1P5e+yIh1xc7s+yu8j6ehGHNs6lx8ftSFJ0ksRsW2jy9bZx2zgpoi4RtKRwMURsdcg9jfomPrar6SfAw9FxN/VKf85oDsizmh0LNY5XCOwtiBpW0n/lt6tL5e0yUijksZIWpi5Yz44XX+kpDvT714tqa8L9ELgfel3v5Lua4Wks9J120j613T8+xWSTkjX3yqpW9J3gK3SOK5Mt72U/v5F9g49rYl8StIwSRdJWqJkjPkv5viz3Ek62Jik/ZXMM3Ff+nu39E3cbwEnpLGckMY+Kz3OfbX+jlZCrR572z/+qfUDvE4ykNhS4HqSt+BHpttGk7xVWanRvpT+/hvgvPTzMGBEWnYhsE26/mzg6zWON5t0vgLgM8BiksHblgPbkAxvvBLYF/gU8JPMd0elv28luft+M6ZMmUqMxwE/Tz8PJxlFcitgGnB+uv4dwN3AhBpxvpQ5v6uBKenySGDz9PPHgGvTz58DfpD5/oXAn6WftyMZg2ibVv97+6e1Px03xIR1jFciYp/KgqQtgAslfYRk6ISxwLuAJzLfWQLMSsveEBFLJX0UmATcng6tMZzkTrqWiySdDzxFMkLr4cD1kQzghqTrgIOBm4GLJX2XpDnp9/04r18D0yW9A5gCLIyIV9LmqL301ixqo4CJwJqq728laSkwHrgHuCVT/ueSJpKMRLlFL8c/EvhTSV9Nl7cEumjv8YhskJwIrF2cQjL71Acj4jVJj5BcxN4UEQvTRPEJ4ApJFwHPAbdExEk5jvG1iLimsiDpY7UKRcRDkj5IMt7L30v6TUR8K89JRMQfJN1KMnTyCcBVlcMBZ0bEgj528UpE7CNpFHATcDownWS8nd9FxHFpx/qtvXxfwKci4sE88Vo5uI/A2sUo4Mk0CRwKvLe6gKT3pmV+AvyUZLq/RcCHJVXa/LeW9P6cx1wIfDL9zjYkzTq/l/Qe4OWI+Bfg4vQ41V5Laya1zCUZKOxgksHUSH//VeU7kt6fHrOmiHge+DLw1fQ7o4DH0s2fyxR9kaSJrGIBcKbS6pGkfXs7hpWHE4G1iyuBbkl3k9QO/rNGmUOApZLuI2nHvyQiniK5MF4laRlJYtg9zwEj4l6SvoO7SPoMLouI+4A9gbvSJprzgAtqfH0msKzSWVzlNyTz0v42kukXIZknYhVwr5JJy39MHzX2NJb7SYZm/geS2sntJP0HFb8DJlU6i0lqDluksa1Il63k/PiomVnJuUZgZlZyTgRmZiXnRGBmVnJOBGZmJedEYGZWck4EZmYl50RgZlZy/x9xBRKULcYH6QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = {1: 'Simple LSTM',\n",
    "               2: 'Stacked LSTM',\n",
    "               3: 'Bidirectional LSTM',\n",
    "               4: 'CNN',\n",
    "               5: 'CNN LSTM',\n",
    "               6: 'LSTM Autoencoder',\n",
    "               7: 'Deep CNN',\n",
    "               8: 'GRU',\n",
    "               9: 'GRU CNN'}\n",
    "\n",
    "def plot_graphs_metrics(model, results_list, steps_in, steps_out):\n",
    "    model_name = model_names[model]\n",
    "    \n",
    "    #this block of code is because some models (like 6) require steps_in start at 3 instead of 1\n",
    "    shift_vals = {1: 1,\n",
    "                  3: 1,\n",
    "                  6: 3,\n",
    "                  9: 2}\n",
    "    shift_val = shift_vals[model]\n",
    "    \n",
    "    #plot graph of a metric result for all n_step_in and n_step_out values\n",
    "    x=list(range(1, steps_out))\n",
    "    label = ['accuracy', 'TNR', 'NPV', 'f1']\n",
    "    for z in range(4):\n",
    "        for i in range(steps_in-shift_val):\n",
    "            y=[]\n",
    "            for j in range(steps_out-1):\n",
    "                y.append(results_list[i*(steps_out-1):i*(steps_out-1) + (steps_out-1)][j][z])\n",
    "            plt.plot(x, y, label=f'n_steps_in={i+shift_val}')\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        plt.xlabel(\"n_steps_out\")\n",
    "        plt.ylabel(label[z])\n",
    "        plt.title(model_name + \", 3 layers (50,25,1),\\n name='first_lstm', recurrent_dropout=0.1 \\n optimizer='adam', loss='binary_crossentropy' \")\n",
    "        plt.savefig(f\"figures/{model_name} {label[z]}.png\", bbox_inches=\"tight\")\n",
    "        plt.close()    \n",
    "    \n",
    "    #plot graph of all metric results for a n_step_in value\n",
    "    x=list(range(1, steps_out))\n",
    "    label = ['accuracy', 'TNR', 'NPV', 'f1']\n",
    "    for z in range(steps_in-shift_val):\n",
    "        for i in range(4):\n",
    "            y=[]\n",
    "            for j in range(steps_out-1):\n",
    "                y.append(results_list[z*(steps_out-1):z*(steps_out-1)+(steps_out-1)][j][i])\n",
    "            plt.plot(x, y, label=label[i])\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        plt.xlabel(\"n_steps_out\")\n",
    "        plt.ylabel('Metric value')\n",
    "        plt.title(f\"{model_name}, 3 layers (50,25,1),\\n name='first_lstm', recurrent_dropout=0.1 \\n optimizer='adam', loss='binary_crossentropy' \\n n_steps_in={z+shift_val} \")\n",
    "        plt.savefig(f\"figures/{model_name} n_steps_in={z+shift_val}.png\", bbox_inches=\"tight\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model type 1\n",
    "def train_SIMPLE_LSTM_model(epochs, steps_in, steps_out):\n",
    "    results_list = []\n",
    "    for i in range(1, steps_in):\n",
    "        for j in range(1, steps_out):\n",
    "            X, Y = km.create_join_x_y_arr(reactor_list, n_steps_in=i, n_steps_out = j, binary=True)\n",
    "            X_normalize, Y_normalize, scalers = km.normalize(X, Y)\n",
    "            X_normalize = np.nan_to_num(X_normalize, nan=-1)\n",
    "            Xtrain, Xtest, ytrain, ytest = train_test_split(X_normalize, Y_normalize, test_size=0.20, random_state=42)\n",
    "\n",
    "            model = Sequential()\n",
    "            model.add(LSTM(units=50, activation='relu', name='first_lstm', recurrent_dropout=0.1, input_shape=(Xtrain.shape[1], Xtrain.shape[2])))\n",
    "            model.add(Dense(25, activation='relu'))\n",
    "            model.add(Dense(1, activation=\"sigmoid\"))\n",
    "            \n",
    "            model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy')\n",
    "            model.fit(Xtrain, ytrain, epochs=epochs, batch_size=10, shuffle=True)\n",
    "            \n",
    "            Yhat, Ytest = km.evaluate(model, Xtest, ytest, scalers, binary=True)\n",
    "            y_real = Ytest.astype(int)\n",
    "            threshold = threshold_for_max_f1(y_real, Yhat)\n",
    "            y_predict = np.where(Yhat > threshold, 1, 0).astype(int)\n",
    "            results_list.append(km.results(y_real, y_predict))\n",
    "    return results_list\n",
    "\n",
    "###Just need to fill out the three functions for below. All other infrastructure is handled.###\n",
    "\n",
    "#Model type 3\n",
    "def train_BIDIRECTIONAL_LSTM_model(epochs, steps_in, steps_out):\n",
    "    results_list = []\n",
    "    for i in range(1, steps_in):\n",
    "        for j in range(1, steps_out):\n",
    "            X, Y = km.create_join_x_y_arr(reactor_list, n_steps_in=i, n_steps_out = j, binary=True)\n",
    "            X_normalize, Y_normalize, scalers = km.normalize(X, Y)\n",
    "            X_normalize = np.nan_to_num(X_normalize, nan=-1)\n",
    "            Xtrain, Xtest, ytrain, ytest = train_test_split(X_normalize, Y_normalize, test_size=0.20, random_state=42)\n",
    "            \n",
    "            model = Sequential()\n",
    "            model.add(Bidirectional(LSTM(100, return_sequences=True, activation='relu')))\n",
    "            model.add(Bidirectional(LSTM(50, return_sequences=True, activation='relu')))\n",
    "            model.add(Bidirectional(LSTM(20, activation='relu')))\n",
    "            model.add(Dense(1, activation=\"sigmoid\"))\n",
    "            \n",
    "            model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy')\n",
    "            model.fit(Xtrain, ytrain, epochs=epochs, batch_size=10, shuffle=True)\n",
    "            \n",
    "            Yhat, Ytest = km.evaluate(model, Xtest, ytest, scalers, binary=True)\n",
    "            y_real = Ytest.astype(int)\n",
    "            threshold = threshold_for_max_f1(y_real, Yhat)\n",
    "            y_predict = np.where(Yhat > threshold, 1, 0).astype(int)\n",
    "            results_list.append(km.results(y_real, y_predict))\n",
    "    return results_list\n",
    "\n",
    "#Model type 6 - having lots of trouble with this one\n",
    "#For some reason we need steps_in to be at least 3 for this one\n",
    "#This probably has to do with the pooling, Convolution, or Dropout layers\n",
    "def train_LSTM_AUTOENCODER_model(epochs, steps_in, steps_out):\n",
    "    results_list = []\n",
    "    for i in range(3, steps_in):\n",
    "        for j in range(1, steps_out):\n",
    "            X, Y = km.create_join_x_y_arr(reactor_list, n_steps_in=i, n_steps_out = j, binary=True)\n",
    "            X_normalize, Y_normalize, scalers = km.normalize(X, Y)\n",
    "            X_normalize = np.nan_to_num(X_normalize, nan=-1)\n",
    "            Xtrain, Xtest, ytrain, ytest = train_test_split(X_normalize, Y_normalize, test_size=0.20, random_state=42)\n",
    "\n",
    "            model = Sequential()\n",
    "            model.add(Conv1D(filters=128, \n",
    "                             kernel_size=2, \n",
    "                             activation='relu', \n",
    "                             name='extractor', \n",
    "                             input_shape=(Xtrain.shape[1], Xtrain.shape[2])))\n",
    "            model.add(Dropout(0.3))\n",
    "            model.add(MaxPooling1D(pool_size=2))\n",
    "            model.add(Bidirectional(LSTM(50, activation='relu', input_shape=(Xtrain.shape[1], Xtrain.shape[2]))))\n",
    "            model.add(RepeatVector(10))\n",
    "            model.add(Bidirectional(LSTM(50, activation='relu')))\n",
    "            model.add(Dense(1))\n",
    "\n",
    "            model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy')\n",
    "            model.fit(Xtrain, ytrain, epochs=epochs, batch_size=10, shuffle=True)\n",
    "            \n",
    "            Yhat, Ytest = km.evaluate(model, Xtest, ytest, scalers, binary=True)\n",
    "            y_real = Ytest.astype(int)\n",
    "            threshold = threshold_for_max_f1(y_real, Yhat)\n",
    "            y_predict = np.where(Yhat > threshold, 1, 0).astype(int)\n",
    "            results_list.append(km.results(y_real, y_predict))\n",
    "    return results_list\n",
    "\n",
    "def train_GRU_CNN_model(epochs, steps_in, steps_out):\n",
    "    results_list = []\n",
    "    for i in range(2, steps_in):\n",
    "        for j in range(1, steps_out):\n",
    "            X, Y = km.create_join_x_y_arr(reactor_list, n_steps_in=i, n_steps_out = j, binary=True)\n",
    "            X_normalize, Y_normalize, scalers = km.normalize(X, Y)\n",
    "            X_normalize = np.nan_to_num(X_normalize, nan=-1)\n",
    "            Xtrain, Xtest, ytrain, ytest = train_test_split(X_normalize, Y_normalize, test_size=0.20, random_state=42)            \n",
    "            \n",
    "            inp_seq = Input(shape=(Xtrain.shape[1], Xtrain.shape[2]))\n",
    "            x = Bidirectional(GRU(100, return_sequences=True))(inp_seq)\n",
    "            x = AveragePooling1D(2)(x)\n",
    "            x = Conv1D(100, 3, activation='relu', padding='same',\n",
    "                       name='extractor')(x)\n",
    "            x = Flatten()(x)\n",
    "            x = Dense(16, activation='relu')(x)\n",
    "            x = Dropout(0.5)(x)\n",
    "\n",
    "            out = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "            model = Model(inp_seq, out)\n",
    "\n",
    "            \n",
    "            model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy')\n",
    "            model.fit(Xtrain, ytrain, epochs=epochs, batch_size=10, shuffle=True)\n",
    "            \n",
    "            Yhat, Ytest = km.evaluate(model, Xtest, ytest, scalers, binary=True)\n",
    "            y_real = Ytest.astype(int)\n",
    "            threshold = threshold_for_max_f1(y_real, Yhat)\n",
    "            y_predict = np.where(Yhat > threshold, 1, 0).astype(int)\n",
    "            results_list.append(km.results(y_real, y_predict))\n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 516.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12854/12854 [==============================] - 6s 443us/step - loss: 0.6463\n",
      "Epoch 2/10\n",
      "12854/12854 [==============================] - 4s 291us/step - loss: 0.6051\n",
      "Epoch 3/10\n",
      "12854/12854 [==============================] - 4s 276us/step - loss: 0.5674\n",
      "Epoch 4/10\n",
      "12854/12854 [==============================] - 4s 278us/step - loss: 0.5241\n",
      "Epoch 5/10\n",
      "12854/12854 [==============================] - 4s 275us/step - loss: 0.4890\n",
      "Epoch 6/10\n",
      "12854/12854 [==============================] - 4s 279us/step - loss: 0.4637\n",
      "Epoch 7/10\n",
      "12854/12854 [==============================] - 4s 277us/step - loss: 0.4466\n",
      "Epoch 8/10\n",
      "12854/12854 [==============================] - 4s 276us/step - loss: 0.4359\n",
      "Epoch 9/10\n",
      "12854/12854 [==============================] - 4s 277us/step - loss: 0.4292\n",
      "Epoch 10/10\n",
      "12854/12854 [==============================] - 4s 277us/step - loss: 0.4251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 892.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12851/12851 [==============================] - 5s 391us/step - loss: 0.6448\n",
      "Epoch 2/10\n",
      "12851/12851 [==============================] - 4s 346us/step - loss: 0.6127\n",
      "Epoch 3/10\n",
      "12851/12851 [==============================] - 4s 301us/step - loss: 0.5860\n",
      "Epoch 4/10\n",
      "12851/12851 [==============================] - 4s 303us/step - loss: 0.5545\n",
      "Epoch 5/10\n",
      "12851/12851 [==============================] - 4s 300us/step - loss: 0.5243\n",
      "Epoch 6/10\n",
      "12851/12851 [==============================] - 4s 302us/step - loss: 0.4979\n",
      "Epoch 7/10\n",
      "12851/12851 [==============================] - 4s 308us/step - loss: 0.4778\n",
      "Epoch 8/10\n",
      "12851/12851 [==============================] - 4s 346us/step - loss: 0.4639\n",
      "Epoch 9/10\n",
      "12851/12851 [==============================] - 4s 308us/step - loss: 0.4550\n",
      "Epoch 10/10\n",
      "12851/12851 [==============================] - 4s 291us/step - loss: 0.4497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 169.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12848/12848 [==============================] - 5s 409us/step - loss: 0.6417\n",
      "Epoch 2/10\n",
      "12848/12848 [==============================] - 4s 286us/step - loss: 0.6107\n",
      "Epoch 3/10\n",
      "12848/12848 [==============================] - 4s 285us/step - loss: 0.5852\n",
      "Epoch 4/10\n",
      "12848/12848 [==============================] - 4s 287us/step - loss: 0.5577\n",
      "Epoch 5/10\n",
      "12848/12848 [==============================] - 4s 290us/step - loss: 0.5326\n",
      "Epoch 6/10\n",
      "12848/12848 [==============================] - 4s 299us/step - loss: 0.5113\n",
      "Epoch 7/10\n",
      "12848/12848 [==============================] - 4s 288us/step - loss: 0.4954\n",
      "Epoch 8/10\n",
      "12848/12848 [==============================] - 4s 290us/step - loss: 0.4839\n",
      "Epoch 9/10\n",
      "12848/12848 [==============================] - 4s 288us/step - loss: 0.4760\n",
      "Epoch 10/10\n",
      "12848/12848 [==============================] - 4s 290us/step - loss: 0.4706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 742.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12844/12844 [==============================] - 5s 405us/step - loss: 0.6482\n",
      "Epoch 2/10\n",
      "12844/12844 [==============================] - 4s 297us/step - loss: 0.6122\n",
      "Epoch 3/10\n",
      "12844/12844 [==============================] - 4s 338us/step - loss: 0.5910\n",
      "Epoch 4/10\n",
      "12844/12844 [==============================] - 4s 331us/step - loss: 0.5638\n",
      "Epoch 5/10\n",
      "12844/12844 [==============================] - 4s 284us/step - loss: 0.5386\n",
      "Epoch 6/10\n",
      "12844/12844 [==============================] - 4s 278us/step - loss: 0.5187\n",
      "Epoch 7/10\n",
      "12844/12844 [==============================] - 4s 277us/step - loss: 0.5042\n",
      "Epoch 8/10\n",
      "12844/12844 [==============================] - 4s 276us/step - loss: 0.4938\n",
      "Epoch 9/10\n",
      "12844/12844 [==============================] - 4s 276us/step - loss: 0.4864\n",
      "Epoch 10/10\n",
      "12844/12844 [==============================] - 4s 296us/step - loss: 0.4816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 731.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12841/12841 [==============================] - 5s 394us/step - loss: 0.6471\n",
      "Epoch 2/10\n",
      "12841/12841 [==============================] - 4s 280us/step - loss: 0.6150\n",
      "Epoch 3/10\n",
      "12841/12841 [==============================] - 4s 280us/step - loss: 0.5927\n",
      "Epoch 4/10\n",
      "12841/12841 [==============================] - 4s 276us/step - loss: 0.5644\n",
      "Epoch 5/10\n",
      "12841/12841 [==============================] - 4s 278us/step - loss: 0.5389\n",
      "Epoch 6/10\n",
      "12841/12841 [==============================] - 4s 275us/step - loss: 0.5194\n",
      "Epoch 7/10\n",
      "12841/12841 [==============================] - 4s 274us/step - loss: 0.5057\n",
      "Epoch 8/10\n",
      "12841/12841 [==============================] - 4s 274us/step - loss: 0.4962\n",
      "Epoch 9/10\n",
      "12841/12841 [==============================] - 4s 275us/step - loss: 0.4896\n",
      "Epoch 10/10\n",
      "12841/12841 [==============================] - 4s 275us/step - loss: 0.4854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 779.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12838/12838 [==============================] - 5s 394us/step - loss: 0.6445\n",
      "Epoch 2/10\n",
      "12838/12838 [==============================] - 4s 278us/step - loss: 0.6146\n",
      "Epoch 3/10\n",
      "12838/12838 [==============================] - 4s 278us/step - loss: 0.5956\n",
      "Epoch 4/10\n",
      "12838/12838 [==============================] - 4s 279us/step - loss: 0.5735\n",
      "Epoch 5/10\n",
      "12838/12838 [==============================] - 4s 279us/step - loss: 0.5525\n",
      "Epoch 6/10\n",
      "12838/12838 [==============================] - 4s 304us/step - loss: 0.5350\n",
      "Epoch 7/10\n",
      "12838/12838 [==============================] - 4s 278us/step - loss: 0.5211\n",
      "Epoch 8/10\n",
      "12838/12838 [==============================] - 4s 281us/step - loss: 0.5109\n",
      "Epoch 9/10\n",
      "12838/12838 [==============================] - 4s 278us/step - loss: 0.5034\n",
      "Epoch 10/10\n",
      "12838/12838 [==============================] - 4s 278us/step - loss: 0.4981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 827.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12835/12835 [==============================] - 5s 390us/step - loss: 0.6508\n",
      "Epoch 2/10\n",
      "12835/12835 [==============================] - 4s 277us/step - loss: 0.6139\n",
      "Epoch 3/10\n",
      "12835/12835 [==============================] - 4s 278us/step - loss: 0.5908\n",
      "Epoch 4/10\n",
      "12835/12835 [==============================] - 4s 278us/step - loss: 0.5666\n",
      "Epoch 5/10\n",
      "12835/12835 [==============================] - 4s 279us/step - loss: 0.5460\n",
      "Epoch 6/10\n",
      "12835/12835 [==============================] - 4s 278us/step - loss: 0.5306\n",
      "Epoch 7/10\n",
      "12835/12835 [==============================] - 4s 276us/step - loss: 0.5197\n",
      "Epoch 8/10\n",
      "12835/12835 [==============================] - 4s 277us/step - loss: 0.5121\n",
      "Epoch 9/10\n",
      "12835/12835 [==============================] - 4s 276us/step - loss: 0.5067\n",
      "Epoch 10/10\n",
      "12835/12835 [==============================] - 4s 278us/step - loss: 0.5028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 685.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12832/12832 [==============================] - 5s 390us/step - loss: 0.6492\n",
      "Epoch 2/10\n",
      "12832/12832 [==============================] - 4s 276us/step - loss: 0.6202\n",
      "Epoch 3/10\n",
      "12832/12832 [==============================] - 4s 279us/step - loss: 0.6070\n",
      "Epoch 4/10\n",
      "12832/12832 [==============================] - 4s 278us/step - loss: 0.5888\n",
      "Epoch 5/10\n",
      "12832/12832 [==============================] - 4s 274us/step - loss: 0.5699\n",
      "Epoch 6/10\n",
      "12832/12832 [==============================] - 4s 285us/step - loss: 0.5532\n",
      "Epoch 7/10\n",
      "12832/12832 [==============================] - 4s 273us/step - loss: 0.5400\n",
      "Epoch 8/10\n",
      "12832/12832 [==============================] - 4s 276us/step - loss: 0.5302\n",
      "Epoch 9/10\n",
      "12832/12832 [==============================] - 4s 274us/step - loss: 0.5229\n",
      "Epoch 10/10\n",
      "12832/12832 [==============================] - 4s 274us/step - loss: 0.5174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 863.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12828/12828 [==============================] - 5s 391us/step - loss: 0.6416\n",
      "Epoch 2/10\n",
      "12828/12828 [==============================] - 4s 274us/step - loss: 0.6168\n",
      "Epoch 3/10\n",
      "12828/12828 [==============================] - 4s 275us/step - loss: 0.6009\n",
      "Epoch 4/10\n",
      "12828/12828 [==============================] - 4s 275us/step - loss: 0.5822\n",
      "Epoch 5/10\n",
      "12828/12828 [==============================] - 4s 274us/step - loss: 0.5641\n",
      "Epoch 6/10\n",
      "12828/12828 [==============================] - 4s 278us/step - loss: 0.5494\n",
      "Epoch 7/10\n",
      "12828/12828 [==============================] - 4s 277us/step - loss: 0.5383\n",
      "Epoch 8/10\n",
      "12828/12828 [==============================] - 4s 278us/step - loss: 0.5297\n",
      "Epoch 9/10\n",
      "12828/12828 [==============================] - 4s 278us/step - loss: 0.5238\n",
      "Epoch 10/10\n",
      "12828/12828 [==============================] - 4s 282us/step - loss: 0.5196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 708.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12825/12825 [==============================] - 5s 397us/step - loss: 0.6436\n",
      "Epoch 2/10\n",
      "12825/12825 [==============================] - 4s 278us/step - loss: 0.6146\n",
      "Epoch 3/10\n",
      "12825/12825 [==============================] - 4s 278us/step - loss: 0.6003\n",
      "Epoch 4/10\n",
      "12825/12825 [==============================] - 4s 277us/step - loss: 0.5831\n",
      "Epoch 5/10\n",
      "12825/12825 [==============================] - 4s 279us/step - loss: 0.5680\n",
      "Epoch 6/10\n",
      "12825/12825 [==============================] - 4s 280us/step - loss: 0.5557\n",
      "Epoch 7/10\n",
      "12825/12825 [==============================] - 4s 279us/step - loss: 0.5465\n",
      "Epoch 8/10\n",
      "12825/12825 [==============================] - 4s 277us/step - loss: 0.5398\n",
      "Epoch 9/10\n",
      "12825/12825 [==============================] - 4s 277us/step - loss: 0.5345\n",
      "Epoch 10/10\n",
      "12825/12825 [==============================] - 4s 278us/step - loss: 0.5306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 665.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12851/12851 [==============================] - 6s 478us/step - loss: 0.6533\n",
      "Epoch 2/10\n",
      "12851/12851 [==============================] - 5s 362us/step - loss: 0.5981\n",
      "Epoch 3/10\n",
      "12851/12851 [==============================] - 5s 369us/step - loss: 0.5360\n",
      "Epoch 4/10\n",
      "12851/12851 [==============================] - 5s 363us/step - loss: 0.4749\n",
      "Epoch 5/10\n",
      "12851/12851 [==============================] - 5s 365us/step - loss: 0.4451\n",
      "Epoch 6/10\n",
      "12851/12851 [==============================] - 5s 371us/step - loss: 0.4327\n",
      "Epoch 7/10\n",
      "12851/12851 [==============================] - 5s 361us/step - loss: 0.4249\n",
      "Epoch 8/10\n",
      "12851/12851 [==============================] - 5s 362us/step - loss: 0.4214\n",
      "Epoch 9/10\n",
      "12851/12851 [==============================] - 5s 371us/step - loss: 0.4186\n",
      "Epoch 10/10\n",
      "12851/12851 [==============================] - 5s 368us/step - loss: 0.4161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 655.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12848/12848 [==============================] - 6s 472us/step - loss: 0.6459\n",
      "Epoch 2/10\n",
      "12848/12848 [==============================] - 5s 361us/step - loss: 0.5999\n",
      "Epoch 3/10\n",
      "12848/12848 [==============================] - 5s 391us/step - loss: 0.5481\n",
      "Epoch 4/10\n",
      "12848/12848 [==============================] - 5s 395us/step - loss: 0.4984\n",
      "Epoch 5/10\n",
      "12848/12848 [==============================] - 5s 394us/step - loss: 0.4716\n",
      "Epoch 6/10\n",
      "12848/12848 [==============================] - 5s 392us/step - loss: 0.4569\n",
      "Epoch 7/10\n",
      "12848/12848 [==============================] - 5s 400us/step - loss: 0.4524\n",
      "Epoch 8/10\n",
      "12848/12848 [==============================] - 5s 396us/step - loss: 0.4467\n",
      "Epoch 9/10\n",
      "12848/12848 [==============================] - 5s 395us/step - loss: 0.4433\n",
      "Epoch 10/10\n",
      "12848/12848 [==============================] - 5s 397us/step - loss: 0.4415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 677.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12844/12844 [==============================] - 7s 524us/step - loss: 0.6408\n",
      "Epoch 2/10\n",
      "12844/12844 [==============================] - 5s 402us/step - loss: 0.5708\n",
      "Epoch 3/10\n",
      "12844/12844 [==============================] - 5s 408us/step - loss: 0.5042\n",
      "Epoch 4/10\n",
      "12844/12844 [==============================] - 5s 427us/step - loss: 0.4723\n",
      "Epoch 5/10\n",
      "12844/12844 [==============================] - 5s 398us/step - loss: 0.4621\n",
      "Epoch 6/10\n",
      "12844/12844 [==============================] - 5s 398us/step - loss: 0.4545\n",
      "Epoch 7/10\n",
      "12844/12844 [==============================] - 5s 396us/step - loss: 0.4515\n",
      "Epoch 8/10\n",
      "12844/12844 [==============================] - 5s 401us/step - loss: 0.4524\n",
      "Epoch 9/10\n",
      "12844/12844 [==============================] - 5s 403us/step - loss: 0.4500\n",
      "Epoch 10/10\n",
      "12844/12844 [==============================] - 5s 408us/step - loss: 0.4480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 650.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12841/12841 [==============================] - 7s 522us/step - loss: 0.6383\n",
      "Epoch 2/10\n",
      "12841/12841 [==============================] - 5s 392us/step - loss: 0.5954\n",
      "Epoch 3/10\n",
      "12841/12841 [==============================] - 5s 393us/step - loss: 0.5440\n",
      "Epoch 4/10\n",
      "12841/12841 [==============================] - 5s 402us/step - loss: 0.4978\n",
      "Epoch 5/10\n",
      "12841/12841 [==============================] - 5s 405us/step - loss: 0.4758\n",
      "Epoch 6/10\n",
      "12841/12841 [==============================] - 5s 393us/step - loss: 0.4665\n",
      "Epoch 7/10\n",
      "12841/12841 [==============================] - 5s 404us/step - loss: 0.4619\n",
      "Epoch 8/10\n",
      "12841/12841 [==============================] - 5s 396us/step - loss: 0.4597\n",
      "Epoch 9/10\n",
      "12841/12841 [==============================] - 5s 395us/step - loss: 0.4577\n",
      "Epoch 10/10\n",
      "12841/12841 [==============================] - 5s 404us/step - loss: 0.4570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 665.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12838/12838 [==============================] - 7s 519us/step - loss: 0.6312\n",
      "Epoch 2/10\n",
      "12838/12838 [==============================] - 5s 402us/step - loss: 0.5791\n",
      "Epoch 3/10\n",
      "12838/12838 [==============================] - 5s 402us/step - loss: 0.5311\n",
      "Epoch 4/10\n",
      "12838/12838 [==============================] - 5s 402us/step - loss: 0.4979\n",
      "Epoch 5/10\n",
      "12838/12838 [==============================] - 5s 398us/step - loss: 0.4819\n",
      "Epoch 6/10\n",
      "12838/12838 [==============================] - 5s 398us/step - loss: 0.4747\n",
      "Epoch 7/10\n",
      "12838/12838 [==============================] - 5s 397us/step - loss: 0.4721\n",
      "Epoch 8/10\n",
      "12838/12838 [==============================] - 5s 365us/step - loss: 0.4691\n",
      "Epoch 9/10\n",
      "12838/12838 [==============================] - 5s 369us/step - loss: 0.4672\n",
      "Epoch 10/10\n",
      "12838/12838 [==============================] - 5s 364us/step - loss: 0.4671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 675.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12835/12835 [==============================] - 8s 608us/step - loss: 0.6402\n",
      "Epoch 2/10\n",
      "12835/12835 [==============================] - 5s 362us/step - loss: 0.6039\n",
      "Epoch 3/10\n",
      "12835/12835 [==============================] - 5s 364us/step - loss: 0.5630\n",
      "Epoch 4/10\n",
      "12835/12835 [==============================] - 5s 360us/step - loss: 0.5281\n",
      "Epoch 5/10\n",
      "12835/12835 [==============================] - 5s 362us/step - loss: 0.5050\n",
      "Epoch 6/10\n",
      "12835/12835 [==============================] - 5s 362us/step - loss: 0.4929\n",
      "Epoch 7/10\n",
      "12835/12835 [==============================] - 5s 367us/step - loss: 0.4857\n",
      "Epoch 8/10\n",
      "12835/12835 [==============================] - 5s 367us/step - loss: 0.4847\n",
      "Epoch 9/10\n",
      "12835/12835 [==============================] - 5s 362us/step - loss: 0.4818\n",
      "Epoch 10/10\n",
      "12835/12835 [==============================] - 5s 361us/step - loss: 0.4789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 620.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12832/12832 [==============================] - 6s 476us/step - loss: 0.6430\n",
      "Epoch 2/10\n",
      "12832/12832 [==============================] - 5s 414us/step - loss: 0.5963\n",
      "Epoch 3/10\n",
      "12832/12832 [==============================] - 5s 370us/step - loss: 0.5585\n",
      "Epoch 4/10\n",
      "12832/12832 [==============================] - 5s 374us/step - loss: 0.5304\n",
      "Epoch 5/10\n",
      "12832/12832 [==============================] - 5s 371us/step - loss: 0.5133\n",
      "Epoch 6/10\n",
      "12832/12832 [==============================] - 5s 365us/step - loss: 0.5039\n",
      "Epoch 7/10\n",
      "12832/12832 [==============================] - 5s 362us/step - loss: 0.4973\n",
      "Epoch 8/10\n",
      "12832/12832 [==============================] - 5s 363us/step - loss: 0.4954\n",
      "Epoch 9/10\n",
      "12832/12832 [==============================] - 5s 372us/step - loss: 0.4911\n",
      "Epoch 10/10\n",
      "12832/12832 [==============================] - 5s 363us/step - loss: 0.4900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 668.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12828/12828 [==============================] - 7s 565us/step - loss: 0.6351\n",
      "Epoch 2/10\n",
      "12828/12828 [==============================] - 6s 486us/step - loss: 0.6063\n",
      "Epoch 3/10\n",
      "12828/12828 [==============================] - 5s 413us/step - loss: 0.5750\n",
      "Epoch 4/10\n",
      "12828/12828 [==============================] - 7s 508us/step - loss: 0.5456\n",
      "Epoch 5/10\n",
      "12828/12828 [==============================] - 5s 369us/step - loss: 0.5239\n",
      "Epoch 6/10\n",
      "12828/12828 [==============================] - 5s 372us/step - loss: 0.5118\n",
      "Epoch 7/10\n",
      "12828/12828 [==============================] - 5s 378us/step - loss: 0.5043\n",
      "Epoch 8/10\n",
      "12828/12828 [==============================] - 5s 383us/step - loss: 0.5025\n",
      "Epoch 9/10\n",
      "12828/12828 [==============================] - 7s 564us/step - loss: 0.4988\n",
      "Epoch 10/10\n",
      "12828/12828 [==============================] - 5s 379us/step - loss: 0.4968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 633.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12825/12825 [==============================] - 9s 689us/step - loss: 0.6356\n",
      "Epoch 2/10\n",
      "12825/12825 [==============================] - 5s 426us/step - loss: 0.5969\n",
      "Epoch 3/10\n",
      "12825/12825 [==============================] - 5s 360us/step - loss: 0.5618\n",
      "Epoch 4/10\n",
      "12825/12825 [==============================] - 5s 364us/step - loss: 0.5376\n",
      "Epoch 5/10\n",
      "12825/12825 [==============================] - 5s 363us/step - loss: 0.5247\n",
      "Epoch 6/10\n",
      "12825/12825 [==============================] - 5s 384us/step - loss: 0.5172\n",
      "Epoch 7/10\n",
      "12825/12825 [==============================] - 6s 451us/step - loss: 0.5136\n",
      "Epoch 8/10\n",
      "12825/12825 [==============================] - 5s 404us/step - loss: 0.5108\n",
      "Epoch 9/10\n",
      "12825/12825 [==============================] - 6s 499us/step - loss: 0.5098\n",
      "Epoch 10/10\n",
      "12825/12825 [==============================] - 6s 468us/step - loss: 0.5076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 516.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12822/12822 [==============================] - 6s 500us/step - loss: 0.6426\n",
      "Epoch 2/10\n",
      "12822/12822 [==============================] - 5s 370us/step - loss: 0.6136\n",
      "Epoch 3/10\n",
      "12822/12822 [==============================] - 5s 367us/step - loss: 0.5905\n",
      "Epoch 4/10\n",
      "12822/12822 [==============================] - 5s 362us/step - loss: 0.5654\n",
      "Epoch 5/10\n",
      "12822/12822 [==============================] - 5s 363us/step - loss: 0.5464\n",
      "Epoch 6/10\n",
      "12822/12822 [==============================] - 5s 365us/step - loss: 0.5356\n",
      "Epoch 7/10\n",
      "12822/12822 [==============================] - 5s 374us/step - loss: 0.5274\n",
      "Epoch 8/10\n",
      "12822/12822 [==============================] - 5s 370us/step - loss: 0.5236\n",
      "Epoch 9/10\n",
      "12822/12822 [==============================] - 5s 368us/step - loss: 0.5216\n",
      "Epoch 10/10\n",
      "12822/12822 [==============================] - 5s 363us/step - loss: 0.5195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 710.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12848/12848 [==============================] - 7s 562us/step - loss: 0.6227\n",
      "Epoch 2/10\n",
      "12848/12848 [==============================] - 6s 446us/step - loss: 0.5337\n",
      "Epoch 3/10\n",
      "12848/12848 [==============================] - 6s 447us/step - loss: 0.4608\n",
      "Epoch 4/10\n",
      "12848/12848 [==============================] - 6s 453us/step - loss: 0.4390\n",
      "Epoch 5/10\n",
      "12848/12848 [==============================] - 6s 448us/step - loss: 0.4301\n",
      "Epoch 6/10\n",
      "12848/12848 [==============================] - 6s 444us/step - loss: 0.4252\n",
      "Epoch 7/10\n",
      "12848/12848 [==============================] - 6s 448us/step - loss: 0.4193\n",
      "Epoch 8/10\n",
      "12848/12848 [==============================] - 6s 462us/step - loss: 0.4162\n",
      "Epoch 9/10\n",
      "12848/12848 [==============================] - 6s 486us/step - loss: 0.4116\n",
      "Epoch 10/10\n",
      "12848/12848 [==============================] - 6s 489us/step - loss: 0.4120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 591.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12844/12844 [==============================] - 8s 593us/step - loss: 0.6250\n",
      "Epoch 2/10\n",
      "12844/12844 [==============================] - 6s 448us/step - loss: 0.5464\n",
      "Epoch 3/10\n",
      "12844/12844 [==============================] - 6s 447us/step - loss: 0.4748\n",
      "Epoch 4/10\n",
      "12844/12844 [==============================] - 6s 449us/step - loss: 0.4537\n",
      "Epoch 5/10\n",
      "12844/12844 [==============================] - 6s 463us/step - loss: 0.4438\n",
      "Epoch 6/10\n",
      "12844/12844 [==============================] - 6s 455us/step - loss: 0.4399\n",
      "Epoch 7/10\n",
      "12844/12844 [==============================] - 6s 447us/step - loss: 0.4363\n",
      "Epoch 8/10\n",
      "12844/12844 [==============================] - 6s 455us/step - loss: 0.4331\n",
      "Epoch 9/10\n",
      "12844/12844 [==============================] - 6s 447us/step - loss: 0.4302\n",
      "Epoch 10/10\n",
      "12844/12844 [==============================] - 6s 463us/step - loss: 0.4297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 705.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12841/12841 [==============================] - 7s 562us/step - loss: 0.6321\n",
      "Epoch 2/10\n",
      "12841/12841 [==============================] - 6s 452us/step - loss: 0.5687\n",
      "Epoch 3/10\n",
      "12841/12841 [==============================] - 6s 449us/step - loss: 0.5014\n",
      "Epoch 4/10\n",
      "12841/12841 [==============================] - 6s 460us/step - loss: 0.4727\n",
      "Epoch 5/10\n",
      "12841/12841 [==============================] - 6s 456us/step - loss: 0.4647\n",
      "Epoch 6/10\n",
      "12841/12841 [==============================] - 6s 455us/step - loss: 0.4601\n",
      "Epoch 7/10\n",
      "12841/12841 [==============================] - 6s 447us/step - loss: 0.4530\n",
      "Epoch 8/10\n",
      "12841/12841 [==============================] - 6s 448us/step - loss: 0.4498\n",
      "Epoch 9/10\n",
      "12841/12841 [==============================] - 6s 446us/step - loss: 0.4459\n",
      "Epoch 10/10\n",
      "12841/12841 [==============================] - 6s 461us/step - loss: 0.4428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 742.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12838/12838 [==============================] - 8s 592us/step - loss: 0.6295\n",
      "Epoch 2/10\n",
      "12838/12838 [==============================] - 6s 465us/step - loss: 0.5421\n",
      "Epoch 3/10\n",
      "12838/12838 [==============================] - 6s 450us/step - loss: 0.4893\n",
      "Epoch 4/10\n",
      "12838/12838 [==============================] - 6s 448us/step - loss: 0.4756\n",
      "Epoch 5/10\n",
      "12838/12838 [==============================] - 6s 460us/step - loss: 0.4693\n",
      "Epoch 6/10\n",
      "12838/12838 [==============================] - 6s 443us/step - loss: 0.4642\n",
      "Epoch 7/10\n",
      "12838/12838 [==============================] - 6s 442us/step - loss: 0.4626\n",
      "Epoch 8/10\n",
      "12838/12838 [==============================] - 6s 447us/step - loss: 0.4601\n",
      "Epoch 9/10\n",
      "12838/12838 [==============================] - 6s 463us/step - loss: 0.4567\n",
      "Epoch 10/10\n",
      "12838/12838 [==============================] - 6s 446us/step - loss: 0.4564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 423.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12835/12835 [==============================] - 7s 565us/step - loss: 0.6283\n",
      "Epoch 2/10\n",
      "12835/12835 [==============================] - 6s 447us/step - loss: 0.5725\n",
      "Epoch 3/10\n",
      "12835/12835 [==============================] - 6s 453us/step - loss: 0.5176\n",
      "Epoch 4/10\n",
      "12835/12835 [==============================] - 6s 464us/step - loss: 0.4939\n",
      "Epoch 5/10\n",
      "12835/12835 [==============================] - 6s 463us/step - loss: 0.4844\n",
      "Epoch 6/10\n",
      "12835/12835 [==============================] - 7s 554us/step - loss: 0.4774\n",
      "Epoch 7/10\n",
      "12835/12835 [==============================] - 6s 489us/step - loss: 0.4724\n",
      "Epoch 8/10\n",
      "12835/12835 [==============================] - 6s 470us/step - loss: 0.4707\n",
      "Epoch 9/10\n",
      "12835/12835 [==============================] - 7s 568us/step - loss: 0.4684\n",
      "Epoch 10/10\n",
      "12835/12835 [==============================] - 6s 500us/step - loss: 0.4672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 212.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12832/12832 [==============================] - 8s 591us/step - loss: 0.6270\n",
      "Epoch 2/10\n",
      "12832/12832 [==============================] - 6s 472us/step - loss: 0.5840\n",
      "Epoch 3/10\n",
      "12832/12832 [==============================] - 6s 460us/step - loss: 0.5337\n",
      "Epoch 4/10\n",
      "12832/12832 [==============================] - 6s 494us/step - loss: 0.5035\n",
      "Epoch 5/10\n",
      "12832/12832 [==============================] - 6s 452us/step - loss: 0.4920\n",
      "Epoch 6/10\n",
      "12832/12832 [==============================] - 6s 449us/step - loss: 0.4861\n",
      "Epoch 7/10\n",
      "12832/12832 [==============================] - 6s 467us/step - loss: 0.4835\n",
      "Epoch 8/10\n",
      "12832/12832 [==============================] - 6s 447us/step - loss: 0.4810\n",
      "Epoch 9/10\n",
      "12832/12832 [==============================] - 6s 453us/step - loss: 0.4790\n",
      "Epoch 10/10\n",
      "12832/12832 [==============================] - 6s 448us/step - loss: 0.4763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 744.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12828/12828 [==============================] - 8s 647us/step - loss: 0.6475\n",
      "Epoch 2/10\n",
      "12828/12828 [==============================] - 8s 636us/step - loss: 0.5856\n",
      "Epoch 3/10\n",
      "12828/12828 [==============================] - 8s 589us/step - loss: 0.5286\n",
      "Epoch 4/10\n",
      "12828/12828 [==============================] - 6s 486us/step - loss: 0.5070\n",
      "Epoch 5/10\n",
      "12828/12828 [==============================] - 7s 573us/step - loss: 0.4986\n",
      "Epoch 6/10\n",
      "12828/12828 [==============================] - 7s 528us/step - loss: 0.4952\n",
      "Epoch 7/10\n",
      "12828/12828 [==============================] - 6s 492us/step - loss: 0.4903\n",
      "Epoch 8/10\n",
      "12828/12828 [==============================] - 6s 483us/step - loss: 0.4897\n",
      "Epoch 9/10\n",
      "12828/12828 [==============================] - 6s 490us/step - loss: 0.4855\n",
      "Epoch 10/10\n",
      "12828/12828 [==============================] - 6s 491us/step - loss: 0.4851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 756.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12825/12825 [==============================] - 8s 651us/step - loss: 0.6333\n",
      "Epoch 2/10\n",
      "12825/12825 [==============================] - 7s 516us/step - loss: 0.5860\n",
      "Epoch 3/10\n",
      "12825/12825 [==============================] - 6s 480us/step - loss: 0.5436\n",
      "Epoch 4/10\n",
      "12825/12825 [==============================] - 7s 544us/step - loss: 0.5225\n",
      "Epoch 5/10\n",
      "12825/12825 [==============================] - 6s 501us/step - loss: 0.5139\n",
      "Epoch 6/10\n",
      "12825/12825 [==============================] - 6s 498us/step - loss: 0.5094\n",
      "Epoch 7/10\n",
      "12825/12825 [==============================] - 6s 454us/step - loss: 0.5067\n",
      "Epoch 8/10\n",
      "12825/12825 [==============================] - 6s 447us/step - loss: 0.5038\n",
      "Epoch 9/10\n",
      "12825/12825 [==============================] - 6s 447us/step - loss: 0.5015\n",
      "Epoch 10/10\n",
      "12825/12825 [==============================] - 6s 448us/step - loss: 0.4994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 695.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12822/12822 [==============================] - 7s 574us/step - loss: 0.6310\n",
      "Epoch 2/10\n",
      "12822/12822 [==============================] - 6s 450us/step - loss: 0.5680\n",
      "Epoch 3/10\n",
      "12822/12822 [==============================] - 6s 468us/step - loss: 0.5381\n",
      "Epoch 4/10\n",
      "12822/12822 [==============================] - 6s 460us/step - loss: 0.5263\n",
      "Epoch 5/10\n",
      "12822/12822 [==============================] - 6s 453us/step - loss: 0.5202\n",
      "Epoch 6/10\n",
      "12822/12822 [==============================] - 6s 450us/step - loss: 0.5160\n",
      "Epoch 7/10\n",
      "12822/12822 [==============================] - 6s 453us/step - loss: 0.5138\n",
      "Epoch 8/10\n",
      "12822/12822 [==============================] - 6s 450us/step - loss: 0.5099\n",
      "Epoch 9/10\n",
      "12822/12822 [==============================] - 6s 469us/step - loss: 0.5096\n",
      "Epoch 10/10\n",
      "12822/12822 [==============================] - 6s 497us/step - loss: 0.5069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 459.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12819/12819 [==============================] - 8s 637us/step - loss: 0.6259\n",
      "Epoch 2/10\n",
      "12819/12819 [==============================] - 6s 468us/step - loss: 0.5818\n",
      "Epoch 3/10\n",
      "12819/12819 [==============================] - 6s 494us/step - loss: 0.5515\n",
      "Epoch 4/10\n",
      "12819/12819 [==============================] - 6s 448us/step - loss: 0.5339\n",
      "Epoch 5/10\n",
      "12819/12819 [==============================] - 6s 464us/step - loss: 0.5235\n",
      "Epoch 6/10\n",
      "12819/12819 [==============================] - 6s 469us/step - loss: 0.5189\n",
      "Epoch 7/10\n",
      "12819/12819 [==============================] - 7s 517us/step - loss: 0.5179\n",
      "Epoch 8/10\n",
      "12819/12819 [==============================] - 6s 474us/step - loss: 0.5163\n",
      "Epoch 9/10\n",
      "12819/12819 [==============================] - 7s 557us/step - loss: 0.5122\n",
      "Epoch 10/10\n",
      "12819/12819 [==============================] - 6s 471us/step - loss: 0.5106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 723.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12844/12844 [==============================] - 8s 650us/step - loss: 0.6045\n",
      "Epoch 2/10\n",
      "12844/12844 [==============================] - 7s 568us/step - loss: 0.4864\n",
      "Epoch 3/10\n",
      "12844/12844 [==============================] - 7s 562us/step - loss: 0.4418\n",
      "Epoch 4/10\n",
      "12844/12844 [==============================] - 7s 528us/step - loss: 0.4304\n",
      "Epoch 5/10\n",
      "12844/12844 [==============================] - 7s 524us/step - loss: 0.4256\n",
      "Epoch 6/10\n",
      "12844/12844 [==============================] - 7s 528us/step - loss: 0.4214\n",
      "Epoch 7/10\n",
      "12844/12844 [==============================] - 7s 533us/step - loss: 0.4166\n",
      "Epoch 8/10\n",
      "12844/12844 [==============================] - 7s 535us/step - loss: 0.4136\n",
      "Epoch 9/10\n",
      "12844/12844 [==============================] - 7s 527us/step - loss: 0.4128\n",
      "Epoch 10/10\n",
      "12844/12844 [==============================] - 7s 551us/step - loss: 0.4089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 684.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12841/12841 [==============================] - 8s 649us/step - loss: 0.6157\n",
      "Epoch 2/10\n",
      "12841/12841 [==============================] - 7s 548us/step - loss: 0.5083\n",
      "Epoch 3/10\n",
      "12841/12841 [==============================] - 7s 584us/step - loss: 0.4586\n",
      "Epoch 4/10\n",
      "12841/12841 [==============================] - 7s 538us/step - loss: 0.4474\n",
      "Epoch 5/10\n",
      "12841/12841 [==============================] - 7s 560us/step - loss: 0.4401\n",
      "Epoch 6/10\n",
      "12841/12841 [==============================] - 7s 542us/step - loss: 0.4347\n",
      "Epoch 7/10\n",
      "12841/12841 [==============================] - 8s 606us/step - loss: 0.4343\n",
      "Epoch 8/10\n",
      "12841/12841 [==============================] - 7s 572us/step - loss: 0.4284\n",
      "Epoch 9/10\n",
      "12841/12841 [==============================] - 7s 575us/step - loss: 0.4252\n",
      "Epoch 10/10\n",
      "12841/12841 [==============================] - 7s 535us/step - loss: 0.4235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 707.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12838/12838 [==============================] - 8s 657us/step - loss: 0.6292\n",
      "Epoch 2/10\n",
      "12838/12838 [==============================] - 8s 585us/step - loss: 0.5298\n",
      "Epoch 3/10\n",
      "12838/12838 [==============================] - 7s 554us/step - loss: 0.4727\n",
      "Epoch 4/10\n",
      "12838/12838 [==============================] - 8s 590us/step - loss: 0.4623\n",
      "Epoch 5/10\n",
      "12838/12838 [==============================] - 8s 585us/step - loss: 0.4545\n",
      "Epoch 6/10\n",
      "12838/12838 [==============================] - 8s 601us/step - loss: 0.4498\n",
      "Epoch 7/10\n",
      "12838/12838 [==============================] - 7s 536us/step - loss: 0.4472\n",
      "Epoch 8/10\n",
      "12838/12838 [==============================] - 7s 542us/step - loss: 0.4445\n",
      "Epoch 9/10\n",
      "12838/12838 [==============================] - 7s 545us/step - loss: 0.4431\n",
      "Epoch 10/10\n",
      "12838/12838 [==============================] - 7s 545us/step - loss: 0.4392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 709.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12835/12835 [==============================] - 9s 702us/step - loss: 0.6225\n",
      "Epoch 2/10\n",
      "12835/12835 [==============================] - 7s 576us/step - loss: 0.5595\n",
      "Epoch 3/10\n",
      "12835/12835 [==============================] - 9s 672us/step - loss: 0.4969\n",
      "Epoch 4/10\n",
      "12835/12835 [==============================] - 9s 679us/step - loss: 0.4776\n",
      "Epoch 5/10\n",
      "12835/12835 [==============================] - 9s 721us/step - loss: 0.4704\n",
      "Epoch 6/10\n",
      "12835/12835 [==============================] - 7s 565us/step - loss: 0.4670\n",
      "Epoch 7/10\n",
      "12835/12835 [==============================] - 7s 538us/step - loss: 0.4636\n",
      "Epoch 8/10\n",
      "12835/12835 [==============================] - 7s 532us/step - loss: 0.4580\n",
      "Epoch 9/10\n",
      "12835/12835 [==============================] - 7s 529us/step - loss: 0.4569\n",
      "Epoch 10/10\n",
      "12835/12835 [==============================] - 7s 553us/step - loss: 0.4555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 595.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12832/12832 [==============================] - 9s 686us/step - loss: 0.6322\n",
      "Epoch 2/10\n",
      "12832/12832 [==============================] - 7s 548us/step - loss: 0.5716\n",
      "Epoch 3/10\n",
      "12832/12832 [==============================] - 7s 533us/step - loss: 0.5146\n",
      "Epoch 4/10\n",
      "12832/12832 [==============================] - 7s 543us/step - loss: 0.4910\n",
      "Epoch 5/10\n",
      "12832/12832 [==============================] - 7s 550us/step - loss: 0.4834\n",
      "Epoch 6/10\n",
      "12832/12832 [==============================] - 7s 546us/step - loss: 0.4806\n",
      "Epoch 7/10\n",
      "12832/12832 [==============================] - 7s 545us/step - loss: 0.4744\n",
      "Epoch 8/10\n",
      "12832/12832 [==============================] - 7s 556us/step - loss: 0.4713\n",
      "Epoch 9/10\n",
      "12832/12832 [==============================] - 7s 548us/step - loss: 0.4676\n",
      "Epoch 10/10\n",
      "12832/12832 [==============================] - 7s 548us/step - loss: 0.4634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 711.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12828/12828 [==============================] - 9s 688us/step - loss: 0.6235\n",
      "Epoch 2/10\n",
      "12828/12828 [==============================] - 7s 553us/step - loss: 0.5468\n",
      "Epoch 3/10\n",
      "12828/12828 [==============================] - 7s 561us/step - loss: 0.5042\n",
      "Epoch 4/10\n",
      "12828/12828 [==============================] - 8s 588us/step - loss: 0.4916\n",
      "Epoch 5/10\n",
      "12828/12828 [==============================] - 7s 547us/step - loss: 0.4867\n",
      "Epoch 6/10\n",
      "12828/12828 [==============================] - 7s 548us/step - loss: 0.4826\n",
      "Epoch 7/10\n",
      "12828/12828 [==============================] - 7s 548us/step - loss: 0.4816\n",
      "Epoch 8/10\n",
      "12828/12828 [==============================] - 7s 569us/step - loss: 0.4772\n",
      "Epoch 9/10\n",
      "12828/12828 [==============================] - 8s 604us/step - loss: 0.4749\n",
      "Epoch 10/10\n",
      "12828/12828 [==============================] - 8s 606us/step - loss: 0.4739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 595.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12825/12825 [==============================] - 9s 740us/step - loss: 0.6372\n",
      "Epoch 2/10\n",
      "12825/12825 [==============================] - 8s 588us/step - loss: 0.5874\n",
      "Epoch 3/10\n",
      "12825/12825 [==============================] - 8s 651us/step - loss: 0.5404\n",
      "Epoch 4/10\n",
      "12825/12825 [==============================] - 8s 602us/step - loss: 0.5181\n",
      "Epoch 5/10\n",
      "12825/12825 [==============================] - 8s 590us/step - loss: 0.5061\n",
      "Epoch 6/10\n",
      "12825/12825 [==============================] - 8s 593us/step - loss: 0.5008\n",
      "Epoch 7/10\n",
      "12825/12825 [==============================] - 8s 602us/step - loss: 0.4976\n",
      "Epoch 8/10\n",
      "12825/12825 [==============================] - 8s 585us/step - loss: 0.4942\n",
      "Epoch 9/10\n",
      "12825/12825 [==============================] - 8s 594us/step - loss: 0.4911\n",
      "Epoch 10/10\n",
      "12825/12825 [==============================] - 7s 578us/step - loss: 0.4892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 673.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12822/12822 [==============================] - 8s 662us/step - loss: 0.6263\n",
      "Epoch 2/10\n",
      "12822/12822 [==============================] - 7s 529us/step - loss: 0.5704\n",
      "Epoch 3/10\n",
      "12822/12822 [==============================] - 7s 538us/step - loss: 0.5301\n",
      "Epoch 4/10\n",
      "12822/12822 [==============================] - 7s 577us/step - loss: 0.5191\n",
      "Epoch 5/10\n",
      "12822/12822 [==============================] - 7s 550us/step - loss: 0.5112\n",
      "Epoch 6/10\n",
      "12822/12822 [==============================] - 7s 560us/step - loss: 0.5076\n",
      "Epoch 7/10\n",
      "12822/12822 [==============================] - 7s 551us/step - loss: 0.5068\n",
      "Epoch 8/10\n",
      "12822/12822 [==============================] - 7s 573us/step - loss: 0.5051\n",
      "Epoch 9/10\n",
      "12822/12822 [==============================] - 7s 547us/step - loss: 0.5000\n",
      "Epoch 10/10\n",
      "12822/12822 [==============================] - 7s 569us/step - loss: 0.4974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 711.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12819/12819 [==============================] - 8s 644us/step - loss: 0.6341\n",
      "Epoch 2/10\n",
      "12819/12819 [==============================] - 7s 527us/step - loss: 0.5836\n",
      "Epoch 3/10\n",
      "12819/12819 [==============================] - 7s 564us/step - loss: 0.5429\n",
      "Epoch 4/10\n",
      "12819/12819 [==============================] - 7s 562us/step - loss: 0.5264\n",
      "Epoch 5/10\n",
      "12819/12819 [==============================] - 7s 568us/step - loss: 0.5204\n",
      "Epoch 6/10\n",
      "12819/12819 [==============================] - 7s 564us/step - loss: 0.5166\n",
      "Epoch 7/10\n",
      "12819/12819 [==============================] - 7s 564us/step - loss: 0.5139\n",
      "Epoch 8/10\n",
      "12819/12819 [==============================] - 7s 556us/step - loss: 0.5117\n",
      "Epoch 9/10\n",
      "12819/12819 [==============================] - 7s 540us/step - loss: 0.5077\n",
      "Epoch 10/10\n",
      "12819/12819 [==============================] - 7s 547us/step - loss: 0.5067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 694.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12816/12816 [==============================] - 9s 712us/step - loss: 0.6312\n",
      "Epoch 2/10\n",
      "12816/12816 [==============================] - 8s 601us/step - loss: 0.5861\n",
      "Epoch 3/10\n",
      "12816/12816 [==============================] - 8s 594us/step - loss: 0.5492\n",
      "Epoch 4/10\n",
      "12816/12816 [==============================] - 8s 597us/step - loss: 0.5344\n",
      "Epoch 5/10\n",
      "12816/12816 [==============================] - 8s 619us/step - loss: 0.5298\n",
      "Epoch 6/10\n",
      "12816/12816 [==============================] - 8s 614us/step - loss: 0.5230\n",
      "Epoch 7/10\n",
      "12816/12816 [==============================] - 8s 600us/step - loss: 0.5222\n",
      "Epoch 8/10\n",
      "12816/12816 [==============================] - 8s 597us/step - loss: 0.5188\n",
      "Epoch 9/10\n",
      "12816/12816 [==============================] - 8s 591us/step - loss: 0.5180\n",
      "Epoch 10/10\n",
      "12816/12816 [==============================] - 7s 568us/step - loss: 0.5155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 640.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12841/12841 [==============================] - 10s 769us/step - loss: 0.6224\n",
      "Epoch 2/10\n",
      "12841/12841 [==============================] - 8s 646us/step - loss: 0.4958\n",
      "Epoch 3/10\n",
      "12841/12841 [==============================] - 9s 674us/step - loss: 0.4557\n",
      "Epoch 4/10\n",
      "12841/12841 [==============================] - 8s 659us/step - loss: 0.4466\n",
      "Epoch 5/10\n",
      "12841/12841 [==============================] - 8s 655us/step - loss: 0.4401\n",
      "Epoch 6/10\n",
      "12841/12841 [==============================] - 8s 656us/step - loss: 0.4316\n",
      "Epoch 7/10\n",
      "12841/12841 [==============================] - 11s 837us/step - loss: 0.4284\n",
      "Epoch 8/10\n",
      "12841/12841 [==============================] - 9s 695us/step - loss: 0.4225\n",
      "Epoch 9/10\n",
      "12841/12841 [==============================] - 10s 813us/step - loss: 0.4214\n",
      "Epoch 10/10\n",
      "12841/12841 [==============================] - 9s 698us/step - loss: 0.4121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 528.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12838/12838 [==============================] - 12s 911us/step - loss: 0.6192\n",
      "Epoch 2/10\n",
      "12838/12838 [==============================] - 8s 653us/step - loss: 0.5088\n",
      "Epoch 3/10\n",
      "12838/12838 [==============================] - 8s 652us/step - loss: 0.4652\n",
      "Epoch 4/10\n",
      "12838/12838 [==============================] - 9s 683us/step - loss: 0.4620\n",
      "Epoch 5/10\n",
      "12838/12838 [==============================] - 8s 659us/step - loss: 0.4499\n",
      "Epoch 6/10\n",
      "12838/12838 [==============================] - 9s 669us/step - loss: 0.4457\n",
      "Epoch 7/10\n",
      "12838/12838 [==============================] - 9s 667us/step - loss: 0.4408\n",
      "Epoch 8/10\n",
      "12838/12838 [==============================] - 8s 658us/step - loss: 0.4355\n",
      "Epoch 9/10\n",
      "12838/12838 [==============================] - 9s 663us/step - loss: 0.4321\n",
      "Epoch 10/10\n",
      "12838/12838 [==============================] - 9s 686us/step - loss: 0.4296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 669.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12835/12835 [==============================] - 10s 778us/step - loss: 0.6261\n",
      "Epoch 2/10\n",
      "12835/12835 [==============================] - 8s 617us/step - loss: 0.5310\n",
      "Epoch 3/10\n",
      "12835/12835 [==============================] - 10s 800us/step - loss: 0.4924\n",
      "Epoch 4/10\n",
      "12835/12835 [==============================] - 8s 650us/step - loss: 0.4756\n",
      "Epoch 5/10\n",
      "12835/12835 [==============================] - 9s 687us/step - loss: 0.4662\n",
      "Epoch 6/10\n",
      "12835/12835 [==============================] - 9s 680us/step - loss: 0.4602\n",
      "Epoch 7/10\n",
      "12835/12835 [==============================] - 10s 789us/step - loss: 0.4545\n",
      "Epoch 8/10\n",
      "12835/12835 [==============================] - 10s 807us/step - loss: 0.4534\n",
      "Epoch 9/10\n",
      "12835/12835 [==============================] - 10s 753us/step - loss: 0.4494\n",
      "Epoch 10/10\n",
      "12835/12835 [==============================] - 10s 793us/step - loss: 0.4458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 653.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12832/12832 [==============================] - 10s 779us/step - loss: 0.6143\n",
      "Epoch 2/10\n",
      "12832/12832 [==============================] - 8s 657us/step - loss: 0.5074\n",
      "Epoch 3/10\n",
      "12832/12832 [==============================] - 9s 679us/step - loss: 0.4847\n",
      "Epoch 4/10\n",
      "12832/12832 [==============================] - 10s 794us/step - loss: 0.4744\n",
      "Epoch 5/10\n",
      "12832/12832 [==============================] - 10s 796us/step - loss: 0.4683\n",
      "Epoch 6/10\n",
      "12832/12832 [==============================] - 9s 739us/step - loss: 0.4629\n",
      "Epoch 7/10\n",
      "12832/12832 [==============================] - 10s 788us/step - loss: 0.4630\n",
      "Epoch 8/10\n",
      "12832/12832 [==============================] - 9s 731us/step - loss: 0.4570\n",
      "Epoch 9/10\n",
      "12832/12832 [==============================] - 9s 706us/step - loss: 0.4569\n",
      "Epoch 10/10\n",
      "12832/12832 [==============================] - 9s 739us/step - loss: 0.4547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 522.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12828/12828 [==============================] - 10s 808us/step - loss: 0.6133\n",
      "Epoch 2/10\n",
      "12828/12828 [==============================] - 9s 721us/step - loss: 0.5227\n",
      "Epoch 3/10\n",
      "12828/12828 [==============================] - 9s 721us/step - loss: 0.4934\n",
      "Epoch 4/10\n",
      "12828/12828 [==============================] - 9s 708us/step - loss: 0.4864\n",
      "Epoch 5/10\n",
      "12828/12828 [==============================] - 9s 701us/step - loss: 0.4818\n",
      "Epoch 6/10\n",
      "12828/12828 [==============================] - 9s 702us/step - loss: 0.4758\n",
      "Epoch 7/10\n",
      "12828/12828 [==============================] - 9s 719us/step - loss: 0.4713\n",
      "Epoch 8/10\n",
      "12828/12828 [==============================] - 9s 731us/step - loss: 0.4695\n",
      "Epoch 9/10\n",
      "12828/12828 [==============================] - 10s 754us/step - loss: 0.4667\n",
      "Epoch 10/10\n",
      "12828/12828 [==============================] - 9s 698us/step - loss: 0.4637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 559.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12825/12825 [==============================] - 12s 974us/step - loss: 0.6094\n",
      "Epoch 2/10\n",
      "12825/12825 [==============================] - 9s 700us/step - loss: 0.5290\n",
      "Epoch 3/10\n",
      "12825/12825 [==============================] - 9s 692us/step - loss: 0.5014\n",
      "Epoch 4/10\n",
      "12825/12825 [==============================] - 9s 717us/step - loss: 0.4912\n",
      "Epoch 5/10\n",
      "12825/12825 [==============================] - 10s 758us/step - loss: 0.4859\n",
      "Epoch 6/10\n",
      "12825/12825 [==============================] - 11s 830us/step - loss: 0.4830\n",
      "Epoch 7/10\n",
      "12825/12825 [==============================] - 10s 803us/step - loss: 0.4785\n",
      "Epoch 8/10\n",
      "12825/12825 [==============================] - 9s 682us/step - loss: 0.4772\n",
      "Epoch 9/10\n",
      "12825/12825 [==============================] - 9s 685us/step - loss: 0.4759\n",
      "Epoch 10/10\n",
      "12825/12825 [==============================] - 9s 682us/step - loss: 0.4741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 577.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12822/12822 [==============================] - 10s 749us/step - loss: 0.6337\n",
      "Epoch 2/10\n",
      "12822/12822 [==============================] - 8s 658us/step - loss: 0.5511\n",
      "Epoch 3/10\n",
      "12822/12822 [==============================] - 9s 710us/step - loss: 0.5241\n",
      "Epoch 4/10\n",
      "12822/12822 [==============================] - 9s 738us/step - loss: 0.5175\n",
      "Epoch 5/10\n",
      "12822/12822 [==============================] - 10s 779us/step - loss: 0.5083\n",
      "Epoch 6/10\n",
      "12822/12822 [==============================] - 11s 829us/step - loss: 0.5040\n",
      "Epoch 7/10\n",
      "12822/12822 [==============================] - 9s 688us/step - loss: 0.5001\n",
      "Epoch 8/10\n",
      "12822/12822 [==============================] - 9s 665us/step - loss: 0.4963\n",
      "Epoch 9/10\n",
      "12822/12822 [==============================] - 9s 677us/step - loss: 0.4932\n",
      "Epoch 10/10\n",
      "12822/12822 [==============================] - 8s 651us/step - loss: 0.4918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 680.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12819/12819 [==============================] - 10s 787us/step - loss: 0.6333\n",
      "Epoch 2/10\n",
      "12819/12819 [==============================] - 8s 643us/step - loss: 0.5480\n",
      "Epoch 3/10\n",
      "12819/12819 [==============================] - 9s 670us/step - loss: 0.5220\n",
      "Epoch 4/10\n",
      "12819/12819 [==============================] - 9s 685us/step - loss: 0.5139\n",
      "Epoch 5/10\n",
      "12819/12819 [==============================] - 9s 716us/step - loss: 0.5079\n",
      "Epoch 6/10\n",
      "12819/12819 [==============================] - 9s 694us/step - loss: 0.5052\n",
      "Epoch 7/10\n",
      "12819/12819 [==============================] - 9s 702us/step - loss: 0.5024\n",
      "Epoch 8/10\n",
      "12819/12819 [==============================] - 9s 709us/step - loss: 0.4999\n",
      "Epoch 9/10\n",
      "12819/12819 [==============================] - 9s 704us/step - loss: 0.4947\n",
      "Epoch 10/10\n",
      "12819/12819 [==============================] - 9s 679us/step - loss: 0.4942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 591.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12816/12816 [==============================] - 10s 807us/step - loss: 0.6257\n",
      "Epoch 2/10\n",
      "12816/12816 [==============================] - 9s 708us/step - loss: 0.5721\n",
      "Epoch 3/10\n",
      "12816/12816 [==============================] - 9s 718us/step - loss: 0.5409\n",
      "Epoch 4/10\n",
      "12816/12816 [==============================] - 9s 670us/step - loss: 0.5312\n",
      "Epoch 5/10\n",
      "12816/12816 [==============================] - 10s 771us/step - loss: 0.5243\n",
      "Epoch 6/10\n",
      "12816/12816 [==============================] - 10s 793us/step - loss: 0.5224\n",
      "Epoch 7/10\n",
      "12816/12816 [==============================] - 10s 743us/step - loss: 0.5171\n",
      "Epoch 8/10\n",
      "12816/12816 [==============================] - 10s 780us/step - loss: 0.5147\n",
      "Epoch 9/10\n",
      "12816/12816 [==============================] - 9s 689us/step - loss: 0.5153\n",
      "Epoch 10/10\n",
      "12816/12816 [==============================] - 9s 669us/step - loss: 0.5106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 663.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12812/12812 [==============================] - 9s 728us/step - loss: 0.6212\n",
      "Epoch 2/10\n",
      "12812/12812 [==============================] - 8s 607us/step - loss: 0.5618\n",
      "Epoch 3/10\n",
      "12812/12812 [==============================] - 10s 748us/step - loss: 0.5379\n",
      "Epoch 4/10\n",
      "12812/12812 [==============================] - 9s 730us/step - loss: 0.5294\n",
      "Epoch 5/10\n",
      "12812/12812 [==============================] - 9s 682us/step - loss: 0.5258\n",
      "Epoch 6/10\n",
      "12812/12812 [==============================] - 10s 788us/step - loss: 0.5210\n",
      "Epoch 7/10\n",
      "12812/12812 [==============================] - 9s 730us/step - loss: 0.5194\n",
      "Epoch 8/10\n",
      "12812/12812 [==============================] - 9s 736us/step - loss: 0.5175\n",
      "Epoch 9/10\n",
      "12812/12812 [==============================] - 10s 807us/step - loss: 0.5148\n",
      "Epoch 10/10\n",
      "12812/12812 [==============================] - 10s 758us/step - loss: 0.5124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 387.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12838/12838 [==============================] - 12s 905us/step - loss: 0.6225\n",
      "Epoch 2/10\n",
      "12838/12838 [==============================] - 10s 772us/step - loss: 0.5146\n",
      "Epoch 3/10\n",
      "12838/12838 [==============================] - 10s 816us/step - loss: 0.4706\n",
      "Epoch 4/10\n",
      "12838/12838 [==============================] - 9s 695us/step - loss: 0.4546\n",
      "Epoch 5/10\n",
      "12838/12838 [==============================] - 9s 700us/step - loss: 0.4439\n",
      "Epoch 6/10\n",
      "12838/12838 [==============================] - 9s 724us/step - loss: 0.4392\n",
      "Epoch 7/10\n",
      "12838/12838 [==============================] - 10s 741us/step - loss: 0.4295\n",
      "Epoch 8/10\n",
      "12838/12838 [==============================] - 9s 738us/step - loss: 0.4281\n",
      "Epoch 9/10\n",
      "12838/12838 [==============================] - 9s 738us/step - loss: 0.4253\n",
      "Epoch 10/10\n",
      "12838/12838 [==============================] - 9s 733us/step - loss: 0.4202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 715.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12835/12835 [==============================] - 11s 845us/step - loss: 0.6188\n",
      "Epoch 2/10\n",
      "12835/12835 [==============================] - 9s 697us/step - loss: 0.5169\n",
      "Epoch 3/10\n",
      "12835/12835 [==============================] - 9s 704us/step - loss: 0.4793\n",
      "Epoch 4/10\n",
      "12835/12835 [==============================] - 9s 715us/step - loss: 0.4690\n",
      "Epoch 5/10\n",
      "12835/12835 [==============================] - 10s 744us/step - loss: 0.4577\n",
      "Epoch 6/10\n",
      "12835/12835 [==============================] - 9s 739us/step - loss: 0.4501\n",
      "Epoch 7/10\n",
      "12835/12835 [==============================] - 9s 732us/step - loss: 0.4462\n",
      "Epoch 8/10\n",
      "12835/12835 [==============================] - 9s 732us/step - loss: 0.4415\n",
      "Epoch 9/10\n",
      "12835/12835 [==============================] - 9s 724us/step - loss: 0.4382\n",
      "Epoch 10/10\n",
      "12835/12835 [==============================] - 9s 738us/step - loss: 0.4349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 712.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12832/12832 [==============================] - 11s 826us/step - loss: 0.6024\n",
      "Epoch 2/10\n",
      "12832/12832 [==============================] - 9s 692us/step - loss: 0.4982\n",
      "Epoch 3/10\n",
      "12832/12832 [==============================] - 9s 707us/step - loss: 0.4794\n",
      "Epoch 4/10\n",
      "12832/12832 [==============================] - 9s 704us/step - loss: 0.4695\n",
      "Epoch 5/10\n",
      "12832/12832 [==============================] - 9s 715us/step - loss: 0.4628\n",
      "Epoch 6/10\n",
      "12832/12832 [==============================] - 9s 735us/step - loss: 0.4571\n",
      "Epoch 7/10\n",
      "12832/12832 [==============================] - 10s 746us/step - loss: 0.4518\n",
      "Epoch 8/10\n",
      "12832/12832 [==============================] - 9s 725us/step - loss: 0.4502\n",
      "Epoch 9/10\n",
      "12832/12832 [==============================] - 9s 716us/step - loss: 0.4477\n",
      "Epoch 10/10\n",
      "12832/12832 [==============================] - 9s 716us/step - loss: 0.4432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 739.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12828/12828 [==============================] - 11s 830us/step - loss: 0.6027\n",
      "Epoch 2/10\n",
      "12828/12828 [==============================] - 9s 703us/step - loss: 0.5092\n",
      "Epoch 3/10\n",
      "12828/12828 [==============================] - 9s 715us/step - loss: 0.4852\n",
      "Epoch 4/10\n",
      "12828/12828 [==============================] - 9s 739us/step - loss: 0.4773\n",
      "Epoch 5/10\n",
      "12828/12828 [==============================] - 13s 1ms/step - loss: 0.4708\n",
      "Epoch 6/10\n",
      "12828/12828 [==============================] - 11s 837us/step - loss: 0.4654\n",
      "Epoch 7/10\n",
      "12828/12828 [==============================] - 11s 891us/step - loss: 0.4624\n",
      "Epoch 8/10\n",
      "12828/12828 [==============================] - 10s 760us/step - loss: 0.4572\n",
      "Epoch 9/10\n",
      "12828/12828 [==============================] - 10s 775us/step - loss: 0.4557\n",
      "Epoch 10/10\n",
      "12828/12828 [==============================] - 10s 763us/step - loss: 0.4526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 598.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12825/12825 [==============================] - 11s 849us/step - loss: 0.6036\n",
      "Epoch 2/10\n",
      "12825/12825 [==============================] - 10s 780us/step - loss: 0.5267\n",
      "Epoch 3/10\n",
      "12825/12825 [==============================] - 10s 775us/step - loss: 0.4964\n",
      "Epoch 4/10\n",
      "12825/12825 [==============================] - 10s 781us/step - loss: 0.4897\n",
      "Epoch 5/10\n",
      "12825/12825 [==============================] - 10s 786us/step - loss: 0.4849\n",
      "Epoch 6/10\n",
      "12825/12825 [==============================] - 11s 863us/step - loss: 0.4804\n",
      "Epoch 7/10\n",
      "12825/12825 [==============================] - 10s 797us/step - loss: 0.4783\n",
      "Epoch 8/10\n",
      "12825/12825 [==============================] - 11s 847us/step - loss: 0.4752\n",
      "Epoch 9/10\n",
      "12825/12825 [==============================] - 9s 733us/step - loss: 0.4716\n",
      "Epoch 10/10\n",
      "12825/12825 [==============================] - 10s 803us/step - loss: 0.4676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 670.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12822/12822 [==============================] - 11s 847us/step - loss: 0.6169\n",
      "Epoch 2/10\n",
      "12822/12822 [==============================] - 9s 702us/step - loss: 0.5472\n",
      "Epoch 3/10\n",
      "12822/12822 [==============================] - 9s 720us/step - loss: 0.5142\n",
      "Epoch 4/10\n",
      "12822/12822 [==============================] - 11s 871us/step - loss: 0.5043\n",
      "Epoch 5/10\n",
      "12822/12822 [==============================] - 9s 728us/step - loss: 0.4966\n",
      "Epoch 6/10\n",
      "12822/12822 [==============================] - 10s 742us/step - loss: 0.4913\n",
      "Epoch 7/10\n",
      "12822/12822 [==============================] - 10s 790us/step - loss: 0.4894\n",
      "Epoch 8/10\n",
      "12822/12822 [==============================] - 10s 771us/step - loss: 0.4858\n",
      "Epoch 9/10\n",
      "12822/12822 [==============================] - 9s 733us/step - loss: 0.4824\n",
      "Epoch 10/10\n",
      "12822/12822 [==============================] - 12s 941us/step - loss: 0.4827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 724.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12819/12819 [==============================] - 11s 830us/step - loss: 0.6153\n",
      "Epoch 2/10\n",
      "12819/12819 [==============================] - 9s 734us/step - loss: 0.5521\n",
      "Epoch 3/10\n",
      "12819/12819 [==============================] - 11s 843us/step - loss: 0.5255\n",
      "Epoch 4/10\n",
      "12819/12819 [==============================] - 10s 755us/step - loss: 0.5173\n",
      "Epoch 5/10\n",
      "12819/12819 [==============================] - 9s 737us/step - loss: 0.5098\n",
      "Epoch 6/10\n",
      "12819/12819 [==============================] - 9s 731us/step - loss: 0.5025\n",
      "Epoch 7/10\n",
      "12819/12819 [==============================] - 10s 751us/step - loss: 0.5003\n",
      "Epoch 8/10\n",
      "12819/12819 [==============================] - 10s 754us/step - loss: 0.4977\n",
      "Epoch 9/10\n",
      "12819/12819 [==============================] - 13s 994us/step - loss: 0.4947\n",
      "Epoch 10/10\n",
      "12819/12819 [==============================] - 332s 26ms/step - loss: 0.4907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 362.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12816/12816 [==============================] - 14s 1ms/step - loss: 0.6128\n",
      "Epoch 2/10\n",
      "12816/12816 [==============================] - 11s 854us/step - loss: 0.5472\n",
      "Epoch 3/10\n",
      "12816/12816 [==============================] - 11s 849us/step - loss: 0.5279\n",
      "Epoch 4/10\n",
      "12816/12816 [==============================] - 10s 779us/step - loss: 0.5215\n",
      "Epoch 5/10\n",
      "12816/12816 [==============================] - 10s 749us/step - loss: 0.5151\n",
      "Epoch 6/10\n",
      "12816/12816 [==============================] - 9s 722us/step - loss: 0.5113\n",
      "Epoch 7/10\n",
      "12816/12816 [==============================] - 10s 749us/step - loss: 0.5090\n",
      "Epoch 8/10\n",
      "12816/12816 [==============================] - 10s 792us/step - loss: 0.5045\n",
      "Epoch 9/10\n",
      "12816/12816 [==============================] - 10s 773us/step - loss: 0.5023\n",
      "Epoch 10/10\n",
      "12816/12816 [==============================] - 10s 778us/step - loss: 0.4996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 524.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12812/12812 [==============================] - 12s 917us/step - loss: 0.6213\n",
      "Epoch 2/10\n",
      "12812/12812 [==============================] - 11s 882us/step - loss: 0.5530\n",
      "Epoch 3/10\n",
      "12812/12812 [==============================] - 10s 808us/step - loss: 0.5305\n",
      "Epoch 4/10\n",
      "12812/12812 [==============================] - 9s 704us/step - loss: 0.5224\n",
      "Epoch 5/10\n",
      "12812/12812 [==============================] - 9s 729us/step - loss: 0.5161\n",
      "Epoch 6/10\n",
      "12812/12812 [==============================] - 10s 813us/step - loss: 0.5153\n",
      "Epoch 7/10\n",
      "12812/12812 [==============================] - 9s 718us/step - loss: 0.5131\n",
      "Epoch 8/10\n",
      "12812/12812 [==============================] - 9s 728us/step - loss: 0.5089\n",
      "Epoch 9/10\n",
      "12812/12812 [==============================] - 9s 732us/step - loss: 0.5071\n",
      "Epoch 10/10\n",
      "12812/12812 [==============================] - 9s 715us/step - loss: 0.5069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 698.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12809/12809 [==============================] - 10s 811us/step - loss: 0.6266\n",
      "Epoch 2/10\n",
      "12809/12809 [==============================] - 9s 732us/step - loss: 0.5639\n",
      "Epoch 3/10\n",
      "12809/12809 [==============================] - 9s 733us/step - loss: 0.5411\n",
      "Epoch 4/10\n",
      "12809/12809 [==============================] - 9s 729us/step - loss: 0.5345\n",
      "Epoch 5/10\n",
      "12809/12809 [==============================] - 10s 797us/step - loss: 0.5304\n",
      "Epoch 6/10\n",
      "12809/12809 [==============================] - 11s 831us/step - loss: 0.5248\n",
      "Epoch 7/10\n",
      "12809/12809 [==============================] - 10s 764us/step - loss: 0.5209\n",
      "Epoch 8/10\n",
      "12809/12809 [==============================] - 10s 760us/step - loss: 0.5184\n",
      "Epoch 9/10\n",
      "12809/12809 [==============================] - 10s 747us/step - loss: 0.5180\n",
      "Epoch 10/10\n",
      "12809/12809 [==============================] - 9s 739us/step - loss: 0.5161\n"
     ]
    }
   ],
   "source": [
    "#Code to run models\n",
    "list_of_result_lists = {}\n",
    "models_list = [1]\n",
    "\n",
    "epochs = 10\n",
    "steps_in = 6\n",
    "steps_out = 10\n",
    "\n",
    "\n",
    "steps_in += 1\n",
    "steps_out += 1\n",
    "\n",
    "#will soon add a resample parameter to each model\n",
    "#(default to None if no resample, otherwise uses the desired sampler)\n",
    "#or use some other system for incorporating resample\n",
    "for m in models_list:\n",
    "    if m == 1:\n",
    "        results_list = train_SIMPLE_LSTM_model(epochs, steps_in, steps_out)\n",
    "    elif m == 3:\n",
    "        results_list = train_BIDIRECTIONAL_LSTM_model(epochs, steps_in, steps_out)\n",
    "    elif m == 6:\n",
    "        results_list = train_LSTM_AUTOENCODER_model(epochs, steps_in, steps_out)\n",
    "    elif m == 9:\n",
    "        results_list = train_GRU_CNN_model(epochs, steps_in, steps_out)\n",
    "    \n",
    "    list_of_result_lists[m] = results_list\n",
    "    plot_graphs_metrics(m, results_list, steps_in, steps_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_result_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_of_result_lists[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

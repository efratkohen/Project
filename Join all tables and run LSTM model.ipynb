{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import clean_data_svi as cds\n",
    "import supervised as sup\n",
    "import pathlib\n",
    "import keras_model as km\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from datetime import timedelta, datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import Input\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, LSTM, Bidirectional, Conv1D, MaxPooling1D, MaxPooling2D, Flatten, \\\n",
    "    TimeDistributed, RepeatVector, Dropout, GRU, AveragePooling1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error, median_absolute_error, roc_curve, auc, f1_score, \\\n",
    "    precision_recall_curve, r2_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVI_list = []\n",
    "for i in range(4):\n",
    "    df = pd.read_csv(f\"clean_tables/svi_{i+1}.csv\", index_col=\"date\")\n",
    "    df = df.drop(columns=['Settling_velocity', 'SV_label', 'SVI_label'])\n",
    "    df.index = pd.to_datetime(df.index, dayfirst=True)\n",
    "    SVI_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.read_csv(\"clean_tables/temperatur.csv\", index_col=\"date\")\n",
    "temp_df.index = pd.to_datetime(temp_df.index, dayfirst=True)\n",
    "sludge_age_df = pd.read_csv(\"clean_tables/sludge_age_f_m.csv\", index_col=\"date\")\n",
    "sludge_age_df.index = pd.to_datetime(sludge_age_df.index, dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactor_list = []\n",
    "for i in range(4):\n",
    "    join = pd.concat([SVI_list[i], temp_df], axis=1)\n",
    "    if i <=1:\n",
    "        join = pd.concat([join, sludge_age_df.iloc[:, np.r_[0, 2]]], axis=1)\n",
    "    else:\n",
    "        join = pd.concat([join, sludge_age_df.iloc[:, np.r_[1, 3]]], axis=1)\n",
    "    join.columns = ['SVI', 'Temperature', 'F_M', 'Sludge Age']\n",
    "    reactor_list.append(join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVI</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>F_M</th>\n",
       "      <th>Sludge Age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>94.066570</td>\n",
       "      <td>22.030</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02</th>\n",
       "      <td>95.318860</td>\n",
       "      <td>21.985</td>\n",
       "      <td>0.22</td>\n",
       "      <td>3.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-03</th>\n",
       "      <td>82.826748</td>\n",
       "      <td>21.740</td>\n",
       "      <td>0.22</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>95.307918</td>\n",
       "      <td>21.815</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>93.930636</td>\n",
       "      <td>21.890</td>\n",
       "      <td>0.23</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-27</th>\n",
       "      <td>144.736842</td>\n",
       "      <td>22.540</td>\n",
       "      <td>0.23</td>\n",
       "      <td>3.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-28</th>\n",
       "      <td>130.890052</td>\n",
       "      <td>22.535</td>\n",
       "      <td>0.24</td>\n",
       "      <td>3.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-29</th>\n",
       "      <td>140.306122</td>\n",
       "      <td>22.660</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-30</th>\n",
       "      <td>131.250000</td>\n",
       "      <td>22.660</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>147.453083</td>\n",
       "      <td>22.735</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4018 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   SVI  Temperature   F_M  Sludge Age\n",
       "date                                                 \n",
       "2010-01-01   94.066570       22.030  0.22        2.92\n",
       "2010-01-02   95.318860       21.985  0.22        3.04\n",
       "2010-01-03   82.826748       21.740  0.22        3.00\n",
       "2010-01-04   95.307918       21.815  0.22        2.97\n",
       "2010-01-05   93.930636       21.890  0.23        2.94\n",
       "...                ...          ...   ...         ...\n",
       "2020-12-27  144.736842       22.540  0.23        3.41\n",
       "2020-12-28  130.890052       22.535  0.24        3.10\n",
       "2020-12-29  140.306122       22.660  0.25        3.15\n",
       "2020-12-30  131.250000       22.660  0.25        3.32\n",
       "2020-12-31  147.453083       22.735  0.25        3.32\n",
       "\n",
       "[4018 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reactor_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_list = []\n",
    "for i in range(4):\n",
    "    df = pd.read_csv(f\"clean_tables/micro_{i+1}.csv\", index_col=\"date\")\n",
    "    df.index = pd.to_datetime(df.index, dayfirst=True)\n",
    "    micro_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arcella</th>\n",
       "      <th>nude ameba</th>\n",
       "      <th>aspidisca</th>\n",
       "      <th>trachelopylum</th>\n",
       "      <th>lionutus</th>\n",
       "      <th>paramecium</th>\n",
       "      <th>carchecium</th>\n",
       "      <th>epistylis</th>\n",
       "      <th>opercularia</th>\n",
       "      <th>podophyra</th>\n",
       "      <th>...</th>\n",
       "      <th>Floc Strength</th>\n",
       "      <th>Indian Ink</th>\n",
       "      <th>Filament index</th>\n",
       "      <th>Floc_size_small</th>\n",
       "      <th>Floc_size_medium</th>\n",
       "      <th>Floc_size_large</th>\n",
       "      <th>Shape_close</th>\n",
       "      <th>Shape_open</th>\n",
       "      <th>Filaments_in_floc</th>\n",
       "      <th>Free_filaments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-02-18</th>\n",
       "      <td>40.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-02</th>\n",
       "      <td>27.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-08</th>\n",
       "      <td>27.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-18</th>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-08</th>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-23</th>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-21</th>\n",
       "      <td>7.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-28</th>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-11</th>\n",
       "      <td>23.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-25</th>\n",
       "      <td>12.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>362 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            arcella  nude ameba  aspidisca  trachelopylum  lionutus  \\\n",
       "date                                                                  \n",
       "2010-02-18     40.0         4.0        2.0            0.0       6.0   \n",
       "2010-03-02     27.0         5.0        3.0            1.0      16.0   \n",
       "2010-03-08     27.0         8.0       14.0            1.0       9.0   \n",
       "2010-03-18     11.0        12.0        2.0            0.0      16.0   \n",
       "2010-04-08     12.0         6.0       10.0            0.0      13.0   \n",
       "...             ...         ...        ...            ...       ...   \n",
       "2020-09-23      5.0        11.0        9.0            2.0       5.0   \n",
       "2020-10-21      7.0        57.0       55.0            0.0      12.0   \n",
       "2020-10-28     14.0        20.0        1.0            0.0      24.0   \n",
       "2020-11-11     23.0        86.0       17.0            1.0      29.0   \n",
       "2020-11-25     12.0        56.0       64.0            0.0      18.0   \n",
       "\n",
       "            paramecium  carchecium  epistylis  opercularia  podophyra  ...  \\\n",
       "date                                                                   ...   \n",
       "2010-02-18         0.0         1.0        4.0          4.0        0.0  ...   \n",
       "2010-03-02         0.0         0.0       13.0          4.0        0.0  ...   \n",
       "2010-03-08         1.0         0.0       11.0          9.0        0.0  ...   \n",
       "2010-03-18         0.0         0.0        7.0          0.0        0.0  ...   \n",
       "2010-04-08         1.0         0.0        1.0          1.0        0.0  ...   \n",
       "...                ...         ...        ...          ...        ...  ...   \n",
       "2020-09-23         0.0         0.0        6.0          0.0        3.0  ...   \n",
       "2020-10-21         0.0        14.0       26.0          0.0        0.0  ...   \n",
       "2020-10-28         0.0         0.0       35.0          2.0        0.0  ...   \n",
       "2020-11-11         0.0         0.0       18.0          0.0        0.0  ...   \n",
       "2020-11-25         0.0         0.0       41.0          4.0        2.0  ...   \n",
       "\n",
       "            Floc Strength  Indian Ink  Filament index  Floc_size_small  \\\n",
       "date                                                                     \n",
       "2010-02-18            NaN         NaN             3.0              0.0   \n",
       "2010-03-02            NaN         NaN             3.0              NaN   \n",
       "2010-03-08            NaN         NaN             3.0              NaN   \n",
       "2010-03-18            NaN         NaN             3.0              0.0   \n",
       "2010-04-08            NaN         NaN             3.0              0.0   \n",
       "...                   ...         ...             ...              ...   \n",
       "2020-09-23            3.0         1.0             2.0              0.0   \n",
       "2020-10-21            1.0         3.0             3.0              1.0   \n",
       "2020-10-28            2.0         3.0             2.5              1.0   \n",
       "2020-11-11            3.0         2.0             2.5              1.0   \n",
       "2020-11-25            1.0         2.0             2.5              1.0   \n",
       "\n",
       "            Floc_size_medium  Floc_size_large  Shape_close  Shape_open  \\\n",
       "date                                                                     \n",
       "2010-02-18               1.0              1.0          0.0         1.0   \n",
       "2010-03-02               NaN              NaN          0.0         1.0   \n",
       "2010-03-08               NaN              NaN          1.0         1.0   \n",
       "2010-03-18               1.0              1.0          0.0         1.0   \n",
       "2010-04-08               1.0              1.0          0.0         1.0   \n",
       "...                      ...              ...          ...         ...   \n",
       "2020-09-23               1.0              1.0          1.0         1.0   \n",
       "2020-10-21               1.0              1.0          0.0         1.0   \n",
       "2020-10-28               1.0              1.0          1.0         1.0   \n",
       "2020-11-11               1.0              1.0          1.0         1.0   \n",
       "2020-11-25               1.0              1.0          0.0         1.0   \n",
       "\n",
       "            Filaments_in_floc  Free_filaments  \n",
       "date                                           \n",
       "2010-02-18                1.0             1.0  \n",
       "2010-03-02                1.0             0.0  \n",
       "2010-03-08                1.0             1.0  \n",
       "2010-03-18                1.0             1.0  \n",
       "2010-04-08                1.0             1.0  \n",
       "...                       ...             ...  \n",
       "2020-09-23                1.0             1.0  \n",
       "2020-10-21                1.0             1.0  \n",
       "2020-10-28                1.0             1.0  \n",
       "2020-11-11                1.0             1.0  \n",
       "2020-11-25                1.0             1.0  \n",
       "\n",
       "[362 rows x 37 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_list = []\n",
    "for i in range(4):\n",
    "    join = pd.concat([reactor_list[i], micro_list[i]], axis=1)\n",
    "    join_list.append(join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVI</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>F_M</th>\n",
       "      <th>Sludge Age</th>\n",
       "      <th>arcella</th>\n",
       "      <th>nude ameba</th>\n",
       "      <th>aspidisca</th>\n",
       "      <th>trachelopylum</th>\n",
       "      <th>lionutus</th>\n",
       "      <th>paramecium</th>\n",
       "      <th>...</th>\n",
       "      <th>Floc Strength</th>\n",
       "      <th>Indian Ink</th>\n",
       "      <th>Filament index</th>\n",
       "      <th>Floc_size_small</th>\n",
       "      <th>Floc_size_medium</th>\n",
       "      <th>Floc_size_large</th>\n",
       "      <th>Shape_close</th>\n",
       "      <th>Shape_open</th>\n",
       "      <th>Filaments_in_floc</th>\n",
       "      <th>Free_filaments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>88.649852</td>\n",
       "      <td>22.030</td>\n",
       "      <td>0.23</td>\n",
       "      <td>3.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02</th>\n",
       "      <td>86.480363</td>\n",
       "      <td>21.985</td>\n",
       "      <td>0.18</td>\n",
       "      <td>3.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-03</th>\n",
       "      <td>96.370968</td>\n",
       "      <td>21.740</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>109.427609</td>\n",
       "      <td>21.815</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>100.929054</td>\n",
       "      <td>21.890</td>\n",
       "      <td>0.23</td>\n",
       "      <td>3.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-27</th>\n",
       "      <td>159.420290</td>\n",
       "      <td>22.540</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-28</th>\n",
       "      <td>147.887324</td>\n",
       "      <td>22.535</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-29</th>\n",
       "      <td>152.173913</td>\n",
       "      <td>22.660</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-30</th>\n",
       "      <td>148.725212</td>\n",
       "      <td>22.660</td>\n",
       "      <td>0.27</td>\n",
       "      <td>2.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>152.777778</td>\n",
       "      <td>22.735</td>\n",
       "      <td>0.27</td>\n",
       "      <td>2.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4018 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   SVI  Temperature   F_M  Sludge Age  arcella  nude ameba  \\\n",
       "date                                                                         \n",
       "2010-01-01   88.649852       22.030  0.23        3.44      NaN         NaN   \n",
       "2010-01-02   86.480363       21.985  0.18        3.78      NaN         NaN   \n",
       "2010-01-03   96.370968       21.740  0.21        3.82      NaN         NaN   \n",
       "2010-01-04  109.427609       21.815  0.21        3.40      NaN         NaN   \n",
       "2010-01-05  100.929054       21.890  0.23        3.70      NaN         NaN   \n",
       "...                ...          ...   ...         ...      ...         ...   \n",
       "2020-12-27  159.420290       22.540  0.25        2.75      NaN         NaN   \n",
       "2020-12-28  147.887324       22.535  0.26        2.91      NaN         NaN   \n",
       "2020-12-29  152.173913       22.660  0.26        2.82      NaN         NaN   \n",
       "2020-12-30  148.725212       22.660  0.27        2.91      NaN         NaN   \n",
       "2020-12-31  152.777778       22.735  0.27        2.91      NaN         NaN   \n",
       "\n",
       "            aspidisca  trachelopylum  lionutus  paramecium  ...  \\\n",
       "date                                                        ...   \n",
       "2010-01-01        NaN            NaN       NaN         NaN  ...   \n",
       "2010-01-02        NaN            NaN       NaN         NaN  ...   \n",
       "2010-01-03        NaN            NaN       NaN         NaN  ...   \n",
       "2010-01-04        NaN            NaN       NaN         NaN  ...   \n",
       "2010-01-05        NaN            NaN       NaN         NaN  ...   \n",
       "...               ...            ...       ...         ...  ...   \n",
       "2020-12-27        NaN            NaN       NaN         NaN  ...   \n",
       "2020-12-28        NaN            NaN       NaN         NaN  ...   \n",
       "2020-12-29        NaN            NaN       NaN         NaN  ...   \n",
       "2020-12-30        NaN            NaN       NaN         NaN  ...   \n",
       "2020-12-31        NaN            NaN       NaN         NaN  ...   \n",
       "\n",
       "            Floc Strength  Indian Ink  Filament index  Floc_size_small  \\\n",
       "date                                                                     \n",
       "2010-01-01            NaN         NaN             NaN              NaN   \n",
       "2010-01-02            NaN         NaN             NaN              NaN   \n",
       "2010-01-03            NaN         NaN             NaN              NaN   \n",
       "2010-01-04            NaN         NaN             NaN              NaN   \n",
       "2010-01-05            NaN         NaN             NaN              NaN   \n",
       "...                   ...         ...             ...              ...   \n",
       "2020-12-27            NaN         NaN             NaN              NaN   \n",
       "2020-12-28            NaN         NaN             NaN              NaN   \n",
       "2020-12-29            NaN         NaN             NaN              NaN   \n",
       "2020-12-30            NaN         NaN             NaN              NaN   \n",
       "2020-12-31            NaN         NaN             NaN              NaN   \n",
       "\n",
       "            Floc_size_medium  Floc_size_large  Shape_close  Shape_open  \\\n",
       "date                                                                     \n",
       "2010-01-01               NaN              NaN          NaN         NaN   \n",
       "2010-01-02               NaN              NaN          NaN         NaN   \n",
       "2010-01-03               NaN              NaN          NaN         NaN   \n",
       "2010-01-04               NaN              NaN          NaN         NaN   \n",
       "2010-01-05               NaN              NaN          NaN         NaN   \n",
       "...                      ...              ...          ...         ...   \n",
       "2020-12-27               NaN              NaN          NaN         NaN   \n",
       "2020-12-28               NaN              NaN          NaN         NaN   \n",
       "2020-12-29               NaN              NaN          NaN         NaN   \n",
       "2020-12-30               NaN              NaN          NaN         NaN   \n",
       "2020-12-31               NaN              NaN          NaN         NaN   \n",
       "\n",
       "            Filaments_in_floc  Free_filaments  \n",
       "date                                           \n",
       "2010-01-01                NaN             NaN  \n",
       "2010-01-02                NaN             NaN  \n",
       "2010-01-03                NaN             NaN  \n",
       "2010-01-04                NaN             NaN  \n",
       "2010-01-05                NaN             NaN  \n",
       "...                       ...             ...  \n",
       "2020-12-27                NaN             NaN  \n",
       "2020-12-28                NaN             NaN  \n",
       "2020-12-29                NaN             NaN  \n",
       "2020-12-30                NaN             NaN  \n",
       "2020-12-31                NaN             NaN  \n",
       "\n",
       "[4018 rows x 41 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = km.create_join_x_y_arr(join_list, n_steps_in=7, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 90.94368341,  22.03      ,   0.23      , ...,          nan,\n",
       "                  nan,          nan],\n",
       "        [ 84.36532508,  21.985     ,   0.18      , ...,          nan,\n",
       "                  nan,          nan],\n",
       "        [ 94.54113924,  21.74      ,   0.21      , ...,          nan,\n",
       "                  nan,          nan],\n",
       "        ...,\n",
       "        [107.93768546,  21.89      ,   0.23      , ...,          nan,\n",
       "                  nan,          nan],\n",
       "        [ 89.8744113 ,  21.73      ,   0.2       , ...,          nan,\n",
       "                  nan,          nan],\n",
       "        [ 94.62809917,  21.655     ,   0.21      , ...,          nan,\n",
       "                  nan,          nan]],\n",
       "\n",
       "       [[ 84.36532508,  21.985     ,   0.18      , ...,          nan,\n",
       "                  nan,          nan],\n",
       "        [ 94.54113924,  21.74      ,   0.21      , ...,          nan,\n",
       "                  nan,          nan],\n",
       "        [ 97.4025974 ,  21.815     ,   0.21      , ...,          nan,\n",
       "                  nan,          nan],\n",
       "        ...,\n",
       "        [ 89.8744113 ,  21.73      ,   0.2       , ...,          nan,\n",
       "                  nan,          nan],\n",
       "        [ 94.62809917,  21.655     ,   0.21      , ...,          nan,\n",
       "                  nan,          nan],\n",
       "        [ 78.85674931,  21.68      ,   0.23      , ...,          nan,\n",
       "                  nan,          nan]],\n",
       "\n",
       "       [[ 94.54113924,  21.74      ,   0.21      , ...,          nan,\n",
       "                  nan,          nan],\n",
       "        [ 97.4025974 ,  21.815     ,   0.21      , ...,          nan,\n",
       "                  nan,          nan],\n",
       "        [107.93768546,  21.89      ,   0.23      , ...,          nan,\n",
       "                  nan,          nan],\n",
       "        ...,\n",
       "        [ 94.62809917,  21.655     ,   0.21      , ...,          nan,\n",
       "                  nan,          nan],\n",
       "        [ 78.85674931,  21.68      ,   0.23      , ...,          nan,\n",
       "                  nan,          nan],\n",
       "        [ 82.85094067,  21.545     ,   0.23      , ...,          nan,\n",
       "                  nan,          nan]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[116.70761671,  23.38      ,   0.26      , ...,          nan,\n",
       "                  nan,          nan],\n",
       "        [115.08951407,  23.395     ,   0.26      , ...,          nan,\n",
       "                  nan,          nan],\n",
       "        [138.53904282,  23.14      ,   0.25      , ...,          nan,\n",
       "                  nan,          nan],\n",
       "        ...,\n",
       "        [124.6882793 ,  22.77      ,   0.22      , ...,          nan,\n",
       "                  nan,          nan],\n",
       "        [143.22916667,  22.54      ,   0.23      , ...,          nan,\n",
       "                  nan,          nan],\n",
       "        [125.6281407 ,  22.535     ,   0.24      , ...,          nan,\n",
       "                  nan,          nan]],\n",
       "\n",
       "       [[115.08951407,  23.395     ,   0.26      , ...,          nan,\n",
       "                  nan,          nan],\n",
       "        [138.53904282,  23.14      ,   0.25      , ...,          nan,\n",
       "                  nan,          nan],\n",
       "        [158.50144092,  22.66      ,   0.28      , ...,          nan,\n",
       "                  nan,          nan],\n",
       "        ...,\n",
       "        [143.22916667,  22.54      ,   0.23      , ...,          nan,\n",
       "                  nan,          nan],\n",
       "        [125.6281407 ,  22.535     ,   0.24      , ...,          nan,\n",
       "                  nan,          nan],\n",
       "        [145.93908629,  22.66      ,   0.25      , ...,          nan,\n",
       "                  nan,          nan]],\n",
       "\n",
       "       [[138.53904282,  23.14      ,   0.25      , ...,          nan,\n",
       "                  nan,          nan],\n",
       "        [158.50144092,  22.66      ,   0.28      , ...,          nan,\n",
       "                  nan,          nan],\n",
       "        [124.6882793 ,  22.77      ,   0.22      , ...,          nan,\n",
       "                  nan,          nan],\n",
       "        ...,\n",
       "        [125.6281407 ,  22.535     ,   0.24      , ...,          nan,\n",
       "                  nan,          nan],\n",
       "        [145.93908629,  22.66      ,   0.25      , ...,          nan,\n",
       "                  nan,          nan],\n",
       "        [137.15710723,  22.66      ,   0.25      , ...,          nan,\n",
       "                  nan,          nan]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16044, 7, 41)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 72.89it/s]\n"
     ]
    }
   ],
   "source": [
    "X_normalize, Y_normalize, scalers = km.normalize(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normalize = np.nan_to_num(X_normalize, nan=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17449926, 0.37586548, 0.3255814 , 0.27717391,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan],\n",
       "       [0.15989432, 0.37289812, 0.20930233, 0.32336957,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan],\n",
       "       [0.18248614, 0.3567425 , 0.27906977, 0.32880435,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan],\n",
       "       [0.18883901, 0.3616881 , 0.27906977, 0.27173913,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan],\n",
       "       [0.21222847, 0.3666337 , 0.3255814 , 0.3125    ,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan],\n",
       "       [0.17212531, 0.35608309, 0.25581395, 0.36277174,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan],\n",
       "       [0.18267921, 0.35113749, 0.27906977, 0.30570652,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16044, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_normalize.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X_normalize, Y_normalize, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "14439/14439 [==============================] - 13s 905us/step - loss: 0.5527 - binary_accuracy: 0.6901\n",
      "Epoch 2/3\n",
      "14439/14439 [==============================] - 12s 824us/step - loss: 0.4539 - binary_accuracy: 0.7427\n",
      "Epoch 3/3\n",
      "14439/14439 [==============================] - 12s 806us/step - loss: 0.4254 - binary_accuracy: 0.7644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f8973b1d650>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X_normalize, Y_normalize, test_size=0.10, random_state=42)\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, activation='relu', name='first_lstm', recurrent_dropout=0.1, input_shape=(Xtrain.shape[1], Xtrain.shape[2])))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', \n",
    "              metrics=[keras.metrics.BinaryAccuracy(name='binary_accuracy', dtype=None, threshold=0.5)])\n",
    "model.fit(Xtrain, ytrain, epochs=3, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yhat, Ytest = km.evaluate(model, Xtest, ytest, scalers, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1605, 7, 41)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8761754 ],\n",
       "       [0.9782087 ],\n",
       "       [0.98512554],\n",
       "       ...,\n",
       "       [0.9842793 ],\n",
       "       [0.9116802 ],\n",
       "       [0.88895434]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_real = Ytest.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_for_max_f1(y_real, Yhat):\n",
    "    '''\n",
    "    Given inputs y_real and y_predict, the function returns\n",
    "    the threshold (rounded to the nearest hundredth) that\n",
    "    maximizes f1.\n",
    "    \n",
    "    Note: this func not necessarily optimized, could return to \n",
    "    doing this but not needed).\n",
    "    '''\n",
    "    f1_vals = []\n",
    "    for i in range(1, 100):\n",
    "        threshold = i/100\n",
    "        y_predict = np.where(Yhat > threshold, 1, 0).astype(int)\n",
    "        y_real = Ytest.astype(int)\n",
    "        \n",
    "        f1 = km.results(y_real, y_predict, binary=True)[3]\n",
    "        \n",
    "        if f1>0 and f1<1:\n",
    "            f1_vals.append(f1)\n",
    "        else:\n",
    "            f1_vals.append(-1)            \n",
    "\n",
    "    return (f1_vals.index(max(f1_vals))+1)/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = threshold_for_max_f1(y_real, Yhat)\n",
    "y_predict = np.where(Yhat > threshold, 1, 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['High_svi', 'Low_svi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_real, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[371 141]\n",
      " [152 941]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sup.plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = km.results(y_real, y_predict, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8174454828660436, 0.724609375, 0.7093690248565966, 0.7169082125603865)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results #accuracy, recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(Ytest, Yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8829983417200367"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'ROC curve')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = {1: 'Simple LSTM',\n",
    "               2: 'Stacked LSTM',\n",
    "               3: 'Bidirectional LSTM',\n",
    "               4: 'CNN',\n",
    "               5: 'CNN LSTM',\n",
    "               6: 'LSTM Autoencoder',\n",
    "               7: 'Deep CNN',\n",
    "               8: 'GRU',\n",
    "               9: 'GRU CNN'}\n",
    "\n",
    "def plot_graphs_metrics(model, results_list, steps_in, steps_out):\n",
    "    model_name = model_names[model]\n",
    "    \n",
    "    #plot graph of a metric result for all n_step_in and n_step_out values\n",
    "    x=list(range(1, steps_out))\n",
    "    label = ['accuracy', 'TNR', 'NPV', 'f1']\n",
    "    for z in range(4):\n",
    "        for i in range(steps_in-1):\n",
    "            y=[]\n",
    "            for j in range(steps_out-1):\n",
    "                y.append(results_list[i*(steps_out-1):i*(steps_out-1) + (steps_out-1)][j][z])\n",
    "            plt.plot(x, y, label=f'n_steps_in={i+1}')\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        plt.xlabel(\"n_steps_out\")\n",
    "        plt.ylabel(label[z])\n",
    "        #change Simple LSTM to a variable\n",
    "        plt.title(model_name + \", 3 layers (50,25,1),\\n name='first_lstm', recurrent_dropout=0.1 \\n optimizer='adam', loss='binary_crossentropy' \")\n",
    "        #change Simple LSTM to a variable\n",
    "        plt.savefig(f\"figures/{model_name} {label[z]}.png\", bbox_inches=\"tight\")\n",
    "        plt.close()    \n",
    "    \n",
    "    #plot graph of all metric results for a n_step_in value\n",
    "    x=list(range(1, steps_out))\n",
    "    label = ['accuracy', 'TNR', 'NPV', 'f1']\n",
    "    for z in range(steps_in-1):\n",
    "        for i in range(4):\n",
    "            y=[]\n",
    "            for j in range(steps_out-1):\n",
    "                y.append(results_list[z*(steps_out-1):z*(steps_out-1)+(steps_out-1)][j][i])\n",
    "            plt.plot(x, y, label=label[i])\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        plt.xlabel(\"n_steps_out\")\n",
    "        plt.ylabel('Metric value')\n",
    "        #change Simple LSTM to a variable\n",
    "        plt.title(f\"{model_name}, 3 layers (50,25,1),\\n name='first_lstm', recurrent_dropout=0.1 \\n optimizer='adam', loss='binary_crossentropy' \\n n_steps_in={z+1} \")\n",
    "        #change Simple LSTM to a variable\n",
    "        plt.savefig(f\"figures/{model_name} n_steps_in={z+1}.png\", bbox_inches=\"tight\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model type 1\n",
    "def train_SIMPLE_LSTM_model(epochs, steps_in, steps_out):\n",
    "    results_list = []\n",
    "    for i in range(1, steps_in):\n",
    "        for j in range(1, steps_out):\n",
    "            X, Y = km.create_join_x_y_arr(reactor_list, n_steps_in=i, n_steps_out=j, binary=True)\n",
    "            X_normalize, Y_normalize, scalers = km.normalize(X, Y)\n",
    "            Xtrain, Xtest, ytrain, ytest = train_test_split(X_normalize, Y_normalize, test_size=0.20, random_state=42)\n",
    "            \n",
    "            model = Sequential()\n",
    "            model.add(LSTM(units=50, activation='relu', name='first_lstm', recurrent_dropout=0.1, input_shape=(Xtrain.shape[1], Xtrain.shape[2])))\n",
    "            model.add(Dense(25, activation='relu'))\n",
    "            model.add(Dense(1, activation=\"sigmoid\"))\n",
    "            \n",
    "            model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy')\n",
    "            model.fit(Xtrain, ytrain, epochs=epochs, batch_size=10, shuffle=True)\n",
    "            Yhat, Ytest = km.evaluate(model, Xtest, ytest, scalers, binary=True)\n",
    "            y_predict = np.rint(Yhat).astype(int)\n",
    "            y_real = Ytest.astype(int)\n",
    "            results_list.append(km.results(y_real, y_predict))\n",
    "    return results_list\n",
    "\n",
    "###Just need to fill out the three functions for below. All other infrastructure is handled.###\n",
    "\n",
    "#Model type 3\n",
    "def train_BIDIRECTIONAL_LSTM_model(epochs, steps_in, steps_out):\n",
    "    results_list = []\n",
    "    for i in range(1, steps_in):\n",
    "        for j in range(1, steps_out):\n",
    "            X, Y = km.create_join_x_y_arr(reactor_list, n_steps_in=i, n_steps_out=j, binary=True)\n",
    "            X_normalize, Y_normalize, scalers = km.normalize(X, Y)\n",
    "            Xtrain, Xtest, ytrain, ytest = train_test_split(X_normalize, Y_normalize, test_size=0.20, random_state=42)\n",
    "            \n",
    "            \n",
    "            model = Sequential()\n",
    "            model.add(Bidirectional(LSTM(100, return_sequences=True, activation='relu')))\n",
    "            model.add(Bidirectional(LSTM(50, return_sequences=True, activation='relu')))\n",
    "            model.add(Bidirectional(LSTM(20, activation='relu')))\n",
    "            model.add(Dense(1, activation=\"sigmoid\"))\n",
    "            \n",
    "            model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy')\n",
    "            model.fit(Xtrain, ytrain, epochs=epochs, batch_size=10, shuffle=True)\n",
    "            Yhat, Ytest = km.evaluate(model, Xtest, ytest, scalers, binary=True)\n",
    "            y_predict = np.rint(Yhat).astype(int)\n",
    "            y_real = Ytest.astype(int)\n",
    "            results_list.append(km.results(y_real, y_predict))\n",
    "    return results_list\n",
    "\n",
    "#Model type 6 - having lots of trouble with this one\n",
    "#For some reason we need steps_in to be at least 3 for this one\n",
    "#This probably has to do with the pooling, Convolution, or Dropout layers\n",
    "def train_LSTM_AUTOENCODER_model(epochs, steps_in, steps_out):\n",
    "    results_list = []\n",
    "    for i in range(3, steps_in):\n",
    "        for j in range(1, steps_out):\n",
    "            X, Y = km.create_join_x_y_arr(join_list, n_steps_in=3, n_steps_out = 1, binary=True)\n",
    "            X_normalize, Y_normalize, scalers = km.normalize(X, Y)\n",
    "            X_normalize = np.nan_to_num(X_normalize, nan=-1)\n",
    "            Xtrain, Xtest, ytrain, ytest = train_test_split(X_normalize, Y_normalize, test_size=0.20, random_state=42)\n",
    "\n",
    "            model = Sequential()\n",
    "            model.add(Conv1D(filters=128, \n",
    "                             kernel_size=2, \n",
    "                             activation='relu', \n",
    "                             name='extractor', \n",
    "                             input_shape=(Xtrain.shape[1], Xtrain.shape[2])))\n",
    "            model.add(Dropout(0.3))\n",
    "            model.add(MaxPooling1D(pool_size=2))\n",
    "            model.add(Bidirectional(LSTM(50, activation='relu', input_shape=(Xtrain.shape[1], Xtrain.shape[2]))))\n",
    "            model.add(RepeatVector(10))\n",
    "            model.add(Bidirectional(LSTM(50, activation='relu')))\n",
    "            model.add(Dense(1))\n",
    "\n",
    "            model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy')\n",
    "            model.fit(Xtrain, ytrain, epochs=epochs, batch_size=10, shuffle=True)\n",
    "\n",
    "            Yhat, Ytest = km.evaluate(model, Xtest, ytest, scalers, binary=True)\n",
    "            y_real = Ytest.astype(int)\n",
    "            threshold = threshold_for_max_f1(y_real, Yhat)\n",
    "            y_predict = np.where(Yhat > threshold, 1, 0).astype(int)\n",
    "            \n",
    "            results_list.append(km.results(y_real, y_predict))\n",
    "    return results_list\n",
    "\n",
    "#Model type 9 - having lots of trouble with this one\n",
    "def train_GRU_CNN_model(epochs, steps_in, steps_out):\n",
    "#     results_list = []\n",
    "#     for i in range(1, steps_in):\n",
    "#         for j in range(1, steps_out):\n",
    "#             X, Y = km.create_join_x_y_arr(reactor_list, n_steps_in=i, n_steps_out=j, binary=True)\n",
    "#             X_normalize, Y_normalize, scalers = km.normalize(X, Y)\n",
    "#             Xtrain, Xtest, ytrain, ytest = train_test_split(X_normalize, Y_normalize, test_size=0.20, random_state=42)\n",
    "            \n",
    "            \n",
    "#             inp_seq = Input(shape=(Xtrain.shape[1], Xtrain.shape[2]))\n",
    "#             x = Bidirectional(GRU(100, return_sequences=True))(inp_seq)\n",
    "#             x = AveragePooling1D(2)(x)\n",
    "#             x = Conv1D(100, 3, activation='relu', padding='same',\n",
    "#                        name='extractor')(x)\n",
    "#             x = Flatten()(x)\n",
    "#             x = Dense(16, activation='relu')(x)\n",
    "#             x = Dropout(0.5)(x)\n",
    "\n",
    "#             out = Dense(1, activation=LAST_ACTIVATION)(x)\n",
    "\n",
    "#             model = Model(inp_seq, out)\n",
    "\n",
    "            \n",
    "#             model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy')\n",
    "#             model.fit(Xtrain, ytrain, epochs=epochs, batch_size=10, shuffle=True)\n",
    "#             Yhat, Ytest = km.evaluate(model, Xtest, ytest, scalers, binary=True)\n",
    "#             y_predict = np.rint(Yhat).astype(int)\n",
    "#             y_real = Ytest.astype(int)\n",
    "#             results_list.append(km.results(y_real, y_predict))\n",
    "#     return results_list\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 65.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "12848/12848 [==============================] - 46s 4ms/step - loss: 0.6399\n",
      "Epoch 2/2\n",
      "12848/12848 [==============================] - 42s 3ms/step - loss: 0.6032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sammitchell/Desktop/Mekorot/Project/keras_model.py:93: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  NPV = (tn) / (tn + fn)\n",
      "/Users/sammitchell/Desktop/Mekorot/Project/keras_model.py:93: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  NPV = (tn) / (tn + fn)\n",
      "/Users/sammitchell/Desktop/Mekorot/Project/keras_model.py:93: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  NPV = (tn) / (tn + fn)\n",
      "/Users/sammitchell/Desktop/Mekorot/Project/keras_model.py:93: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  NPV = (tn) / (tn + fn)\n",
      "/Users/sammitchell/Desktop/Mekorot/Project/keras_model.py:93: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  NPV = (tn) / (tn + fn)\n",
      "/Users/sammitchell/Desktop/Mekorot/Project/keras_model.py:93: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  NPV = (tn) / (tn + fn)\n",
      "/Users/sammitchell/Desktop/Mekorot/Project/keras_model.py:93: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  NPV = (tn) / (tn + fn)\n",
      "/Users/sammitchell/Desktop/Mekorot/Project/keras_model.py:93: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  NPV = (tn) / (tn + fn)\n",
      "/Users/sammitchell/Desktop/Mekorot/Project/keras_model.py:93: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  NPV = (tn) / (tn + fn)\n",
      "/Users/sammitchell/Desktop/Mekorot/Project/keras_model.py:93: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  NPV = (tn) / (tn + fn)\n",
      "/Users/sammitchell/Desktop/Mekorot/Project/keras_model.py:93: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  NPV = (tn) / (tn + fn)\n",
      "/Users/sammitchell/Desktop/Mekorot/Project/keras_model.py:93: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  NPV = (tn) / (tn + fn)\n",
      "/Users/sammitchell/Desktop/Mekorot/Project/keras_model.py:93: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  NPV = (tn) / (tn + fn)\n",
      "/Users/sammitchell/Desktop/Mekorot/Project/keras_model.py:93: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  NPV = (tn) / (tn + fn)\n",
      "/Users/sammitchell/Desktop/Mekorot/Project/keras_model.py:93: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  NPV = (tn) / (tn + fn)\n",
      "/Users/sammitchell/Desktop/Mekorot/Project/keras_model.py:93: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  NPV = (tn) / (tn + fn)\n",
      "/Users/sammitchell/Desktop/Mekorot/Project/keras_model.py:93: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  NPV = (tn) / (tn + fn)\n",
      "/Users/sammitchell/Desktop/Mekorot/Project/keras_model.py:93: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  NPV = (tn) / (tn + fn)\n",
      "/Users/sammitchell/Desktop/Mekorot/Project/keras_model.py:93: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  NPV = (tn) / (tn + fn)\n"
     ]
    }
   ],
   "source": [
    "X, Y = km.create_join_x_y_arr(join_list, n_steps_in=3, n_steps_out = 1, binary=True)\n",
    "X_normalize, Y_normalize, scalers = km.normalize(X, Y)\n",
    "X_normalize = np.nan_to_num(X_normalize, nan=-1)\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X_normalize, Y_normalize, test_size=0.20, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=128, \n",
    "                 kernel_size=2, \n",
    "                 activation='relu', \n",
    "                 name='extractor', \n",
    "                 input_shape=(Xtrain.shape[1], Xtrain.shape[2])))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Bidirectional(LSTM(50, activation='relu', input_shape=(Xtrain.shape[1], Xtrain.shape[2]))))\n",
    "model.add(RepeatVector(10))\n",
    "model.add(Bidirectional(LSTM(50, activation='relu')))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy')\n",
    "model.fit(Xtrain, ytrain, epochs=epochs, batch_size=10, shuffle=True)\n",
    "\n",
    "Yhat, Ytest = km.evaluate(model, Xtest, ytest, scalers, binary=True)\n",
    "y_real = Ytest.astype(int)\n",
    "threshold = threshold_for_max_f1(y_real, Yhat)\n",
    "y_predict = np.where(Yhat > threshold, 1, 0).astype(int)\n",
    "\n",
    "km.results(y_real, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7235367372353674,\n",
       " 0.6863905325443787,\n",
       " 0.5497630331753555,\n",
       " 0.6105263157894737)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.results(y_real, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 62.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "12848/12848 [==============================] - 45s 4ms/step - loss: 0.7309\n",
      "Epoch 2/2\n",
      "12848/12848 [==============================] - 41s 3ms/step - loss: 0.6011\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1605, 3212]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-038b298efc69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mresults_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_BIDIRECTIONAL_LSTM_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mresults_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_LSTM_AUTOENCODER_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mresults_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_GRU_CNN_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-2584ffe2b53b>\u001b[0m in \u001b[0;36mtrain_LSTM_AUTOENCODER_model\u001b[0;34m(epochs, steps_in, steps_out)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mYhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0my_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreshold_for_max_f1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYhat\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-d051fadb9027>\u001b[0m in \u001b[0;36mthreshold_for_max_f1\u001b[0;34m(y_real, Yhat)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0my_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Mekorot/Project/keras_model.py\u001b[0m in \u001b[0;36mresults\u001b[0;34m(y_real, y_predict, binary)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mtn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/TF/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/TF/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \"\"\"\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/TF/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/TF/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 320\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1605, 3212]"
     ]
    }
   ],
   "source": [
    "\n",
    "list_of_result_lists = {}\n",
    "models_list = [6]\n",
    "\n",
    "epochs = 2\n",
    "steps_in = 4\n",
    "steps_out = 2\n",
    "\n",
    "for m in models_list:\n",
    "    if m == 1:\n",
    "        results_list = train_SIMPLE_LSTM_model(epochs, steps_in, steps_out)\n",
    "    elif m == 3:\n",
    "        results_list = train_BIDIRECTIONAL_LSTM_model(epochs, steps_in, steps_out)\n",
    "    elif m == 6:\n",
    "        results_list = train_LSTM_AUTOENCODER_model(epochs, steps_in, steps_out)\n",
    "    elif m == 9:\n",
    "        results_list = train_GRU_CNN_model(epochs, steps_in, steps_out)\n",
    "    \n",
    "    list_of_result_lists[m] = results_list\n",
    "    plot_graphs_metrics(m, results_list, steps_in, steps_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['High_svi', 'Low_svi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_real, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup.plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = km.results(y_real, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

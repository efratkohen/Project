{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import clean_data_svi as cds\n",
    "import supervised as sup\n",
    "import pathlib\n",
    "import keras_model as km\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from datetime import timedelta, datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from keras import backend as K, Sequential, Input, Model\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, LSTM, Bidirectional, Conv1D, MaxPooling1D, MaxPooling2D, Flatten, \\\n",
    "    TimeDistributed, RepeatVector, Dropout, GRU, AveragePooling1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error, median_absolute_error, roc_curve, auc, f1_score, \\\n",
    "    precision_recall_curve, r2_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_for_max_f1(y_real, Yhat):\n",
    "    '''\n",
    "    Given inputs y_real and y_predict, the function returns\n",
    "    the threshold (rounded to the nearest hundredth) that\n",
    "    maximizes f1.\n",
    "    \n",
    "    Note: this func not necessarily optimized, could return to \n",
    "    doing this but not needed).\n",
    "    \n",
    "    Also note that we calculate f1 without using the results method\n",
    "    in keras_model. This is because we need to check beforehand that\n",
    "    computing f1 won't produce a NaN so we won't get an invalid value warning.\n",
    "    '''\n",
    "    \n",
    "    #error is occuring in km.results when computing f1, because TNR, NPV are 0, implying that there\n",
    "    #are no true negatives. While we added if statements to account for at least one predicted\n",
    "    #negative, this does not correlate to at least one true negative. Hence, instead of using keras.results\n",
    "    #we use that code by check that tn is not 0\n",
    "    f1_vals = []\n",
    "    for i in range(0, 100):\n",
    "        threshold = i/100\n",
    "        y_predict = np.where(Yhat > threshold, 1, 0).astype(int)\n",
    "\n",
    "        cm = confusion_matrix(y_real, y_predict)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_real, y_predict).ravel()\n",
    "        \n",
    "        if tn != 0:      \n",
    "            TNR = (tn) / (tn + fp)\n",
    "            NPV = (tn) / (tn + fn)\n",
    "            f1 = 2 * (TNR * NPV) / (TNR + NPV)\n",
    "        else:\n",
    "            f1 = -2   \n",
    "        f1_vals.append(f1)\n",
    "        \n",
    "    f1_vals = np.array(f1_vals)\n",
    "    f1_vals = np.nan_to_num(f1_vals, nan=-1)\n",
    "    return (np.argmax(f1_vals))/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_real, y_predict):\n",
    "    '''\n",
    "    Given y_real and y_predict, this method displays the results\n",
    "    (accuracy, recall, precision, f1) followed by the plot of the confusion matrix.\n",
    "    '''\n",
    "    print(km.results(y_real, y_predict), '\\n')\n",
    "    \n",
    "    classes = ['High_svi', 'Low_svi']\n",
    "    cm = confusion_matrix(y_real, y_predict)\n",
    "    sup.plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVI_list = []\n",
    "for i in range(4):\n",
    "    df = pd.read_csv(f\"clean_tables/svi_{i+1}.csv\", index_col=\"date\")\n",
    "    df = df.drop(columns=['Settling_velocity', 'SV_label', 'SVI_label'])\n",
    "    df.index = pd.to_datetime(df.index, dayfirst=True)\n",
    "    SVI_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.read_csv(\"clean_tables/temperatur.csv\", index_col=\"date\")\n",
    "temp_df.index = pd.to_datetime(temp_df.index, dayfirst=True)\n",
    "sludge_age_df = pd.read_csv(\"clean_tables/sludge_age_f_m.csv\", index_col=\"date\")\n",
    "sludge_age_df.index = pd.to_datetime(sludge_age_df.index, dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactor_list = []\n",
    "for i in range(4):\n",
    "    join = pd.concat([SVI_list[i], temp_df], axis=1)\n",
    "    if i <=1:\n",
    "        join = pd.concat([join, sludge_age_df.iloc[:, np.r_[0, 2]]], axis=1)\n",
    "    else:\n",
    "        join = pd.concat([join, sludge_age_df.iloc[:, np.r_[1, 3]]], axis=1)\n",
    "    join.columns = ['SVI', 'Temperature', 'F_M', 'Sludge Age']\n",
    "    reactor_list.append(join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVI</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>F_M</th>\n",
       "      <th>Sludge Age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>94.066570</td>\n",
       "      <td>22.030</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02</th>\n",
       "      <td>95.318860</td>\n",
       "      <td>21.985</td>\n",
       "      <td>0.22</td>\n",
       "      <td>3.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-03</th>\n",
       "      <td>82.826748</td>\n",
       "      <td>21.740</td>\n",
       "      <td>0.22</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>95.307918</td>\n",
       "      <td>21.815</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>93.930636</td>\n",
       "      <td>21.890</td>\n",
       "      <td>0.23</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-27</th>\n",
       "      <td>144.736842</td>\n",
       "      <td>22.540</td>\n",
       "      <td>0.23</td>\n",
       "      <td>3.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-28</th>\n",
       "      <td>130.890052</td>\n",
       "      <td>22.535</td>\n",
       "      <td>0.24</td>\n",
       "      <td>3.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-29</th>\n",
       "      <td>140.306122</td>\n",
       "      <td>22.660</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-30</th>\n",
       "      <td>131.250000</td>\n",
       "      <td>22.660</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>147.453083</td>\n",
       "      <td>22.735</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4018 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   SVI  Temperature   F_M  Sludge Age\n",
       "date                                                 \n",
       "2010-01-01   94.066570       22.030  0.22        2.92\n",
       "2010-01-02   95.318860       21.985  0.22        3.04\n",
       "2010-01-03   82.826748       21.740  0.22        3.00\n",
       "2010-01-04   95.307918       21.815  0.22        2.97\n",
       "2010-01-05   93.930636       21.890  0.23        2.94\n",
       "...                ...          ...   ...         ...\n",
       "2020-12-27  144.736842       22.540  0.23        3.41\n",
       "2020-12-28  130.890052       22.535  0.24        3.10\n",
       "2020-12-29  140.306122       22.660  0.25        3.15\n",
       "2020-12-30  131.250000       22.660  0.25        3.32\n",
       "2020-12-31  147.453083       22.735  0.25        3.32\n",
       "\n",
       "[4018 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reactor_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_list = []\n",
    "for i in range(4):\n",
    "    df = pd.read_csv(f\"clean_tables/micro_{i+1}.csv\", index_col=\"date\")\n",
    "    df.index = pd.to_datetime(df.index, dayfirst=True)\n",
    "    micro_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arcella</th>\n",
       "      <th>nude ameba</th>\n",
       "      <th>aspidisca</th>\n",
       "      <th>trachelopylum</th>\n",
       "      <th>lionutus</th>\n",
       "      <th>paramecium</th>\n",
       "      <th>carchecium</th>\n",
       "      <th>epistylis</th>\n",
       "      <th>opercularia</th>\n",
       "      <th>podophyra</th>\n",
       "      <th>...</th>\n",
       "      <th>Floc Strength</th>\n",
       "      <th>Indian Ink</th>\n",
       "      <th>Filament index</th>\n",
       "      <th>Floc_size_small</th>\n",
       "      <th>Floc_size_medium</th>\n",
       "      <th>Floc_size_large</th>\n",
       "      <th>Shape_close</th>\n",
       "      <th>Shape_open</th>\n",
       "      <th>Filaments_in_floc</th>\n",
       "      <th>Free_filaments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-02-18</th>\n",
       "      <td>40.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-02</th>\n",
       "      <td>27.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-08</th>\n",
       "      <td>27.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-18</th>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-08</th>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-23</th>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-21</th>\n",
       "      <td>7.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-28</th>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-11</th>\n",
       "      <td>23.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-25</th>\n",
       "      <td>12.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>362 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            arcella  nude ameba  aspidisca  trachelopylum  lionutus  \\\n",
       "date                                                                  \n",
       "2010-02-18     40.0         4.0        2.0            0.0       6.0   \n",
       "2010-03-02     27.0         5.0        3.0            1.0      16.0   \n",
       "2010-03-08     27.0         8.0       14.0            1.0       9.0   \n",
       "2010-03-18     11.0        12.0        2.0            0.0      16.0   \n",
       "2010-04-08     12.0         6.0       10.0            0.0      13.0   \n",
       "...             ...         ...        ...            ...       ...   \n",
       "2020-09-23      5.0        11.0        9.0            2.0       5.0   \n",
       "2020-10-21      7.0        57.0       55.0            0.0      12.0   \n",
       "2020-10-28     14.0        20.0        1.0            0.0      24.0   \n",
       "2020-11-11     23.0        86.0       17.0            1.0      29.0   \n",
       "2020-11-25     12.0        56.0       64.0            0.0      18.0   \n",
       "\n",
       "            paramecium  carchecium  epistylis  opercularia  podophyra  ...  \\\n",
       "date                                                                   ...   \n",
       "2010-02-18         0.0         1.0        4.0          4.0        0.0  ...   \n",
       "2010-03-02         0.0         0.0       13.0          4.0        0.0  ...   \n",
       "2010-03-08         1.0         0.0       11.0          9.0        0.0  ...   \n",
       "2010-03-18         0.0         0.0        7.0          0.0        0.0  ...   \n",
       "2010-04-08         1.0         0.0        1.0          1.0        0.0  ...   \n",
       "...                ...         ...        ...          ...        ...  ...   \n",
       "2020-09-23         0.0         0.0        6.0          0.0        3.0  ...   \n",
       "2020-10-21         0.0        14.0       26.0          0.0        0.0  ...   \n",
       "2020-10-28         0.0         0.0       35.0          2.0        0.0  ...   \n",
       "2020-11-11         0.0         0.0       18.0          0.0        0.0  ...   \n",
       "2020-11-25         0.0         0.0       41.0          4.0        2.0  ...   \n",
       "\n",
       "            Floc Strength  Indian Ink  Filament index  Floc_size_small  \\\n",
       "date                                                                     \n",
       "2010-02-18            NaN         NaN             3.0              0.0   \n",
       "2010-03-02            NaN         NaN             3.0              NaN   \n",
       "2010-03-08            NaN         NaN             3.0              NaN   \n",
       "2010-03-18            NaN         NaN             3.0              0.0   \n",
       "2010-04-08            NaN         NaN             3.0              0.0   \n",
       "...                   ...         ...             ...              ...   \n",
       "2020-09-23            3.0         1.0             2.0              0.0   \n",
       "2020-10-21            1.0         3.0             3.0              1.0   \n",
       "2020-10-28            2.0         3.0             2.5              1.0   \n",
       "2020-11-11            3.0         2.0             2.5              1.0   \n",
       "2020-11-25            1.0         2.0             2.5              1.0   \n",
       "\n",
       "            Floc_size_medium  Floc_size_large  Shape_close  Shape_open  \\\n",
       "date                                                                     \n",
       "2010-02-18               1.0              1.0          0.0         1.0   \n",
       "2010-03-02               NaN              NaN          0.0         1.0   \n",
       "2010-03-08               NaN              NaN          1.0         1.0   \n",
       "2010-03-18               1.0              1.0          0.0         1.0   \n",
       "2010-04-08               1.0              1.0          0.0         1.0   \n",
       "...                      ...              ...          ...         ...   \n",
       "2020-09-23               1.0              1.0          1.0         1.0   \n",
       "2020-10-21               1.0              1.0          0.0         1.0   \n",
       "2020-10-28               1.0              1.0          1.0         1.0   \n",
       "2020-11-11               1.0              1.0          1.0         1.0   \n",
       "2020-11-25               1.0              1.0          0.0         1.0   \n",
       "\n",
       "            Filaments_in_floc  Free_filaments  \n",
       "date                                           \n",
       "2010-02-18                1.0             1.0  \n",
       "2010-03-02                1.0             0.0  \n",
       "2010-03-08                1.0             1.0  \n",
       "2010-03-18                1.0             1.0  \n",
       "2010-04-08                1.0             1.0  \n",
       "...                       ...             ...  \n",
       "2020-09-23                1.0             1.0  \n",
       "2020-10-21                1.0             1.0  \n",
       "2020-10-28                1.0             1.0  \n",
       "2020-11-11                1.0             1.0  \n",
       "2020-11-25                1.0             1.0  \n",
       "\n",
       "[362 rows x 37 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_list = []\n",
    "for i in range(4):\n",
    "    join = pd.concat([reactor_list[i], micro_list[i]], axis=1)\n",
    "    join_list.append(join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVI</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>F_M</th>\n",
       "      <th>Sludge Age</th>\n",
       "      <th>arcella</th>\n",
       "      <th>nude ameba</th>\n",
       "      <th>aspidisca</th>\n",
       "      <th>trachelopylum</th>\n",
       "      <th>lionutus</th>\n",
       "      <th>paramecium</th>\n",
       "      <th>...</th>\n",
       "      <th>Floc Strength</th>\n",
       "      <th>Indian Ink</th>\n",
       "      <th>Filament index</th>\n",
       "      <th>Floc_size_small</th>\n",
       "      <th>Floc_size_medium</th>\n",
       "      <th>Floc_size_large</th>\n",
       "      <th>Shape_close</th>\n",
       "      <th>Shape_open</th>\n",
       "      <th>Filaments_in_floc</th>\n",
       "      <th>Free_filaments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>88.649852</td>\n",
       "      <td>22.030</td>\n",
       "      <td>0.23</td>\n",
       "      <td>3.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02</th>\n",
       "      <td>86.480363</td>\n",
       "      <td>21.985</td>\n",
       "      <td>0.18</td>\n",
       "      <td>3.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-03</th>\n",
       "      <td>96.370968</td>\n",
       "      <td>21.740</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>109.427609</td>\n",
       "      <td>21.815</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>100.929054</td>\n",
       "      <td>21.890</td>\n",
       "      <td>0.23</td>\n",
       "      <td>3.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-27</th>\n",
       "      <td>159.420290</td>\n",
       "      <td>22.540</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-28</th>\n",
       "      <td>147.887324</td>\n",
       "      <td>22.535</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-29</th>\n",
       "      <td>152.173913</td>\n",
       "      <td>22.660</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-30</th>\n",
       "      <td>148.725212</td>\n",
       "      <td>22.660</td>\n",
       "      <td>0.27</td>\n",
       "      <td>2.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>152.777778</td>\n",
       "      <td>22.735</td>\n",
       "      <td>0.27</td>\n",
       "      <td>2.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4018 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   SVI  Temperature   F_M  Sludge Age  arcella  nude ameba  \\\n",
       "date                                                                         \n",
       "2010-01-01   88.649852       22.030  0.23        3.44      NaN         NaN   \n",
       "2010-01-02   86.480363       21.985  0.18        3.78      NaN         NaN   \n",
       "2010-01-03   96.370968       21.740  0.21        3.82      NaN         NaN   \n",
       "2010-01-04  109.427609       21.815  0.21        3.40      NaN         NaN   \n",
       "2010-01-05  100.929054       21.890  0.23        3.70      NaN         NaN   \n",
       "...                ...          ...   ...         ...      ...         ...   \n",
       "2020-12-27  159.420290       22.540  0.25        2.75      NaN         NaN   \n",
       "2020-12-28  147.887324       22.535  0.26        2.91      NaN         NaN   \n",
       "2020-12-29  152.173913       22.660  0.26        2.82      NaN         NaN   \n",
       "2020-12-30  148.725212       22.660  0.27        2.91      NaN         NaN   \n",
       "2020-12-31  152.777778       22.735  0.27        2.91      NaN         NaN   \n",
       "\n",
       "            aspidisca  trachelopylum  lionutus  paramecium  ...  \\\n",
       "date                                                        ...   \n",
       "2010-01-01        NaN            NaN       NaN         NaN  ...   \n",
       "2010-01-02        NaN            NaN       NaN         NaN  ...   \n",
       "2010-01-03        NaN            NaN       NaN         NaN  ...   \n",
       "2010-01-04        NaN            NaN       NaN         NaN  ...   \n",
       "2010-01-05        NaN            NaN       NaN         NaN  ...   \n",
       "...               ...            ...       ...         ...  ...   \n",
       "2020-12-27        NaN            NaN       NaN         NaN  ...   \n",
       "2020-12-28        NaN            NaN       NaN         NaN  ...   \n",
       "2020-12-29        NaN            NaN       NaN         NaN  ...   \n",
       "2020-12-30        NaN            NaN       NaN         NaN  ...   \n",
       "2020-12-31        NaN            NaN       NaN         NaN  ...   \n",
       "\n",
       "            Floc Strength  Indian Ink  Filament index  Floc_size_small  \\\n",
       "date                                                                     \n",
       "2010-01-01            NaN         NaN             NaN              NaN   \n",
       "2010-01-02            NaN         NaN             NaN              NaN   \n",
       "2010-01-03            NaN         NaN             NaN              NaN   \n",
       "2010-01-04            NaN         NaN             NaN              NaN   \n",
       "2010-01-05            NaN         NaN             NaN              NaN   \n",
       "...                   ...         ...             ...              ...   \n",
       "2020-12-27            NaN         NaN             NaN              NaN   \n",
       "2020-12-28            NaN         NaN             NaN              NaN   \n",
       "2020-12-29            NaN         NaN             NaN              NaN   \n",
       "2020-12-30            NaN         NaN             NaN              NaN   \n",
       "2020-12-31            NaN         NaN             NaN              NaN   \n",
       "\n",
       "            Floc_size_medium  Floc_size_large  Shape_close  Shape_open  \\\n",
       "date                                                                     \n",
       "2010-01-01               NaN              NaN          NaN         NaN   \n",
       "2010-01-02               NaN              NaN          NaN         NaN   \n",
       "2010-01-03               NaN              NaN          NaN         NaN   \n",
       "2010-01-04               NaN              NaN          NaN         NaN   \n",
       "2010-01-05               NaN              NaN          NaN         NaN   \n",
       "...                      ...              ...          ...         ...   \n",
       "2020-12-27               NaN              NaN          NaN         NaN   \n",
       "2020-12-28               NaN              NaN          NaN         NaN   \n",
       "2020-12-29               NaN              NaN          NaN         NaN   \n",
       "2020-12-30               NaN              NaN          NaN         NaN   \n",
       "2020-12-31               NaN              NaN          NaN         NaN   \n",
       "\n",
       "            Filaments_in_floc  Free_filaments  \n",
       "date                                           \n",
       "2010-01-01                NaN             NaN  \n",
       "2010-01-02                NaN             NaN  \n",
       "2010-01-03                NaN             NaN  \n",
       "2010-01-04                NaN             NaN  \n",
       "2010-01-05                NaN             NaN  \n",
       "...                       ...             ...  \n",
       "2020-12-27                NaN             NaN  \n",
       "2020-12-28                NaN             NaN  \n",
       "2020-12-29                NaN             NaN  \n",
       "2020-12-30                NaN             NaN  \n",
       "2020-12-31                NaN             NaN  \n",
       "\n",
       "[4018 rows x 41 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = km.create_join_x_y_arr(join_list, n_steps_in=7, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 70.93it/s]\n"
     ]
    }
   ],
   "source": [
    "X_normalize, Y_normalize, scalers = km.normalize(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normalize = np.nan_to_num(X_normalize, nan=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "14439/14439 [==============================] - 15s 1ms/step - loss: 0.5811 - binary_accuracy: 0.6827\n",
      "Epoch 2/3\n",
      "14439/14439 [==============================] - 13s 918us/step - loss: 0.4502 - binary_accuracy: 0.7281\n",
      "Epoch 3/3\n",
      "14439/14439 [==============================] - 12s 831us/step - loss: 0.4287 - binary_accuracy: 0.7552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fc3ebd9b490>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X_normalize, Y_normalize, test_size=0.10, random_state=42)\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, activation='relu', name='first_lstm', recurrent_dropout=0.1, input_shape=(Xtrain.shape[1], Xtrain.shape[2])))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', \n",
    "              metrics=[keras.metrics.BinaryAccuracy(name='binary_accuracy', dtype=None, threshold=0.5)])\n",
    "model.fit(Xtrain, ytrain, epochs=3, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yhat, Ytest = km.evaluate(model, Xtest, ytest, scalers, binary=True)\n",
    "y_real = Ytest.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = threshold_for_max_f1(y_real, Yhat)\n",
    "y_predict = np.where(Yhat > threshold, 1, 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8043613707165109, 0.771484375, 0.6672297297297297, 0.7155797101449275) \n",
      "\n",
      "Confusion matrix, without normalization\n",
      "[[395 117]\n",
      " [197 896]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_real, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(Ytest, Yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 71.03it/s]\n"
     ]
    }
   ],
   "source": [
    "X_normalize, Y_normalize, scalers = km.normalize(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8794262494281794"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normalize = np.nan_to_num(X_normalize, nan=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'ROC curve')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = {1: 'Simple LSTM',\n",
    "               2: 'Stacked LSTM',\n",
    "               3: 'Bidirectional LSTM',\n",
    "               4: 'CNN',\n",
    "               5: 'CNN LSTM',\n",
    "               6: 'LSTM Autoencoder',\n",
    "               7: 'Deep CNN',\n",
    "               8: 'GRU',\n",
    "               9: 'GRU CNN'}\n",
    "\n",
    "def plot_graphs_metrics(model, results_list, steps_in, steps_out):\n",
    "    model_name = model_names[model]\n",
    "    \n",
    "    #this block of code is because some models (like 6) require steps_in start at 3 instead of 1\n",
    "    shift_vals = {1: 1,\n",
    "                  3: 1,\n",
    "                  6: 3,\n",
    "                  9: 2}\n",
    "    shift_val = shift_vals[model]\n",
    "    \n",
    "    #plot graph of a metric result for all n_step_in and n_step_out values\n",
    "    x=list(range(1, steps_out))\n",
    "    label = ['accuracy', 'TNR', 'NPV', 'f1']\n",
    "    for z in range(4):\n",
    "        for i in range(steps_in-shift_val):\n",
    "            y=[]\n",
    "            for j in range(steps_out-1):\n",
    "                y.append(results_list[i*(steps_out-1):i*(steps_out-1) + (steps_out-1)][j][z])\n",
    "            plt.plot(x, y, label=f'n_steps_in={i+shift_val}')\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        plt.xlabel(\"n_steps_out\")\n",
    "        plt.ylabel(label[z])\n",
    "        plt.title(model_name + \", 3 layers (50,25,1),\\n name='first_lstm', recurrent_dropout=0.1 \\n optimizer='adam', loss='binary_crossentropy' \")\n",
    "        plt.savefig(f\"figures/{model_name} {label[z]}.png\", bbox_inches=\"tight\")\n",
    "        plt.close()    \n",
    "    \n",
    "    #plot graph of all metric results for a n_step_in value\n",
    "    x=list(range(1, steps_out))\n",
    "    label = ['accuracy', 'TNR', 'NPV', 'f1']\n",
    "    for z in range(steps_in-shift_val):\n",
    "        for i in range(4):\n",
    "            y=[]\n",
    "            for j in range(steps_out-1):\n",
    "                y.append(results_list[z*(steps_out-1):z*(steps_out-1)+(steps_out-1)][j][i])\n",
    "            plt.plot(x, y, label=label[i])\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        plt.xlabel(\"n_steps_out\")\n",
    "        plt.ylabel('Metric value')\n",
    "        plt.title(f\"{model_name}, 3 layers (50,25,1),\\n name='first_lstm', recurrent_dropout=0.1 \\n optimizer='adam', loss='binary_crossentropy' \\n n_steps_in={z+shift_val} \")\n",
    "        plt.savefig(f\"figures/{model_name} n_steps_in={z+shift_val}.png\", bbox_inches=\"tight\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model type 1\n",
    "def train_SIMPLE_LSTM_model(epochs, steps_in, steps_out):\n",
    "    results_list = []\n",
    "    for i in range(1, steps_in):\n",
    "        for j in range(1, steps_out):\n",
    "            X, Y = km.create_join_x_y_arr(reactor_list, n_steps_in=i, n_steps_out = j, binary=True)\n",
    "            X_normalize, Y_normalize, scalers = km.normalize(X, Y)\n",
    "            X_normalize = np.nan_to_num(X_normalize, nan=-1)\n",
    "            Xtrain, Xtest, ytrain, ytest = train_test_split(X_normalize, Y_normalize, test_size=0.20, random_state=42)\n",
    "\n",
    "            model = Sequential()\n",
    "            model.add(LSTM(units=50, activation='relu', name='first_lstm', recurrent_dropout=0.1, input_shape=(Xtrain.shape[1], Xtrain.shape[2])))\n",
    "            model.add(Dense(25, activation='relu'))\n",
    "            model.add(Dense(1, activation=\"sigmoid\"))\n",
    "            \n",
    "            model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy')\n",
    "            model.fit(Xtrain, ytrain, epochs=epochs, batch_size=10, shuffle=True)\n",
    "            \n",
    "            Yhat, Ytest = km.evaluate(model, Xtest, ytest, scalers, binary=True)\n",
    "            y_real = Ytest.astype(int)\n",
    "            threshold = threshold_for_max_f1(y_real, Yhat)\n",
    "            y_predict = np.where(Yhat > threshold, 1, 0).astype(int)\n",
    "            results_list.append(km.results(y_real, y_predict))\n",
    "    return results_list\n",
    "\n",
    "###Just need to fill out the three functions for below. All other infrastructure is handled.###\n",
    "\n",
    "#Model type 3\n",
    "def train_BIDIRECTIONAL_LSTM_model(epochs, steps_in, steps_out):\n",
    "    results_list = []\n",
    "    for i in range(1, steps_in):\n",
    "        for j in range(1, steps_out):\n",
    "            X, Y = km.create_join_x_y_arr(reactor_list, n_steps_in=i, n_steps_out = j, binary=True)\n",
    "            X_normalize, Y_normalize, scalers = km.normalize(X, Y)\n",
    "            X_normalize = np.nan_to_num(X_normalize, nan=-1)\n",
    "            Xtrain, Xtest, ytrain, ytest = train_test_split(X_normalize, Y_normalize, test_size=0.20, random_state=42)\n",
    "            \n",
    "            model = Sequential()\n",
    "            model.add(Bidirectional(LSTM(100, return_sequences=True, activation='relu')))\n",
    "            model.add(Bidirectional(LSTM(50, return_sequences=True, activation='relu')))\n",
    "            model.add(Bidirectional(LSTM(20, activation='relu')))\n",
    "            model.add(Dense(1, activation=\"sigmoid\"))\n",
    "            \n",
    "            model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy')\n",
    "            model.fit(Xtrain, ytrain, epochs=epochs, batch_size=10, shuffle=True)\n",
    "            \n",
    "            Yhat, Ytest = km.evaluate(model, Xtest, ytest, scalers, binary=True)\n",
    "            y_real = Ytest.astype(int)\n",
    "            threshold = threshold_for_max_f1(y_real, Yhat)\n",
    "            y_predict = np.where(Yhat > threshold, 1, 0).astype(int)\n",
    "            results_list.append(km.results(y_real, y_predict))\n",
    "    return results_list\n",
    "\n",
    "#Model type 6 - having lots of trouble with this one\n",
    "#For some reason we need steps_in to be at least 3 for this one\n",
    "#This probably has to do with the pooling, Convolution, or Dropout layers\n",
    "def train_LSTM_AUTOENCODER_model(epochs, steps_in, steps_out):\n",
    "    results_list = []\n",
    "    for i in range(3, steps_in):\n",
    "        for j in range(1, steps_out):\n",
    "            X, Y = km.create_join_x_y_arr(reactor_list, n_steps_in=i, n_steps_out = j, binary=True)\n",
    "            X_normalize, Y_normalize, scalers = km.normalize(X, Y)\n",
    "            X_normalize = np.nan_to_num(X_normalize, nan=-1)\n",
    "            Xtrain, Xtest, ytrain, ytest = train_test_split(X_normalize, Y_normalize, test_size=0.20, random_state=42)\n",
    "\n",
    "            model = Sequential()\n",
    "            model.add(Conv1D(filters=128, \n",
    "                             kernel_size=2, \n",
    "                             activation='relu', \n",
    "                             name='extractor', \n",
    "                             input_shape=(Xtrain.shape[1], Xtrain.shape[2])))\n",
    "            model.add(Dropout(0.3))\n",
    "            model.add(MaxPooling1D(pool_size=2))\n",
    "            model.add(Bidirectional(LSTM(50, activation='relu', input_shape=(Xtrain.shape[1], Xtrain.shape[2]))))\n",
    "            model.add(RepeatVector(10))\n",
    "            model.add(Bidirectional(LSTM(50, activation='relu')))\n",
    "            model.add(Dense(1))\n",
    "\n",
    "            model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy')\n",
    "            model.fit(Xtrain, ytrain, epochs=epochs, batch_size=10, shuffle=True)\n",
    "            \n",
    "            Yhat, Ytest = km.evaluate(model, Xtest, ytest, scalers, binary=True)\n",
    "            y_real = Ytest.astype(int)\n",
    "            threshold = threshold_for_max_f1(y_real, Yhat)\n",
    "            y_predict = np.where(Yhat > threshold, 1, 0).astype(int)\n",
    "            results_list.append(km.results(y_real, y_predict))\n",
    "    return results_list\n",
    "\n",
    "def train_GRU_CNN_model(epochs, steps_in, steps_out):\n",
    "    results_list = []\n",
    "    for i in range(2, steps_in):\n",
    "        for j in range(1, steps_out):\n",
    "            X, Y = km.create_join_x_y_arr(reactor_list, n_steps_in=i, n_steps_out = j, binary=True)\n",
    "            X_normalize, Y_normalize, scalers = km.normalize(X, Y)\n",
    "            X_normalize = np.nan_to_num(X_normalize, nan=-1)\n",
    "            Xtrain, Xtest, ytrain, ytest = train_test_split(X_normalize, Y_normalize, test_size=0.20, random_state=42)            \n",
    "            \n",
    "            inp_seq = Input(shape=(Xtrain.shape[1], Xtrain.shape[2]))\n",
    "            x = Bidirectional(GRU(100, return_sequences=True))(inp_seq)\n",
    "            x = AveragePooling1D(2)(x)\n",
    "            x = Conv1D(100, 3, activation='relu', padding='same',\n",
    "                       name='extractor')(x)\n",
    "            x = Flatten()(x)\n",
    "            x = Dense(16, activation='relu')(x)\n",
    "            x = Dropout(0.5)(x)\n",
    "\n",
    "            out = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "            model = Model(inp_seq, out)\n",
    "\n",
    "            \n",
    "            model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy')\n",
    "            model.fit(Xtrain, ytrain, epochs=epochs, batch_size=10, shuffle=True)\n",
    "            \n",
    "            Yhat, Ytest = km.evaluate(model, Xtest, ytest, scalers, binary=True)\n",
    "            y_real = Ytest.astype(int)\n",
    "            threshold = threshold_for_max_f1(y_real, Yhat)\n",
    "            y_predict = np.where(Yhat > threshold, 1, 0).astype(int)\n",
    "            results_list.append(km.results(y_real, y_predict))\n",
    "    return results_list\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 668.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12854/12854 [==============================] - 6s 465us/step - loss: 0.6476\n",
      "Epoch 2/10\n",
      "12854/12854 [==============================] - 5s 390us/step - loss: 0.6140\n",
      "Epoch 3/10\n",
      "12854/12854 [==============================] - 5s 419us/step - loss: 0.5936\n",
      "Epoch 4/10\n",
      "12854/12854 [==============================] - 5s 399us/step - loss: 0.5619\n",
      "Epoch 5/10\n",
      "12854/12854 [==============================] - 4s 296us/step - loss: 0.5270\n",
      "Epoch 6/10\n",
      "12854/12854 [==============================] - 4s 292us/step - loss: 0.4961\n",
      "Epoch 7/10\n",
      "12854/12854 [==============================] - 4s 287us/step - loss: 0.4716\n",
      "Epoch 8/10\n",
      "12854/12854 [==============================] - 4s 287us/step - loss: 0.4535\n",
      "Epoch 9/10\n",
      "12854/12854 [==============================] - 4s 282us/step - loss: 0.4406\n",
      "Epoch 10/10\n",
      "12854/12854 [==============================] - 4s 283us/step - loss: 0.4319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 690.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12851/12851 [==============================] - 5s 406us/step - loss: 0.6455\n",
      "Epoch 2/10\n",
      "12851/12851 [==============================] - 4s 286us/step - loss: 0.5997\n",
      "Epoch 3/10\n",
      "12851/12851 [==============================] - 4s 285us/step - loss: 0.5590\n",
      "Epoch 4/10\n",
      "12851/12851 [==============================] - 4s 317us/step - loss: 0.5209\n",
      "Epoch 5/10\n",
      "12851/12851 [==============================] - 4s 299us/step - loss: 0.4932\n",
      "Epoch 6/10\n",
      "12851/12851 [==============================] - 4s 285us/step - loss: 0.4745\n",
      "Epoch 7/10\n",
      "12851/12851 [==============================] - 4s 319us/step - loss: 0.4629\n",
      "Epoch 8/10\n",
      "12851/12851 [==============================] - 4s 301us/step - loss: 0.4556\n",
      "Epoch 9/10\n",
      "12851/12851 [==============================] - 4s 288us/step - loss: 0.4512\n",
      "Epoch 10/10\n",
      "12851/12851 [==============================] - 4s 287us/step - loss: 0.4479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 688.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12848/12848 [==============================] - 5s 401us/step - loss: 0.6501\n",
      "Epoch 2/10\n",
      "12848/12848 [==============================] - 4s 285us/step - loss: 0.6189\n",
      "Epoch 3/10\n",
      "12848/12848 [==============================] - 4s 280us/step - loss: 0.6038\n",
      "Epoch 4/10\n",
      "12848/12848 [==============================] - 4s 281us/step - loss: 0.5823\n",
      "Epoch 5/10\n",
      "12848/12848 [==============================] - 4s 279us/step - loss: 0.5574\n",
      "Epoch 6/10\n",
      "12848/12848 [==============================] - 4s 279us/step - loss: 0.5342\n",
      "Epoch 7/10\n",
      "12848/12848 [==============================] - 4s 279us/step - loss: 0.5146\n",
      "Epoch 8/10\n",
      "12848/12848 [==============================] - 4s 280us/step - loss: 0.4990\n",
      "Epoch 9/10\n",
      "12848/12848 [==============================] - 4s 279us/step - loss: 0.4880\n",
      "Epoch 10/10\n",
      "12848/12848 [==============================] - 4s 280us/step - loss: 0.4797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 805.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12844/12844 [==============================] - 5s 403us/step - loss: 0.6546\n",
      "Epoch 2/10\n",
      "12844/12844 [==============================] - 4s 315us/step - loss: 0.6118\n",
      "Epoch 3/10\n",
      "12844/12844 [==============================] - 4s 300us/step - loss: 0.5905\n",
      "Epoch 4/10\n",
      "12844/12844 [==============================] - 4s 283us/step - loss: 0.5659\n",
      "Epoch 5/10\n",
      "12844/12844 [==============================] - 4s 283us/step - loss: 0.5428\n",
      "Epoch 6/10\n",
      "12844/12844 [==============================] - 4s 284us/step - loss: 0.5244\n",
      "Epoch 7/10\n",
      "12844/12844 [==============================] - 4s 282us/step - loss: 0.5100\n",
      "Epoch 8/10\n",
      "12844/12844 [==============================] - 4s 287us/step - loss: 0.4987\n",
      "Epoch 9/10\n",
      "12844/12844 [==============================] - 4s 283us/step - loss: 0.4905\n",
      "Epoch 10/10\n",
      "12844/12844 [==============================] - 4s 282us/step - loss: 0.4844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 727.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12841/12841 [==============================] - 5s 403us/step - loss: 0.6629\n",
      "Epoch 2/10\n",
      "12841/12841 [==============================] - 4s 339us/step - loss: 0.6127\n",
      "Epoch 3/10\n",
      "12841/12841 [==============================] - 5s 360us/step - loss: 0.5786\n",
      "Epoch 4/10\n",
      "12841/12841 [==============================] - 4s 283us/step - loss: 0.5467\n",
      "Epoch 5/10\n",
      "12841/12841 [==============================] - 4s 283us/step - loss: 0.5236\n",
      "Epoch 6/10\n",
      "12841/12841 [==============================] - 4s 278us/step - loss: 0.5080\n",
      "Epoch 7/10\n",
      "12841/12841 [==============================] - 4s 281us/step - loss: 0.4983\n",
      "Epoch 8/10\n",
      "12841/12841 [==============================] - 4s 279us/step - loss: 0.4915\n",
      "Epoch 9/10\n",
      "12841/12841 [==============================] - 4s 285us/step - loss: 0.4872\n",
      "Epoch 10/10\n",
      "12841/12841 [==============================] - 4s 279us/step - loss: 0.4847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 546.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12838/12838 [==============================] - 5s 391us/step - loss: 0.6466\n",
      "Epoch 2/10\n",
      "12838/12838 [==============================] - 4s 279us/step - loss: 0.6156\n",
      "Epoch 3/10\n",
      "12838/12838 [==============================] - 4s 275us/step - loss: 0.5969\n",
      "Epoch 4/10\n",
      "12838/12838 [==============================] - 4s 288us/step - loss: 0.5735\n",
      "Epoch 5/10\n",
      "12838/12838 [==============================] - 4s 287us/step - loss: 0.5513\n",
      "Epoch 6/10\n",
      "12838/12838 [==============================] - 4s 277us/step - loss: 0.5332\n",
      "Epoch 7/10\n",
      "12838/12838 [==============================] - 4s 275us/step - loss: 0.5200\n",
      "Epoch 8/10\n",
      "12838/12838 [==============================] - 4s 279us/step - loss: 0.5101\n",
      "Epoch 9/10\n",
      "12838/12838 [==============================] - 4s 276us/step - loss: 0.5030\n",
      "Epoch 10/10\n",
      "12838/12838 [==============================] - 4s 304us/step - loss: 0.4984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 825.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12835/12835 [==============================] - 5s 408us/step - loss: 0.6499\n",
      "Epoch 2/10\n",
      "12835/12835 [==============================] - 5s 418us/step - loss: 0.6210\n",
      "Epoch 3/10\n",
      "12835/12835 [==============================] - 4s 294us/step - loss: 0.6099\n",
      "Epoch 4/10\n",
      "12835/12835 [==============================] - 4s 339us/step - loss: 0.5936\n",
      "Epoch 5/10\n",
      "12835/12835 [==============================] - 5s 398us/step - loss: 0.5761\n",
      "Epoch 6/10\n",
      "12835/12835 [==============================] - 5s 367us/step - loss: 0.5582\n",
      "Epoch 7/10\n",
      "12835/12835 [==============================] - 4s 293us/step - loss: 0.5436\n",
      "Epoch 8/10\n",
      "12835/12835 [==============================] - 4s 290us/step - loss: 0.5321\n",
      "Epoch 9/10\n",
      "12835/12835 [==============================] - 4s 310us/step - loss: 0.5229\n",
      "Epoch 10/10\n",
      "12835/12835 [==============================] - 4s 291us/step - loss: 0.5150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 758.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12832/12832 [==============================] - 5s 425us/step - loss: 0.6472\n",
      "Epoch 2/10\n",
      "12832/12832 [==============================] - 4s 278us/step - loss: 0.6146\n",
      "Epoch 3/10\n",
      "12832/12832 [==============================] - 4s 279us/step - loss: 0.5960\n",
      "Epoch 4/10\n",
      "12832/12832 [==============================] - 4s 277us/step - loss: 0.5766\n",
      "Epoch 5/10\n",
      "12832/12832 [==============================] - 4s 278us/step - loss: 0.5597\n",
      "Epoch 6/10\n",
      "12832/12832 [==============================] - 4s 299us/step - loss: 0.5461\n",
      "Epoch 7/10\n",
      "12832/12832 [==============================] - 4s 347us/step - loss: 0.5353\n",
      "Epoch 8/10\n",
      "12832/12832 [==============================] - 4s 339us/step - loss: 0.5271\n",
      "Epoch 9/10\n",
      "12832/12832 [==============================] - 4s 327us/step - loss: 0.5205\n",
      "Epoch 10/10\n",
      "12832/12832 [==============================] - 5s 352us/step - loss: 0.5156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 482.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12828/12828 [==============================] - 6s 442us/step - loss: 0.6402\n",
      "Epoch 2/10\n",
      "12828/12828 [==============================] - 4s 293us/step - loss: 0.6100\n",
      "Epoch 3/10\n",
      "12828/12828 [==============================] - 4s 327us/step - loss: 0.5891\n",
      "Epoch 4/10\n",
      "12828/12828 [==============================] - 4s 339us/step - loss: 0.5691\n",
      "Epoch 5/10\n",
      "12828/12828 [==============================] - 5s 363us/step - loss: 0.5529\n",
      "Epoch 6/10\n",
      "12828/12828 [==============================] - 4s 318us/step - loss: 0.5410\n",
      "Epoch 7/10\n",
      "12828/12828 [==============================] - 4s 326us/step - loss: 0.5321\n",
      "Epoch 8/10\n",
      "12828/12828 [==============================] - 4s 343us/step - loss: 0.5259\n",
      "Epoch 9/10\n",
      "12828/12828 [==============================] - 6s 483us/step - loss: 0.5213\n",
      "Epoch 10/10\n",
      "12828/12828 [==============================] - 4s 297us/step - loss: 0.5181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 724.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12851/12851 [==============================] - 6s 480us/step - loss: 0.6345\n",
      "Epoch 2/10\n",
      "12851/12851 [==============================] - 5s 371us/step - loss: 0.5727\n",
      "Epoch 3/10\n",
      "12851/12851 [==============================] - 5s 374us/step - loss: 0.5035\n",
      "Epoch 4/10\n",
      "12851/12851 [==============================] - 7s 524us/step - loss: 0.4555\n",
      "Epoch 5/10\n",
      "12851/12851 [==============================] - 5s 408us/step - loss: 0.4333\n",
      "Epoch 6/10\n",
      "12851/12851 [==============================] - 5s 399us/step - loss: 0.4261\n",
      "Epoch 7/10\n",
      "12851/12851 [==============================] - 5s 392us/step - loss: 0.4193\n",
      "Epoch 8/10\n",
      "12851/12851 [==============================] - 5s 404us/step - loss: 0.4151\n",
      "Epoch 9/10\n",
      "12851/12851 [==============================] - 5s 399us/step - loss: 0.4138\n",
      "Epoch 10/10\n",
      "12851/12851 [==============================] - 5s 400us/step - loss: 0.4137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 592.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12848/12848 [==============================] - 6s 496us/step - loss: 0.6407\n",
      "Epoch 2/10\n",
      "12848/12848 [==============================] - 5s 412us/step - loss: 0.5930\n",
      "Epoch 3/10\n",
      "12848/12848 [==============================] - 5s 425us/step - loss: 0.5331\n",
      "Epoch 4/10\n",
      "12848/12848 [==============================] - 5s 396us/step - loss: 0.4830\n",
      "Epoch 5/10\n",
      "12848/12848 [==============================] - 6s 438us/step - loss: 0.4619\n",
      "Epoch 6/10\n",
      "12848/12848 [==============================] - 5s 386us/step - loss: 0.4510\n",
      "Epoch 7/10\n",
      "12848/12848 [==============================] - 6s 440us/step - loss: 0.4454\n",
      "Epoch 8/10\n",
      "12848/12848 [==============================] - 5s 396us/step - loss: 0.4420\n",
      "Epoch 9/10\n",
      "12848/12848 [==============================] - 5s 374us/step - loss: 0.4414\n",
      "Epoch 10/10\n",
      "12848/12848 [==============================] - 6s 452us/step - loss: 0.4379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 450.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12844/12844 [==============================] - 9s 664us/step - loss: 0.6465\n",
      "Epoch 2/10\n",
      "12844/12844 [==============================] - 5s 400us/step - loss: 0.5981\n",
      "Epoch 3/10\n",
      "12844/12844 [==============================] - 5s 394us/step - loss: 0.5449\n",
      "Epoch 4/10\n",
      "12844/12844 [==============================] - 5s 425us/step - loss: 0.5029\n",
      "Epoch 5/10\n",
      "12844/12844 [==============================] - 5s 421us/step - loss: 0.4782\n",
      "Epoch 6/10\n",
      "12844/12844 [==============================] - 6s 436us/step - loss: 0.4673\n",
      "Epoch 7/10\n",
      "12844/12844 [==============================] - 6s 440us/step - loss: 0.4602\n",
      "Epoch 8/10\n",
      "12844/12844 [==============================] - 6s 467us/step - loss: 0.4557\n",
      "Epoch 9/10\n",
      "12844/12844 [==============================] - 7s 507us/step - loss: 0.4558\n",
      "Epoch 10/10\n",
      "12844/12844 [==============================] - 5s 428us/step - loss: 0.4519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 586.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12841/12841 [==============================] - 6s 497us/step - loss: 0.6389\n",
      "Epoch 2/10\n",
      "12841/12841 [==============================] - 5s 422us/step - loss: 0.5893\n",
      "Epoch 3/10\n",
      "12841/12841 [==============================] - 5s 424us/step - loss: 0.5390\n",
      "Epoch 4/10\n",
      "12841/12841 [==============================] - 7s 563us/step - loss: 0.5044\n",
      "Epoch 5/10\n",
      "12841/12841 [==============================] - 7s 571us/step - loss: 0.4836\n",
      "Epoch 6/10\n",
      "12841/12841 [==============================] - 5s 418us/step - loss: 0.4733\n",
      "Epoch 7/10\n",
      "12841/12841 [==============================] - 5s 365us/step - loss: 0.4678\n",
      "Epoch 8/10\n",
      "12841/12841 [==============================] - 5s 369us/step - loss: 0.4634\n",
      "Epoch 9/10\n",
      "12841/12841 [==============================] - 5s 368us/step - loss: 0.4615\n",
      "Epoch 10/10\n",
      "12841/12841 [==============================] - 6s 450us/step - loss: 0.4608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 674.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12838/12838 [==============================] - 7s 511us/step - loss: 0.6399\n",
      "Epoch 2/10\n",
      "12838/12838 [==============================] - 6s 466us/step - loss: 0.5909\n",
      "Epoch 3/10\n",
      "12838/12838 [==============================] - 5s 405us/step - loss: 0.5451\n",
      "Epoch 4/10\n",
      "12838/12838 [==============================] - 5s 383us/step - loss: 0.5101\n",
      "Epoch 5/10\n",
      "12838/12838 [==============================] - 5s 417us/step - loss: 0.4912\n",
      "Epoch 6/10\n",
      "12838/12838 [==============================] - 5s 362us/step - loss: 0.4811\n",
      "Epoch 7/10\n",
      "12838/12838 [==============================] - 5s 362us/step - loss: 0.4761\n",
      "Epoch 8/10\n",
      "12838/12838 [==============================] - 5s 360us/step - loss: 0.4734\n",
      "Epoch 9/10\n",
      "12838/12838 [==============================] - 5s 373us/step - loss: 0.4727\n",
      "Epoch 10/10\n",
      "12838/12838 [==============================] - 5s 414us/step - loss: 0.4709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 706.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12835/12835 [==============================] - 6s 505us/step - loss: 0.6318\n",
      "Epoch 2/10\n",
      "12835/12835 [==============================] - 5s 369us/step - loss: 0.5904\n",
      "Epoch 3/10\n",
      "12835/12835 [==============================] - 5s 370us/step - loss: 0.5530\n",
      "Epoch 4/10\n",
      "12835/12835 [==============================] - 5s 376us/step - loss: 0.5204\n",
      "Epoch 5/10\n",
      "12835/12835 [==============================] - 5s 395us/step - loss: 0.4996\n",
      "Epoch 6/10\n",
      "12835/12835 [==============================] - 5s 381us/step - loss: 0.4890\n",
      "Epoch 7/10\n",
      "12835/12835 [==============================] - 5s 384us/step - loss: 0.4833\n",
      "Epoch 8/10\n",
      "12835/12835 [==============================] - 5s 411us/step - loss: 0.4805\n",
      "Epoch 9/10\n",
      "12835/12835 [==============================] - 5s 408us/step - loss: 0.4774\n",
      "Epoch 10/10\n",
      "12835/12835 [==============================] - 5s 414us/step - loss: 0.4765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 636.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12832/12832 [==============================] - 7s 541us/step - loss: 0.6357\n",
      "Epoch 2/10\n",
      "12832/12832 [==============================] - 6s 477us/step - loss: 0.5936\n",
      "Epoch 3/10\n",
      "12832/12832 [==============================] - 6s 448us/step - loss: 0.5583\n",
      "Epoch 4/10\n",
      "12832/12832 [==============================] - 5s 388us/step - loss: 0.5283\n",
      "Epoch 5/10\n",
      "12832/12832 [==============================] - 5s 413us/step - loss: 0.5104\n",
      "Epoch 6/10\n",
      "12832/12832 [==============================] - 5s 376us/step - loss: 0.4998\n",
      "Epoch 7/10\n",
      "12832/12832 [==============================] - 6s 433us/step - loss: 0.4938\n",
      "Epoch 8/10\n",
      "12832/12832 [==============================] - 5s 390us/step - loss: 0.4920\n",
      "Epoch 9/10\n",
      "12832/12832 [==============================] - 5s 404us/step - loss: 0.4904\n",
      "Epoch 10/10\n",
      "12832/12832 [==============================] - 6s 439us/step - loss: 0.4879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 616.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12828/12828 [==============================] - 8s 585us/step - loss: 0.6396\n",
      "Epoch 2/10\n",
      "12828/12828 [==============================] - 5s 382us/step - loss: 0.6052\n",
      "Epoch 3/10\n",
      "12828/12828 [==============================] - 5s 371us/step - loss: 0.5766\n",
      "Epoch 4/10\n",
      "12828/12828 [==============================] - 5s 384us/step - loss: 0.5502\n",
      "Epoch 5/10\n",
      "12828/12828 [==============================] - 6s 435us/step - loss: 0.5284\n",
      "Epoch 6/10\n",
      "12828/12828 [==============================] - 5s 385us/step - loss: 0.5129\n",
      "Epoch 7/10\n",
      "12828/12828 [==============================] - 5s 406us/step - loss: 0.5057\n",
      "Epoch 8/10\n",
      "12828/12828 [==============================] - 5s 411us/step - loss: 0.5016\n",
      "Epoch 9/10\n",
      "12828/12828 [==============================] - 5s 402us/step - loss: 0.4985\n",
      "Epoch 10/10\n",
      "12828/12828 [==============================] - 5s 388us/step - loss: 0.4968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 809.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12825/12825 [==============================] - 6s 500us/step - loss: 0.6383\n",
      "Epoch 2/10\n",
      "11770/12825 [==========================>...] - ETA: 0s - loss: 0.6024"
     ]
    }
   ],
   "source": [
    "#Code to run models\n",
    "list_of_result_lists = {}\n",
    "models_list = [1]\n",
    "\n",
    "epochs = 10\n",
    "steps_in = 10\n",
    "steps_out = 10\n",
    "\n",
    "\n",
    "steps_in += 1\n",
    "steps_out += 1\n",
    "\n",
    "for m in models_list:\n",
    "    if m == 1:\n",
    "        results_list = train_SIMPLE_LSTM_model(epochs, steps_in, steps_out)\n",
    "    elif m == 3:\n",
    "        results_list = train_BIDIRECTIONAL_LSTM_model(epochs, steps_in, steps_out)\n",
    "    elif m == 6:\n",
    "        results_list = train_LSTM_AUTOENCODER_model(epochs, steps_in, steps_out)\n",
    "    elif m == 9:\n",
    "        results_list = train_GRU_CNN_model(epochs, steps_in, steps_out)\n",
    "    \n",
    "    list_of_result_lists[m] = results_list\n",
    "    plot_graphs_metrics(m, results_list, steps_in, steps_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_result_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_of_result_lists[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

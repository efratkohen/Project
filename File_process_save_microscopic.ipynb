{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Union\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_file(data_fname: Union[pathlib.Path, str]):\n",
    "    \"\"\"\n",
    "    Check for valid file name\n",
    "    accept strings and pathlib.Path objects\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_fname: pathlib.Path or str\n",
    "\n",
    "    return\n",
    "    ----------\n",
    "    fname: pathlib.Path\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        fname = pathlib.Path(data_fname)\n",
    "    except TypeError:\n",
    "        print(\"ERROR: Please supply a string or a pathlib.Path instance.\")\n",
    "        raise\n",
    "    if not fname.exists():\n",
    "        raise ValueError(f\"File {str(fname)} doesn't exist.\")\n",
    "    return fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dates_to_datetime_objects(micro_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Change 'date' column from string to datetime objects and normalize the time\n",
    "    Set the time to be the index of the df\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_list: list of df with column 'date'\n",
    "\n",
    "    Return\n",
    "    ----------\n",
    "    df_list: list of df\n",
    "    \"\"\"\n",
    "    \n",
    "    micro_df['date'] = pd.to_datetime(micro_df['date'], dayfirst=True).dt.normalize()\n",
    "    micro_df = micro_df.set_index('date')\n",
    "    micro_df = micro_df[~micro_df.index.duplicated(keep='first')]\n",
    "    micro_df = micro_df.reset_index()\n",
    "    return micro_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_microscopic_to_reactor(micro_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Splits the microscopic data to 4 reactors dfs and saves it in df list\n",
    "    Changes the columns names to be identical in the microscopic data frame of each reactor.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_micro: pd.DataFrame\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    micro_df_list: List of 4 dfs, each representing a bio_reactor\n",
    "    \"\"\"\n",
    "    micro_df_list = []\n",
    "    for i in range(0, 4):\n",
    "        lcol = (len(micro_df.columns.to_list())-1)/4\n",
    "        first_col = 1 + lcol * i\n",
    "        last_col = 1 + lcol * (i + 1)\n",
    "        micro_reactor_df = micro_df.iloc[:, np.r_[0, first_col:last_col]]\n",
    "        micro_reactor_df = micro_reactor_df.set_index('date')\n",
    "        if i > 0:\n",
    "            micro_reactor_df = micro_reactor_df.rename(columns = lambda x : str(x)[:-2])\n",
    "        micro_df_list.append(micro_reactor_df)\n",
    "\n",
    "    return micro_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nan_rows(micro_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Remove rows that contain only nan values (except date column).\n",
    "    Change df inplace.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    micro_df: pd.DataFrame\n",
    "   \n",
    "    \"\"\"\n",
    "    micro_df.dropna(how = 'all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_col_to_float(micro_df: pd.DataFrame, col_i: int):\n",
    "    \"\"\" \n",
    "    Fix string values with commas to float values, in column number 'col_i'.\n",
    "    Change df inplace.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    micro_df: pd.DataFrame\n",
    "    col_i: int\n",
    "        column index\n",
    "\n",
    "    \"\"\"\n",
    "    for row_i in range(micro_df.shape[0]):\n",
    "        datum = micro_df.iloc[row_i, col_i]\n",
    "        if type(datum) is str and ',' in datum:\n",
    "            num = datum.split(',')\n",
    "            micro_df.iloc[row_i, col_i] = num[0]+num[1]\n",
    "\n",
    "    col_name = micro_df.columns[col_i]\n",
    "    micro_df.loc[:, col_name] = pd.to_numeric(micro_df[col_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_object_cols_to_float(micro_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Convert 'object' columns with string numbers to dtype float\n",
    "    Change df inplace.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    micro_df: pd.DataFrame\n",
    "    \"\"\"\n",
    "    obj_cols_is = [] \n",
    "    for col_i in range(0, len(micro_df.dtypes)):\n",
    "        if micro_df.dtypes[col_i]==object:\n",
    "            obj_cols_is.append(col_i)\n",
    "    \n",
    "    for col_i in obj_cols_is:\n",
    "        fix_col_to_float(micro_df, col_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_negatives(micro_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Replaces negative values with NaN.\n",
    "    Change df inplace.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    micro_df: pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    numeric = micro_df._get_numeric_data()\n",
    "    numeric.where(numeric>=0, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filaments_zero_to_nan(micro_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    If a row has all its \"filament\" columns 0 or NaN,\n",
    "    turns all the \"filament\" values, including the \"Total count- Filaments\" to NaN.\n",
    "    Change df inplace.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    micro_df: pd.DataFrame\n",
    "    \"\"\"\n",
    "    ## find col index of first filament:\n",
    "    for i in range(len(micro_df.columns)):\n",
    "        if '0041_0675' in micro_df.columns[i]:\n",
    "            first_filament = i-1\n",
    "            break\n",
    "\n",
    "    for i in range(micro_df.shape[0]):\n",
    "        # if all fillaments are NaN or Zero, turn them all to NaN\n",
    "        if (micro_df.iloc[i, first_filament:first_filament+9].isin([0, np.nan])).all():\n",
    "            micro_df.iloc[i, first_filament:] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_zero_to_nan(micro_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    If a row has all its columns 0 or NaN,\n",
    "    turns all the values to NaN.\n",
    "    Change df inplace.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    micro_df: pd.DataFrame\n",
    "    \"\"\"\n",
    "    for i in range(micro_df.shape[0]):\n",
    "        # if all row's values are NaN or Zero, turn them all to NaN\n",
    "        if micro_df.iloc[i,:].isin([0, np.nan]).all():\n",
    "            micro_df.iloc[i, :] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def floc_size(micro_df: pd.DataFrame):\n",
    "    micro_df[\"Floc_size_small\"] = np.where(micro_df[\"Floc size\"].isin([1, 4, 6, 7, 12, 13, 123]), 1,\n",
    "                                          np.where(micro_df[\"Floc size\"].isin([2, 3, 5, 23, 2.5]), 0, np.nan))\n",
    "    micro_df[\"Floc_size_medium\"] = np.where(micro_df[\"Floc size\"].isin([2, 5, 6, 7, 12, 23, 2.5, 123]), 1,\n",
    "                                          np.where(micro_df[\"Floc size\"].isin([1, 3, 4, 13]), 0, np.nan))\n",
    "    micro_df[\"Floc_size_large\"] = np.where(micro_df[\"Floc size\"].isin([3, 4, 5, 7, 13, 23, 2.5, 123]), 1,\n",
    "                                          np.where(micro_df[\"Floc size\"].isin([1, 2, 6, 12]), 0, np.nan))\n",
    "    micro_df = micro_df.drop([\"Floc size\"], axis=1)\n",
    "    return micro_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def floc_shape(micro_df: pd.DataFrame):\n",
    "    micro_df[\"Shape_close\"] = np.where(micro_df[\"Close\"].isin([3, 0.6, 0.7, 2, 60, 0.02, 0.5, 25]), 1,\n",
    "                                 np.where(micro_df[\"Open\"].isin([3, 40, 0.5, 75, 0.4, 2]), 1, \n",
    "                                 np.where(micro_df[\"Close\"].isin([0, 1]), 0,        \n",
    "                                 np.where(micro_df[\"Open and close\"].isin([2, 3]), 1,\n",
    "                                 np.where(micro_df[\"Shape\"].isin([2, 3]), 1,\n",
    "                                 np.where(micro_df[\"Shape\"].isin([1]), 0, np.nan))))))\n",
    "    micro_df[\"Shape_open\"] = np.where(micro_df[\"Open\"].isin([3, 40, 0.04, 0.5, 75, 1, 0.4]), 1,\n",
    "                                 np.where(micro_df[\"Close\"].isin([3, 0.6, 0.7, 0.5, 25, 1]), 1,\n",
    "                                 np.where(micro_df[\"Open\"].isin([0, 2]), 0,\n",
    "                                 np.where(micro_df[\"Open and close\"].isin([3]), 1,\n",
    "                                 np.where(micro_df[\"Open and close\"].isin([2]), 0, \n",
    "                                 np.where(micro_df[\"Shape\"].isin([1, 3]), 1,\n",
    "                                 np.where(micro_df[\"Shape\"].isin([2]), 0, np.nan)))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_micro_df(micro_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Cleans values of microscopic dataframes with all the cleansing functions\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    micro_df: pd.DataFrame\n",
    "\n",
    "    Return\n",
    "    ----------\n",
    "    micro_df: pd.DataFrame\n",
    "    \"\"\"\n",
    "    remove_nan_rows(micro_df)\n",
    "    fix_object_cols_to_float(micro_df)\n",
    "    remove_negatives(micro_df)\n",
    "    filaments_zero_to_nan(micro_df)\n",
    "    all_zero_to_nan(micro_df)\n",
    "    micro_df = floc_size(micro_df)\n",
    "    floc_shape(micro_df)\n",
    "    return micro_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_micro_df_list(micro_df_list: list):\n",
    "    \"\"\"\n",
    "    Loop over the 4 dataframes in the dataframe list\n",
    "    and use the clean_micro_df to clean values.\n",
    "    Changes all df in list inplace.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    micro_df_list: list\n",
    "    \"\"\"\n",
    "    for i in range(4):\n",
    "        micro_df_list[i] = clean_micro_df(micro_df_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dfs_to_csv(df_list: list, data_name: str):\n",
    "    \"\"\"\n",
    "    Save the split, cleaned list of 4 bio reactors dataframes to csv file.\n",
    "    If files already exists, skips saving.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_list: list\n",
    "    data_name: str\n",
    "        desirable csv file name\n",
    "    \"\"\"\n",
    "    assert data_name in {\"svi\", \"micro\"}, 'data_name invalid, expected \"svi\"/\"micro\"'\n",
    "    for i in range(4):\n",
    "        fname = pathlib.Path(\"clean_tables/\" + f\"{data_name}_{i+1}.csv\")\n",
    "        if not pathlib.Path(fname).is_file():  # only if it does not exist yet\n",
    "            df_list[i].to_csv(fname, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    micro_path = check_file(\"micro - total.csv\")\n",
    "    micro_df = pd.read_csv(micro_path)\n",
    "    micro_df = dates_to_datetime_objects(micro_df)\n",
    "    micro_df_list = split_microscopic_to_reactor(micro_df)\n",
    "    clean_micro_df_list(micro_df_list)\n",
    "    save_dfs_to_csv(micro_df_list,\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['arcella', 'nude ameba', 'aspidisca', 'trachelopylum', 'lionutus',\n",
       "       'paramecium', 'carchecium', 'epistylis', 'opercularia', 'podophyra',\n",
       "       'tokophyra', 'vorticella', 'rotifer', 'nematode', 'worms',\n",
       "       'micro flagellates', 'peranema trich', 'spirochaetes', '0041_0675',\n",
       "       '0092', '1851', 'beggiatoa', 'Microthrix', 'N. Limicola', 'Nocardia',\n",
       "       'Thiothrix', 'zoogloea', 'Floc Strength', 'Indian Ink',\n",
       "       'Filament index', 'Close', 'Open and close', 'Open', 'Shape',\n",
       "       'In and out', 'In', 'Free filaments', 'Filaments location',\n",
       "       'Floc_size_small', 'Floc_size_medium', 'Floc_size_large', 'Shape_close',\n",
       "       'Shape_open'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_df_list[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "r= micro_df_list[0][[\"Shape_open\", \"Shape_close\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shape_open</th>\n",
       "      <th>Shape_close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-08-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-03</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-07</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-09</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-06</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-08</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-05</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-07</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-05</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Shape_open  Shape_close\n",
       "date                               \n",
       "2015-08-06         NaN          NaN\n",
       "2015-09-03         1.0          1.0\n",
       "2015-09-20         1.0          1.0\n",
       "2015-10-07         1.0          1.0\n",
       "2015-10-14         1.0          0.0\n",
       "2015-10-18         1.0          0.0\n",
       "2015-10-20         1.0          1.0\n",
       "2015-12-09         1.0          0.0\n",
       "2015-12-15         NaN          NaN\n",
       "2015-12-17         NaN          NaN\n",
       "2015-12-21         NaN          NaN\n",
       "2015-12-25         NaN          NaN\n",
       "2015-12-28         NaN          NaN\n",
       "2015-12-31         NaN          NaN\n",
       "2016-01-07         NaN          NaN\n",
       "2016-01-12         NaN          NaN\n",
       "2016-01-28         NaN          NaN\n",
       "2016-02-18         NaN          NaN\n",
       "2016-03-10         NaN          NaN\n",
       "2016-03-21         NaN          NaN\n",
       "2016-05-05         NaN          NaN\n",
       "2016-05-14         NaN          NaN\n",
       "2016-06-07         NaN          NaN\n",
       "2016-06-23         NaN          NaN\n",
       "2016-06-29         0.0          1.0\n",
       "2016-07-21         NaN          NaN\n",
       "2016-08-10         NaN          NaN\n",
       "2016-08-18         NaN          NaN\n",
       "2016-09-06         1.0          1.0\n",
       "2016-09-29         NaN          NaN\n",
       "2016-10-26         1.0          0.0\n",
       "2016-12-05         NaN          NaN\n",
       "2016-12-11         NaN          NaN\n",
       "2016-12-14         1.0          0.0\n",
       "2017-01-04         1.0          0.0\n",
       "2017-01-22         NaN          NaN\n",
       "2017-01-29         NaN          NaN\n",
       "2017-02-01         NaN          NaN\n",
       "2017-02-07         NaN          NaN\n",
       "2017-02-20         NaN          NaN\n",
       "2017-03-05         NaN          NaN\n",
       "2017-03-08         NaN          NaN\n",
       "2017-03-14         NaN          NaN\n",
       "2017-03-16         NaN          NaN\n",
       "2017-04-05         1.0          1.0\n",
       "2017-05-07         1.0          1.0\n",
       "2017-05-10         1.0          0.0\n",
       "2017-06-05         1.0          1.0\n",
       "2017-06-18         1.0          0.0\n",
       "2017-06-26         1.0          0.0"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[200:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
